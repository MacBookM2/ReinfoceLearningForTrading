{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ddqn_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP9n7i+m9afsZYyUtdLwH6B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/ddqn_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "612e4f93-fffb-46cc-a5fd-a56831b87882"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "mode = 'train'\n",
        "name = 'ddqn'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evsq8JqfWNoj"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "\n",
        "        self.cntr = 0\n",
        "        self.size = 0\n",
        "        self.max_size = max_size\n",
        "        self.batch_size = batch_size\n",
        "        self.states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.next_states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.acts_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "        self.rewards_memory = np.zeros(self.max_size, dtype=np.float32)\n",
        "        self.done_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        self.states_memory[self.cntr] = state\n",
        "        self.next_states_memory[self.cntr] = next_state\n",
        "        self.acts_memory[self.cntr] = act\n",
        "        self.rewards_memory[self.cntr] = reward\n",
        "        self.done_memory[self.cntr] = done\n",
        "        self.cntr = (self.cntr+1) % self.max_size\n",
        "        self.size = min(self.size+1, self.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(self.size, self.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [self.states_memory[mb_index],self.next_states_memory[mb_index],\n",
        "                 self.acts_memory[mb_index],self.rewards_memory[mb_index],\n",
        "                 self.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        model1 = Sequential()\n",
        "        model1.add(Dense(3, input_shape=(3,)))\n",
        "        model1.add(ReLU()) \n",
        "        model1.add(Dense(3))\n",
        "        model1.add(ReLU()) \n",
        "        model1.add(Dense(3))\n",
        "        model1.compile(loss=\"mse\", optimizer=optimizer)\n",
        "        model1.summary()\n",
        "        self.model1 = model1\n",
        "\n",
        "        model2 = Sequential()\n",
        "        model2.add(Dense(3, input_shape=(3,)))\n",
        "        model2.add(ReLU()) \n",
        "        model2.add(Dense(3))\n",
        "        model2.add(ReLU()) \n",
        "        model2.add(Dense(3))\n",
        "        model2.compile(loss=\"mse\", optimizer=optimizer)\n",
        "        model2.summary()\n",
        "        self.model2 = model2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain, ReplayMemory):\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "        self.batch_size = batch_size\n",
        "        Brain.__init__(self)\n",
        "        ReplayMemory.__init__(self, max_size, batch_size)\n",
        "\n",
        "    def update_replay_memory(self, state, action, reward, next_state, done):\n",
        "        self.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "    def act(self, state,s_flag=12):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self._predict(state,s_flag)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values)\n",
        "\n",
        "    def _predict(self, state, s_flag = 12):\n",
        "        values = None\n",
        "        q1 = self.model1.predict(state)\n",
        "        q2 = self.model2.predict(state)\n",
        "        if s_flag == 12:\n",
        "            values = np.array([q1[0,a] + q2[0,a] for a in range(3)])\n",
        "        elif s_flag == 11:\n",
        "            values = np.array([q1[0,a] + q1[0,a] for a in range(3)])\n",
        "        else:\n",
        "            values = np.array([q2[0,a] + q2[0,a] for a in range(3)])\n",
        "        return values\n",
        "\n",
        "    def replay(self, s_flag):\n",
        "        if self.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "\n",
        "        next_act_values = self._predict(next_states,s_flag)\n",
        "        next_action = np.argmax(next_act_values)\n",
        "\n",
        "        if s_flag == 11:\n",
        "            q = self.model1.predict(states)\n",
        "            next_q = self.model2.predict(next_states)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            target[:, actions] = rewards + (1 - done) * self.gamma*np.max(next_q, axis=1)\n",
        "            self.model1.train_on_batch(states, target)\n",
        "        else:\n",
        "            q = self.model2.predict(states)  \n",
        "            next_q = self.model1.predict(next_states)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            target[:, actions] = rewards + (1 - done) * self.gamma*np.max(next_q, axis=1)\n",
        "            self.model2.train_on_batch(states, target)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "\n",
        "    def load(self, name, name2):\n",
        "        self.model1.load_weights(name)\n",
        "        self.model2.load_weights(name2)\n",
        "\n",
        "    def save(self, name, name2):\n",
        "        self.model1.save_weights(name)\n",
        "        self.model2.save_weights(name2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 200, mode = 'test'):\n",
        "        self.env            = env\n",
        "        self.agent          = agent\n",
        "        self.mdl_dir        = mdl_dir\n",
        "        self.scaler         = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode           = mode\n",
        "        self.name           = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done  = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                s_flag = 12\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    rand = np.random.random()\n",
        "                    if rand <= 0.5:\n",
        "                        s_flag = 11\n",
        "                    else:\n",
        "                        s_flag = 22\n",
        "                    self.agent.update_replay_memory(state, action, reward, next_state, done)\n",
        "                    self.agent.replay(s_flag)                \n",
        "            play_time = datetime.now() - start_time\n",
        "\n",
        "            if self.mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}_1.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}_1.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYFNVDDQz9X9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ba5d83-38b8-4291-d311-0f3af74183bd"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 200\n",
        "batch_size = 32\n",
        "max_size = 500\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "agent = Agent(max_size, batch_size)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Episode: 1/200 RapTime: 0:02:13.733274 FixedProfit: 1111699\n",
            "Episode: 2/200 RapTime: 0:02:29.495101 FixedProfit: 1191466\n",
            "Episode: 3/200 RapTime: 0:02:27.430211 FixedProfit: 1181710\n",
            "Episode: 4/200 RapTime: 0:02:30.063102 FixedProfit: 1177871\n",
            "Episode: 5/200 RapTime: 0:02:28.510329 FixedProfit: 1197165\n",
            "Episode: 6/200 RapTime: 0:02:28.543921 FixedProfit: 1179981\n",
            "Episode: 7/200 RapTime: 0:02:30.840800 FixedProfit: 1199860\n",
            "Episode: 8/200 RapTime: 0:02:29.398661 FixedProfit: 1206940\n",
            "Episode: 9/200 RapTime: 0:02:29.640643 FixedProfit: 1197165\n",
            "Episode: 10/200 RapTime: 0:02:29.012001 FixedProfit: 1194302\n",
            "Episode: 11/200 RapTime: 0:02:29.803845 FixedProfit: 1208390\n",
            "Episode: 12/200 RapTime: 0:02:27.679171 FixedProfit: 1184367\n",
            "Episode: 13/200 RapTime: 0:02:27.619428 FixedProfit: 1210557\n",
            "Episode: 14/200 RapTime: 0:02:28.815725 FixedProfit: 1205038\n",
            "Episode: 15/200 RapTime: 0:02:28.963159 FixedProfit: 1193684\n",
            "Episode: 16/200 RapTime: 0:02:29.218804 FixedProfit: 1194573\n",
            "Episode: 17/200 RapTime: 0:02:29.518366 FixedProfit: 1170520\n",
            "Episode: 18/200 RapTime: 0:02:28.875285 FixedProfit: 1200295\n",
            "Episode: 19/200 RapTime: 0:02:29.311840 FixedProfit: 1179901\n",
            "Episode: 20/200 RapTime: 0:02:29.165670 FixedProfit: 1171335\n",
            "Episode: 21/200 RapTime: 0:02:30.049810 FixedProfit: 1203035\n",
            "Episode: 22/200 RapTime: 0:02:30.810383 FixedProfit: 1201936\n",
            "Episode: 23/200 RapTime: 0:02:30.124759 FixedProfit: 1202219\n",
            "Episode: 24/200 RapTime: 0:02:29.486031 FixedProfit: 1188317\n",
            "Episode: 25/200 RapTime: 0:02:31.783319 FixedProfit: 1197165\n",
            "Episode: 26/200 RapTime: 0:02:29.072619 FixedProfit: 1198699\n",
            "Episode: 27/200 RapTime: 0:02:31.570254 FixedProfit: 1205759\n",
            "Episode: 28/200 RapTime: 0:02:30.505827 FixedProfit: 1177468\n",
            "Episode: 29/200 RapTime: 0:02:29.275458 FixedProfit: 1198753\n",
            "Episode: 30/200 RapTime: 0:02:30.605261 FixedProfit: 1252169\n",
            "Episode: 31/200 RapTime: 0:02:29.596808 FixedProfit: 1197165\n",
            "Episode: 32/200 RapTime: 0:02:30.693137 FixedProfit: 1197165\n",
            "Episode: 33/200 RapTime: 0:02:29.010268 FixedProfit: 1197165\n",
            "Episode: 34/200 RapTime: 0:02:30.525698 FixedProfit: 1201632\n",
            "Episode: 35/200 RapTime: 0:02:28.059330 FixedProfit: 1170168\n",
            "Episode: 36/200 RapTime: 0:02:28.698422 FixedProfit: 1197165\n",
            "Episode: 37/200 RapTime: 0:02:29.221447 FixedProfit: 1197165\n",
            "Episode: 38/200 RapTime: 0:02:30.890103 FixedProfit: 1199204\n",
            "Episode: 39/200 RapTime: 0:02:29.126261 FixedProfit: 1206275\n",
            "Episode: 40/200 RapTime: 0:02:30.847621 FixedProfit: 1177120\n",
            "Episode: 41/200 RapTime: 0:02:31.000168 FixedProfit: 1190812\n",
            "Episode: 42/200 RapTime: 0:02:28.917375 FixedProfit: 1211596\n",
            "Episode: 43/200 RapTime: 0:02:31.300095 FixedProfit: 1195767\n",
            "Episode: 44/200 RapTime: 0:02:29.062809 FixedProfit: 1187259\n",
            "Episode: 45/200 RapTime: 0:02:28.515612 FixedProfit: 1183518\n",
            "Episode: 46/200 RapTime: 0:02:31.639911 FixedProfit: 1196252\n",
            "Episode: 47/200 RapTime: 0:02:30.149339 FixedProfit: 1211658\n",
            "Episode: 48/200 RapTime: 0:02:29.396768 FixedProfit: 1198077\n",
            "Episode: 49/200 RapTime: 0:02:29.464613 FixedProfit: 1199500\n",
            "Episode: 50/200 RapTime: 0:02:29.689669 FixedProfit: 1186805\n",
            "Episode: 51/200 RapTime: 0:02:30.967863 FixedProfit: 1174535\n",
            "Episode: 52/200 RapTime: 0:02:27.857291 FixedProfit: 1177332\n",
            "Episode: 53/200 RapTime: 0:02:30.741235 FixedProfit: 1227786\n",
            "Episode: 54/200 RapTime: 0:02:31.015784 FixedProfit: 1197165\n",
            "Episode: 55/200 RapTime: 0:02:29.365920 FixedProfit: 1191155\n",
            "Episode: 56/200 RapTime: 0:02:31.203709 FixedProfit: 1184201\n",
            "Episode: 57/200 RapTime: 0:02:30.895557 FixedProfit: 1196795\n",
            "Episode: 58/200 RapTime: 0:02:29.139846 FixedProfit: 1198391\n",
            "Episode: 59/200 RapTime: 0:02:29.494392 FixedProfit: 1191825\n",
            "Episode: 60/200 RapTime: 0:02:29.169100 FixedProfit: 1204303\n",
            "Episode: 61/200 RapTime: 0:02:29.297282 FixedProfit: 1182387\n",
            "Episode: 62/200 RapTime: 0:02:29.618799 FixedProfit: 1225053\n",
            "Episode: 63/200 RapTime: 0:02:31.019656 FixedProfit: 1197165\n",
            "Episode: 64/200 RapTime: 0:02:29.266293 FixedProfit: 1195464\n",
            "Episode: 65/200 RapTime: 0:02:31.007819 FixedProfit: 1196665\n",
            "Episode: 66/200 RapTime: 0:02:30.461206 FixedProfit: 1183979\n",
            "Episode: 67/200 RapTime: 0:02:30.698769 FixedProfit: 1187568\n",
            "Episode: 68/200 RapTime: 0:02:29.958590 FixedProfit: 1198337\n",
            "Episode: 69/200 RapTime: 0:02:31.780542 FixedProfit: 1187513\n",
            "Episode: 70/200 RapTime: 0:02:28.946370 FixedProfit: 1197165\n",
            "Episode: 71/200 RapTime: 0:02:29.196248 FixedProfit: 1196338\n",
            "Episode: 72/200 RapTime: 0:02:29.293688 FixedProfit: 1199890\n",
            "Episode: 73/200 RapTime: 0:02:30.119838 FixedProfit: 1201361\n",
            "Episode: 74/200 RapTime: 0:02:29.343062 FixedProfit: 1207854\n",
            "Episode: 75/200 RapTime: 0:02:29.197896 FixedProfit: 1193359\n",
            "Episode: 76/200 RapTime: 0:02:29.035692 FixedProfit: 1201270\n",
            "Episode: 77/200 RapTime: 0:02:29.771138 FixedProfit: 1191753\n",
            "Episode: 78/200 RapTime: 0:02:29.453907 FixedProfit: 1197165\n",
            "Episode: 79/200 RapTime: 0:02:29.245611 FixedProfit: 1196113\n",
            "Episode: 80/200 RapTime: 0:02:29.249963 FixedProfit: 1198241\n",
            "Episode: 81/200 RapTime: 0:02:29.310003 FixedProfit: 1189219\n",
            "Episode: 82/200 RapTime: 0:02:28.806320 FixedProfit: 1173967\n",
            "Episode: 83/200 RapTime: 0:02:29.031646 FixedProfit: 1179124\n",
            "Episode: 84/200 RapTime: 0:02:28.955737 FixedProfit: 1186873\n",
            "Episode: 85/200 RapTime: 0:02:29.091748 FixedProfit: 1196943\n",
            "Episode: 86/200 RapTime: 0:02:29.084475 FixedProfit: 1207717\n",
            "Episode: 87/200 RapTime: 0:02:29.016453 FixedProfit: 1192546\n",
            "Episode: 88/200 RapTime: 0:02:29.279131 FixedProfit: 1198521\n",
            "Episode: 89/200 RapTime: 0:02:29.667077 FixedProfit: 1201174\n",
            "Episode: 90/200 RapTime: 0:02:29.078775 FixedProfit: 1199734\n",
            "Episode: 91/200 RapTime: 0:02:29.138169 FixedProfit: 1197851\n",
            "Episode: 92/200 RapTime: 0:02:31.544092 FixedProfit: 1186624\n",
            "Episode: 93/200 RapTime: 0:02:30.844425 FixedProfit: 1201857\n",
            "Episode: 94/200 RapTime: 0:02:30.637295 FixedProfit: 1197165\n",
            "Episode: 95/200 RapTime: 0:02:29.175689 FixedProfit: 1214471\n",
            "Episode: 96/200 RapTime: 0:02:28.952579 FixedProfit: 1202993\n",
            "Episode: 97/200 RapTime: 0:02:29.148077 FixedProfit: 1205164\n",
            "Episode: 98/200 RapTime: 0:02:29.095693 FixedProfit: 1198243\n",
            "Episode: 99/200 RapTime: 0:02:28.091769 FixedProfit: 1209311\n",
            "Episode: 100/200 RapTime: 0:02:29.542291 FixedProfit: 1194216\n",
            "Episode: 101/200 RapTime: 0:02:28.942033 FixedProfit: 1197121\n",
            "Episode: 102/200 RapTime: 0:02:29.242583 FixedProfit: 1200296\n",
            "Episode: 103/200 RapTime: 0:02:28.959551 FixedProfit: 1219125\n",
            "Episode: 104/200 RapTime: 0:02:29.426216 FixedProfit: 1188102\n",
            "Episode: 105/200 RapTime: 0:02:29.017886 FixedProfit: 1196400\n",
            "Episode: 106/200 RapTime: 0:02:29.438518 FixedProfit: 1195827\n",
            "Episode: 107/200 RapTime: 0:02:29.035396 FixedProfit: 1184691\n",
            "Episode: 108/200 RapTime: 0:02:29.434571 FixedProfit: 1197165\n",
            "Episode: 109/200 RapTime: 0:02:28.654336 FixedProfit: 1224625\n",
            "Episode: 110/200 RapTime: 0:02:29.092222 FixedProfit: 1234074\n",
            "Episode: 111/200 RapTime: 0:02:29.407942 FixedProfit: 1199828\n",
            "Episode: 112/200 RapTime: 0:02:29.807597 FixedProfit: 1189624\n",
            "Episode: 113/200 RapTime: 0:02:29.115455 FixedProfit: 1197136\n",
            "Episode: 114/200 RapTime: 0:02:28.982035 FixedProfit: 1183324\n",
            "Episode: 115/200 RapTime: 0:02:28.979877 FixedProfit: 1203037\n",
            "Episode: 116/200 RapTime: 0:02:29.158738 FixedProfit: 1188432\n",
            "Episode: 117/200 RapTime: 0:02:28.529600 FixedProfit: 1217643\n",
            "Episode: 118/200 RapTime: 0:02:29.101467 FixedProfit: 1239318\n",
            "Episode: 119/200 RapTime: 0:02:30.559881 FixedProfit: 1197165\n",
            "Episode: 120/200 RapTime: 0:02:28.681428 FixedProfit: 1193087\n",
            "Episode: 121/200 RapTime: 0:02:29.254478 FixedProfit: 1200835\n",
            "Episode: 122/200 RapTime: 0:02:28.824882 FixedProfit: 1210604\n",
            "Episode: 123/200 RapTime: 0:02:29.116209 FixedProfit: 1173054\n",
            "Episode: 124/200 RapTime: 0:02:28.548260 FixedProfit: 1177835\n",
            "Episode: 125/200 RapTime: 0:02:28.992018 FixedProfit: 1194074\n",
            "Episode: 126/200 RapTime: 0:02:29.220519 FixedProfit: 1179983\n",
            "Episode: 127/200 RapTime: 0:02:28.929639 FixedProfit: 1201121\n",
            "Episode: 128/200 RapTime: 0:02:28.633943 FixedProfit: 1204861\n",
            "Episode: 129/200 RapTime: 0:02:29.008779 FixedProfit: 1193919\n",
            "Episode: 130/200 RapTime: 0:02:28.687054 FixedProfit: 1200670\n",
            "Episode: 131/200 RapTime: 0:02:29.209128 FixedProfit: 1203416\n",
            "Episode: 132/200 RapTime: 0:02:29.008867 FixedProfit: 1185072\n",
            "Episode: 133/200 RapTime: 0:02:29.748443 FixedProfit: 1192081\n",
            "Episode: 134/200 RapTime: 0:02:28.995834 FixedProfit: 1221794\n",
            "Episode: 135/200 RapTime: 0:02:29.008401 FixedProfit: 1204130\n",
            "Episode: 136/200 RapTime: 0:02:29.027141 FixedProfit: 1197165\n",
            "Episode: 137/200 RapTime: 0:02:29.372598 FixedProfit: 1207077\n",
            "Episode: 138/200 RapTime: 0:02:29.688652 FixedProfit: 1194917\n",
            "Episode: 139/200 RapTime: 0:02:29.804352 FixedProfit: 1179061\n",
            "Episode: 140/200 RapTime: 0:02:28.963472 FixedProfit: 1193727\n",
            "Episode: 141/200 RapTime: 0:02:29.123362 FixedProfit: 1230292\n",
            "Episode: 142/200 RapTime: 0:02:29.220506 FixedProfit: 1192387\n",
            "Episode: 143/200 RapTime: 0:02:28.802416 FixedProfit: 1211512\n",
            "Episode: 144/200 RapTime: 0:02:29.116709 FixedProfit: 1195684\n",
            "Episode: 145/200 RapTime: 0:02:29.296270 FixedProfit: 1197889\n",
            "Episode: 146/200 RapTime: 0:02:29.336376 FixedProfit: 1166996\n",
            "Episode: 147/200 RapTime: 0:02:31.152722 FixedProfit: 1197165\n",
            "Episode: 148/200 RapTime: 0:02:30.562908 FixedProfit: 1211322\n",
            "Episode: 149/200 RapTime: 0:02:29.289326 FixedProfit: 1185062\n",
            "Episode: 150/200 RapTime: 0:02:30.038070 FixedProfit: 1197165\n",
            "Episode: 151/200 RapTime: 0:02:29.153052 FixedProfit: 1182350\n",
            "Episode: 152/200 RapTime: 0:02:29.646256 FixedProfit: 1191061\n",
            "Episode: 153/200 RapTime: 0:02:29.554370 FixedProfit: 1192753\n",
            "Episode: 154/200 RapTime: 0:02:29.367191 FixedProfit: 1182604\n",
            "Episode: 155/200 RapTime: 0:02:28.831016 FixedProfit: 1171970\n",
            "Episode: 156/200 RapTime: 0:02:29.481882 FixedProfit: 1219287\n",
            "Episode: 157/200 RapTime: 0:02:29.297146 FixedProfit: 1222194\n",
            "Episode: 158/200 RapTime: 0:02:29.542690 FixedProfit: 1198589\n",
            "Episode: 159/200 RapTime: 0:02:29.440587 FixedProfit: 1211534\n",
            "Episode: 160/200 RapTime: 0:02:29.725515 FixedProfit: 1199747\n",
            "Episode: 161/200 RapTime: 0:02:30.776199 FixedProfit: 1197165\n",
            "Episode: 162/200 RapTime: 0:02:29.208287 FixedProfit: 1181712\n",
            "Episode: 163/200 RapTime: 0:02:30.194906 FixedProfit: 1198957\n",
            "Episode: 164/200 RapTime: 0:02:30.716142 FixedProfit: 1196953\n",
            "Episode: 165/200 RapTime: 0:02:30.005921 FixedProfit: 1197165\n",
            "Episode: 166/200 RapTime: 0:02:31.501604 FixedProfit: 1187629\n",
            "Episode: 167/200 RapTime: 0:02:30.336764 FixedProfit: 1207077\n",
            "Episode: 168/200 RapTime: 0:02:29.297355 FixedProfit: 1182186\n",
            "Episode: 169/200 RapTime: 0:02:29.587961 FixedProfit: 1181654\n",
            "Episode: 170/200 RapTime: 0:02:29.268803 FixedProfit: 1203652\n",
            "Episode: 171/200 RapTime: 0:02:29.026699 FixedProfit: 1192151\n",
            "Episode: 172/200 RapTime: 0:02:29.073287 FixedProfit: 1177856\n",
            "Episode: 173/200 RapTime: 0:02:29.138670 FixedProfit: 1188875\n",
            "Episode: 174/200 RapTime: 0:02:29.196995 FixedProfit: 1201829\n",
            "Episode: 175/200 RapTime: 0:02:29.095854 FixedProfit: 1186326\n",
            "Episode: 176/200 RapTime: 0:02:29.359093 FixedProfit: 1191259\n",
            "Episode: 177/200 RapTime: 0:02:28.575871 FixedProfit: 1206336\n",
            "Episode: 178/200 RapTime: 0:02:29.105032 FixedProfit: 1194043\n",
            "Episode: 179/200 RapTime: 0:02:29.072304 FixedProfit: 1198021\n",
            "Episode: 180/200 RapTime: 0:02:29.303512 FixedProfit: 1191229\n",
            "Episode: 181/200 RapTime: 0:02:29.769222 FixedProfit: 1211110\n",
            "Episode: 182/200 RapTime: 0:02:29.128445 FixedProfit: 1197165\n",
            "Episode: 183/200 RapTime: 0:02:28.945892 FixedProfit: 1195839\n",
            "Episode: 184/200 RapTime: 0:02:28.825613 FixedProfit: 1197165\n",
            "Episode: 185/200 RapTime: 0:02:29.400871 FixedProfit: 1197165\n",
            "Episode: 186/200 RapTime: 0:02:28.912760 FixedProfit: 1191130\n",
            "Episode: 187/200 RapTime: 0:02:28.572962 FixedProfit: 1210330\n",
            "Episode: 188/200 RapTime: 0:02:28.306697 FixedProfit: 1178113\n",
            "Episode: 189/200 RapTime: 0:02:29.001366 FixedProfit: 1197957\n",
            "Episode: 190/200 RapTime: 0:02:28.805787 FixedProfit: 1196938\n",
            "Episode: 191/200 RapTime: 0:02:29.107816 FixedProfit: 1172558\n",
            "Episode: 192/200 RapTime: 0:02:28.098120 FixedProfit: 1203401\n",
            "Episode: 193/200 RapTime: 0:02:28.461008 FixedProfit: 1180165\n",
            "Episode: 194/200 RapTime: 0:02:28.551679 FixedProfit: 1195690\n",
            "Episode: 195/200 RapTime: 0:02:28.641576 FixedProfit: 1195421\n",
            "Episode: 196/200 RapTime: 0:02:28.482796 FixedProfit: 1206347\n",
            "Episode: 197/200 RapTime: 0:02:28.839202 FixedProfit: 1208861\n",
            "Episode: 198/200 RapTime: 0:02:28.301467 FixedProfit: 1176809\n",
            "Episode: 199/200 RapTime: 0:02:28.914482 FixedProfit: 1200220\n",
            "Episode: 200/200 RapTime: 0:02:28.579485 FixedProfit: 1178080\n"
          ]
        }
      ]
    }
  ]
}
