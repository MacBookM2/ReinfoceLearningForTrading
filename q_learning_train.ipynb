{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMyt796VNVZE8xmTpHNQ5vi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "e592b979-749b-4d14-937b-0dad54a2d89d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_train.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'qlearning_train.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        self.brain.train(state, action, reward, next_state, done)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "\n",
        "            if mode == 'train':\n",
        "                agent.train(state, action, reward, next_state, done)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        state = next_state\n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "8ca341ef-1e9b-4631-fea2-43981b9b12c9"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'train'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_ql.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_ql.h5')\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:58.263011 FixedProfit: 1283639\n",
            "Episode: 2/100 RapTime: 0:00:55.771936 FixedProfit: 961101\n",
            "Episode: 3/100 RapTime: 0:00:55.958344 FixedProfit: 920738\n",
            "Episode: 4/100 RapTime: 0:00:56.279360 FixedProfit: 1136918\n",
            "Episode: 5/100 RapTime: 0:00:56.223074 FixedProfit: 1202078\n",
            "Episode: 6/100 RapTime: 0:00:56.607534 FixedProfit: 1002769\n",
            "Episode: 7/100 RapTime: 0:00:56.113772 FixedProfit: 978777\n",
            "Episode: 8/100 RapTime: 0:00:56.312844 FixedProfit: 990325\n",
            "Episode: 9/100 RapTime: 0:00:56.307427 FixedProfit: 1203268\n",
            "Episode: 10/100 RapTime: 0:00:56.127088 FixedProfit: 1161301\n",
            "Episode: 11/100 RapTime: 0:00:56.445323 FixedProfit: 1058051\n",
            "Episode: 12/100 RapTime: 0:00:56.426931 FixedProfit: 1049050\n",
            "Episode: 13/100 RapTime: 0:00:56.514029 FixedProfit: 1109828\n",
            "Episode: 14/100 RapTime: 0:00:56.476230 FixedProfit: 989543\n",
            "Episode: 15/100 RapTime: 0:00:56.477103 FixedProfit: 1223919\n",
            "Episode: 16/100 RapTime: 0:00:56.804032 FixedProfit: 1096274\n",
            "Episode: 17/100 RapTime: 0:00:56.458412 FixedProfit: 1193458\n",
            "Episode: 18/100 RapTime: 0:00:56.700616 FixedProfit: 1318566\n",
            "Episode: 19/100 RapTime: 0:00:56.416278 FixedProfit: 850874\n",
            "Episode: 20/100 RapTime: 0:00:56.726610 FixedProfit: 1040450\n",
            "Episode: 21/100 RapTime: 0:00:56.482331 FixedProfit: 996108\n",
            "Episode: 22/100 RapTime: 0:00:56.590148 FixedProfit: 1025376\n",
            "Episode: 23/100 RapTime: 0:00:56.891989 FixedProfit: 1083317\n",
            "Episode: 24/100 RapTime: 0:00:56.531544 FixedProfit: 1125743\n",
            "Episode: 25/100 RapTime: 0:00:57.445598 FixedProfit: 1346499\n",
            "Episode: 26/100 RapTime: 0:00:56.546566 FixedProfit: 1153437\n",
            "Episode: 27/100 RapTime: 0:00:56.511140 FixedProfit: 1139613\n",
            "Episode: 28/100 RapTime: 0:00:56.332580 FixedProfit: 1043431\n",
            "Episode: 29/100 RapTime: 0:00:56.408548 FixedProfit: 1012586\n",
            "Episode: 30/100 RapTime: 0:00:56.707704 FixedProfit: 1250510\n",
            "Episode: 31/100 RapTime: 0:00:56.379056 FixedProfit: 998164\n",
            "Episode: 32/100 RapTime: 0:00:56.312269 FixedProfit: 1125487\n",
            "Episode: 33/100 RapTime: 0:00:56.290596 FixedProfit: 944598\n",
            "Episode: 34/100 RapTime: 0:00:56.428614 FixedProfit: 1201154\n",
            "Episode: 35/100 RapTime: 0:00:56.505733 FixedProfit: 1161028\n",
            "Episode: 36/100 RapTime: 0:00:56.196316 FixedProfit: 980182\n",
            "Episode: 37/100 RapTime: 0:00:56.315204 FixedProfit: 916272\n",
            "Episode: 38/100 RapTime: 0:00:55.905143 FixedProfit: 962555\n",
            "Episode: 39/100 RapTime: 0:00:56.433203 FixedProfit: 1006765\n",
            "Episode: 40/100 RapTime: 0:00:56.041525 FixedProfit: 1172677\n",
            "Episode: 41/100 RapTime: 0:00:56.239698 FixedProfit: 1176811\n",
            "Episode: 42/100 RapTime: 0:00:55.895489 FixedProfit: 1046633\n",
            "Episode: 43/100 RapTime: 0:00:56.221588 FixedProfit: 1012223\n",
            "Episode: 44/100 RapTime: 0:00:56.536518 FixedProfit: 1121399\n",
            "Episode: 45/100 RapTime: 0:00:56.014746 FixedProfit: 1135931\n",
            "Episode: 46/100 RapTime: 0:00:56.860461 FixedProfit: 1291364\n",
            "Episode: 47/100 RapTime: 0:00:56.089789 FixedProfit: 908870\n",
            "Episode: 48/100 RapTime: 0:00:56.871385 FixedProfit: 960195\n",
            "Episode: 49/100 RapTime: 0:00:56.268330 FixedProfit: 864944\n",
            "Episode: 50/100 RapTime: 0:00:56.603746 FixedProfit: 1034741\n",
            "Episode: 51/100 RapTime: 0:00:56.385512 FixedProfit: 942259\n",
            "Episode: 52/100 RapTime: 0:00:56.340088 FixedProfit: 986902\n",
            "Episode: 53/100 RapTime: 0:00:56.588622 FixedProfit: 988929\n",
            "Episode: 54/100 RapTime: 0:00:56.267921 FixedProfit: 1189426\n",
            "Episode: 55/100 RapTime: 0:00:56.387572 FixedProfit: 1239179\n",
            "Episode: 56/100 RapTime: 0:00:56.637805 FixedProfit: 933999\n",
            "Episode: 57/100 RapTime: 0:00:56.396861 FixedProfit: 973247\n",
            "Episode: 58/100 RapTime: 0:00:56.492835 FixedProfit: 1016768\n",
            "Episode: 59/100 RapTime: 0:00:56.806577 FixedProfit: 860941\n",
            "Episode: 60/100 RapTime: 0:00:56.645576 FixedProfit: 1096934\n",
            "Episode: 61/100 RapTime: 0:00:56.369609 FixedProfit: 1227058\n",
            "Episode: 62/100 RapTime: 0:00:56.341941 FixedProfit: 1131700\n",
            "Episode: 63/100 RapTime: 0:00:56.177601 FixedProfit: 1016248\n",
            "Episode: 64/100 RapTime: 0:00:56.088925 FixedProfit: 1161804\n",
            "Episode: 65/100 RapTime: 0:00:56.236725 FixedProfit: 1070495\n",
            "Episode: 66/100 RapTime: 0:00:55.994762 FixedProfit: 1127732\n",
            "Episode: 67/100 RapTime: 0:00:56.598680 FixedProfit: 956867\n",
            "Episode: 68/100 RapTime: 0:00:56.081813 FixedProfit: 1100963\n",
            "Episode: 69/100 RapTime: 0:00:56.488887 FixedProfit: 1081854\n",
            "Episode: 70/100 RapTime: 0:00:56.337088 FixedProfit: 1124500\n",
            "Episode: 71/100 RapTime: 0:00:58.658089 FixedProfit: 1220147\n",
            "Episode: 72/100 RapTime: 0:00:56.979665 FixedProfit: 1110526\n",
            "Episode: 73/100 RapTime: 0:00:56.509794 FixedProfit: 1132355\n",
            "Episode: 74/100 RapTime: 0:00:56.482275 FixedProfit: 1055428\n",
            "Episode: 75/100 RapTime: 0:00:56.092109 FixedProfit: 1074169\n",
            "Episode: 76/100 RapTime: 0:00:56.312515 FixedProfit: 1326209\n",
            "Episode: 77/100 RapTime: 0:00:55.826659 FixedProfit: 984929\n",
            "Episode: 78/100 RapTime: 0:00:56.490730 FixedProfit: 1052655\n",
            "Episode: 79/100 RapTime: 0:00:56.220634 FixedProfit: 1351584\n",
            "Episode: 80/100 RapTime: 0:00:56.230025 FixedProfit: 1015630\n",
            "Episode: 81/100 RapTime: 0:00:56.443375 FixedProfit: 1098352\n",
            "Episode: 82/100 RapTime: 0:00:56.263387 FixedProfit: 1018230\n",
            "Episode: 83/100 RapTime: 0:00:56.452096 FixedProfit: 1074259\n",
            "Episode: 84/100 RapTime: 0:00:56.363495 FixedProfit: 1034541\n",
            "Episode: 85/100 RapTime: 0:00:55.977198 FixedProfit: 1037156\n",
            "Episode: 86/100 RapTime: 0:00:56.279112 FixedProfit: 1021864\n",
            "Episode: 87/100 RapTime: 0:00:56.060892 FixedProfit: 1107971\n",
            "Episode: 88/100 RapTime: 0:00:56.071145 FixedProfit: 985826\n",
            "Episode: 89/100 RapTime: 0:00:56.543034 FixedProfit: 1024826\n",
            "Episode: 90/100 RapTime: 0:00:56.483873 FixedProfit: 1096726\n",
            "Episode: 91/100 RapTime: 0:00:56.357732 FixedProfit: 1008217\n",
            "Episode: 92/100 RapTime: 0:00:56.092763 FixedProfit: 1016978\n",
            "Episode: 93/100 RapTime: 0:00:56.265138 FixedProfit: 1202222\n",
            "Episode: 94/100 RapTime: 0:00:56.105023 FixedProfit: 999363\n",
            "Episode: 95/100 RapTime: 0:00:56.955960 FixedProfit: 1131885\n",
            "Episode: 96/100 RapTime: 0:00:57.978816 FixedProfit: 1163233\n",
            "Episode: 97/100 RapTime: 0:00:58.478771 FixedProfit: 1100745\n",
            "Episode: 98/100 RapTime: 0:00:56.446451 FixedProfit: 1058666\n",
            "Episode: 99/100 RapTime: 0:00:56.499989 FixedProfit: 1161073\n",
            "Episode: 100/100 RapTime: 0:00:56.682410 FixedProfit: 1255428\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}