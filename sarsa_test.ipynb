{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOr7f1p3Z6dGC5aGwfOf1I/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/sarsa_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "fa641011-6f96-43a1-e24f-91f3e4b0513e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_test.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'sarsa_test.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, next_act, done):\n",
        "        q = self.model.predict(state)\n",
        "        #next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*next_act\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state, act, reward, info, next_state, done, mode = 'train'):\n",
        "\n",
        "        next_act = self._next_act(state)\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.brain.train(state, act, reward, next_state, next_act, done)\n",
        "\n",
        "        return next_act\n",
        "\n",
        "    def _next_act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "        reward = 0.0\n",
        "        info = None\n",
        "        next_state = copy.copy(state)\n",
        "        next_act = 1\n",
        "        act = 1\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state, act, reward, info, next_state, done, mode)\n",
        "            state = next_state\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "            act = copy.copy(action)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "5a9c8b2b-c456-444f-f7be-cd80808cf25b"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'test'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_sarsa.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_sarsa.h5')\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:36.555326 FixedProfit: 1029020 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 2/100 RapTime: 0:00:35.180330 FixedProfit: 1019034 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 3/100 RapTime: 0:00:35.292036 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 4/100 RapTime: 0:00:35.271489 FixedProfit: 999001 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 5/100 RapTime: 0:00:35.551816 FixedProfit: 1000865 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 6/100 RapTime: 0:00:35.479391 FixedProfit: 1020076 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 7/100 RapTime: 0:00:35.297044 FixedProfit: 1036817 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 8/100 RapTime: 0:00:35.467691 FixedProfit: 1016271 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 9/100 RapTime: 0:00:35.423900 FixedProfit: 1003920 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 10/100 RapTime: 0:00:35.304689 FixedProfit: 1006207 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 11/100 RapTime: 0:00:35.676717 FixedProfit: 950115 TradeTimes: 4 TradeWin: 0\n",
            "Episode: 12/100 RapTime: 0:00:35.398399 FixedProfit: 1004765 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 13/100 RapTime: 0:00:35.662020 FixedProfit: 1025743 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 14/100 RapTime: 0:00:35.203520 FixedProfit: 1011248 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 15/100 RapTime: 0:00:35.322834 FixedProfit: 1026208 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 16/100 RapTime: 0:00:35.589782 FixedProfit: 980379 TradeTimes: 4 TradeWin: 0\n",
            "Episode: 17/100 RapTime: 0:00:35.321297 FixedProfit: 987987 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 18/100 RapTime: 0:00:35.576275 FixedProfit: 981041 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 19/100 RapTime: 0:00:35.124367 FixedProfit: 1002032 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 20/100 RapTime: 0:00:35.582090 FixedProfit: 1015692 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 21/100 RapTime: 0:00:35.333762 FixedProfit: 987746 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 22/100 RapTime: 0:00:35.029661 FixedProfit: 1010709 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 23/100 RapTime: 0:00:35.492661 FixedProfit: 1012980 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 24/100 RapTime: 0:00:35.139318 FixedProfit: 1022708 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 25/100 RapTime: 0:00:35.607580 FixedProfit: 1001737 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 26/100 RapTime: 0:00:35.180401 FixedProfit: 998769 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 27/100 RapTime: 0:00:35.346698 FixedProfit: 1021083 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 28/100 RapTime: 0:00:35.184755 FixedProfit: 998250 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 29/100 RapTime: 0:00:35.273507 FixedProfit: 1017921 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 30/100 RapTime: 0:00:35.551439 FixedProfit: 1048948 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 31/100 RapTime: 0:00:35.440041 FixedProfit: 989505 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 32/100 RapTime: 0:00:35.261661 FixedProfit: 1007507 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 33/100 RapTime: 0:00:35.151626 FixedProfit: 897047 TradeTimes: 9 TradeWin: 5\n",
            "Episode: 34/100 RapTime: 0:00:35.387580 FixedProfit: 1027380 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 35/100 RapTime: 0:00:35.080343 FixedProfit: 997307 TradeTimes: 7 TradeWin: 3\n",
            "Episode: 36/100 RapTime: 0:00:35.363488 FixedProfit: 1009171 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:00:35.542128 FixedProfit: 1024966 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 38/100 RapTime: 0:00:35.449055 FixedProfit: 1007067 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 39/100 RapTime: 0:00:35.200841 FixedProfit: 1009540 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 40/100 RapTime: 0:00:35.316012 FixedProfit: 990248 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 41/100 RapTime: 0:00:35.296295 FixedProfit: 1037965 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 42/100 RapTime: 0:00:35.384721 FixedProfit: 1010283 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 43/100 RapTime: 0:00:35.306713 FixedProfit: 1028005 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 44/100 RapTime: 0:00:35.230621 FixedProfit: 1018372 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 45/100 RapTime: 0:00:35.061411 FixedProfit: 964680 TradeTimes: 4 TradeWin: 0\n",
            "Episode: 46/100 RapTime: 0:00:35.334610 FixedProfit: 991360 TradeTimes: 8 TradeWin: 4\n",
            "Episode: 47/100 RapTime: 0:00:35.390778 FixedProfit: 989562 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 48/100 RapTime: 0:00:35.589289 FixedProfit: 1006383 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 49/100 RapTime: 0:00:35.199004 FixedProfit: 1013298 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 50/100 RapTime: 0:00:35.371130 FixedProfit: 1001660 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 51/100 RapTime: 0:00:35.342951 FixedProfit: 1010543 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 52/100 RapTime: 0:00:35.465685 FixedProfit: 999879 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 53/100 RapTime: 0:00:35.525629 FixedProfit: 1008002 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 54/100 RapTime: 0:00:35.717761 FixedProfit: 1003962 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 55/100 RapTime: 0:00:35.506400 FixedProfit: 1001127 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 56/100 RapTime: 0:00:35.068370 FixedProfit: 1005935 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 57/100 RapTime: 0:00:35.422275 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 58/100 RapTime: 0:00:35.745387 FixedProfit: 1046778 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 59/100 RapTime: 0:00:35.334278 FixedProfit: 1003737 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 60/100 RapTime: 0:00:35.498242 FixedProfit: 997806 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 61/100 RapTime: 0:00:35.312267 FixedProfit: 909347 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 62/100 RapTime: 0:00:35.343072 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 63/100 RapTime: 0:00:35.266901 FixedProfit: 1015260 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 64/100 RapTime: 0:00:35.324523 FixedProfit: 1001644 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 65/100 RapTime: 0:00:35.165558 FixedProfit: 1003581 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 66/100 RapTime: 0:00:35.171139 FixedProfit: 992503 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 67/100 RapTime: 0:00:35.481107 FixedProfit: 1005945 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 68/100 RapTime: 0:00:35.479533 FixedProfit: 989498 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 69/100 RapTime: 0:00:35.819729 FixedProfit: 1017760 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 70/100 RapTime: 0:00:35.509934 FixedProfit: 998915 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 71/100 RapTime: 0:00:35.467630 FixedProfit: 1017217 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 72/100 RapTime: 0:00:35.160470 FixedProfit: 973855 TradeTimes: 7 TradeWin: 4\n",
            "Episode: 73/100 RapTime: 0:00:35.223242 FixedProfit: 996137 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 74/100 RapTime: 0:00:35.389185 FixedProfit: 993635 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 75/100 RapTime: 0:00:35.395364 FixedProfit: 1009707 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 76/100 RapTime: 0:00:34.986791 FixedProfit: 992730 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 77/100 RapTime: 0:00:35.513033 FixedProfit: 999993 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 78/100 RapTime: 0:00:35.440560 FixedProfit: 1020035 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 79/100 RapTime: 0:00:35.440076 FixedProfit: 1001444 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 80/100 RapTime: 0:00:35.418071 FixedProfit: 1218419 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 81/100 RapTime: 0:00:35.139660 FixedProfit: 1017819 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 82/100 RapTime: 0:00:35.557541 FixedProfit: 1014196 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 83/100 RapTime: 0:00:35.362328 FixedProfit: 986515 TradeTimes: 6 TradeWin: 2\n",
            "Episode: 84/100 RapTime: 0:00:35.523782 FixedProfit: 998315 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 85/100 RapTime: 0:00:35.489785 FixedProfit: 1008881 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 86/100 RapTime: 0:00:35.401484 FixedProfit: 999459 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 87/100 RapTime: 0:00:35.181869 FixedProfit: 981854 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 88/100 RapTime: 0:00:36.022103 FixedProfit: 998982 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 89/100 RapTime: 0:00:36.265457 FixedProfit: 1015093 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 90/100 RapTime: 0:00:35.932797 FixedProfit: 1007998 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 91/100 RapTime: 0:00:35.202753 FixedProfit: 992679 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 92/100 RapTime: 0:00:35.178290 FixedProfit: 1025118 TradeTimes: 7 TradeWin: 3\n",
            "Episode: 93/100 RapTime: 0:00:35.272201 FixedProfit: 1013451 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 94/100 RapTime: 0:00:35.498474 FixedProfit: 1059942 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 95/100 RapTime: 0:00:35.465078 FixedProfit: 1005616 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 96/100 RapTime: 0:00:35.173581 FixedProfit: 1012871 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 97/100 RapTime: 0:00:35.193699 FixedProfit: 991226 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 98/100 RapTime: 0:00:35.425748 FixedProfit: 988540 TradeTimes: 8 TradeWin: 3\n",
            "Episode: 99/100 RapTime: 0:00:35.370167 FixedProfit: 1191334 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 100/100 RapTime: 0:00:35.564255 FixedProfit: 1011266 TradeTimes: 2 TradeWin: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}