{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gorila_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNUvSzYwVSXM48AhWIdVTY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/gorila_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "2eb5878c-f32c-4c8a-dc67-78e08aa9bb2b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "mode = 'train'\n",
        "name = 'gorila'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=1000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self):\n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "        else:\n",
        "            if self.action_space[0] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1 \n",
        "            if self.action_space[2] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U1RNmtkaZ2W"
      },
      "source": [
        "class ParameterServer:\n",
        "    def __init__(self):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        mastermodel = Sequential()\n",
        "        mastermodel.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_mid))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_action))\n",
        "        mastermodel.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((mastermodel.summary()))\n",
        "        self.mastermodel = mastermodel\n",
        "    \n",
        "    def load(self, name):\n",
        "        self.mastermodel.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.mastermodel.save_weights(name)\n",
        "\n",
        "    def placement(self, model):\n",
        "        for m, mm in zip(model.trainable_weights, self.mastermodel.trainable_weights):\n",
        "            m.assign(mm)\n",
        "\n",
        "    def integration(self, model):\n",
        "        for mm, m in zip(self.mastermodel.trainable_weights, model.trainable_weights):\n",
        "            mm.assign(m)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, masterbrain):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        Brain.model = model\n",
        "        Brain.masterbrain = masterbrain\n",
        "\n",
        "    def load(self, name):\n",
        "        Brain.mastermodel.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        Brain.mastermodel.save(name)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return Brain.model.predict(state)\n",
        "\n",
        "    def train_on_batch(self, state, target_full):\n",
        "        Brain.model.train_on_batch(state, target_full)\n",
        "\n",
        "    def layering(self):\n",
        "        Brain.masterbrain.placement(Brain.model)\n",
        "\n",
        "    def integration(self):\n",
        "        Brain.masterbrain.integration(Brain.model)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1_BMH7hLQ8"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size, batch_size=32):\n",
        "\n",
        "        ReplayMemory.cntr = 0\n",
        "        ReplayMemory.size = 0\n",
        "        ReplayMemory.max_size = max_size\n",
        "        ReplayMemory.batch_size = batch_size\n",
        "        ReplayMemory.states_memory = np.zeros([ReplayMemory.max_size, 3], dtype=np.float32)\n",
        "        ReplayMemory.next_states_memory = np.zeros([ReplayMemory.max_size, 3], dtype=np.float32)\n",
        "        ReplayMemory.acts_memory = np.zeros(ReplayMemory.max_size, dtype=np.uint8)\n",
        "        ReplayMemory.rewards_memory = np.zeros(ReplayMemory.max_size, dtype=np.float32)\n",
        "        ReplayMemory.done_memory = np.zeros(ReplayMemory.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        ReplayMemory.states_memory[ReplayMemory.cntr] = state\n",
        "        ReplayMemory.next_states_memory[ReplayMemory.cntr] = next_state\n",
        "        ReplayMemory.acts_memory[ReplayMemory.cntr] = act\n",
        "        ReplayMemory.rewards_memory[ReplayMemory.cntr] = reward\n",
        "        ReplayMemory.done_memory[ReplayMemory.cntr] = done\n",
        "        ReplayMemory.cntr = (ReplayMemory.cntr+1) % ReplayMemory.max_size\n",
        "        ReplayMemory.size = min(ReplayMemory.size+1, ReplayMemory.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(ReplayMemory.size, ReplayMemory.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [ReplayMemory.states_memory[mb_index],ReplayMemory.next_states_memory[mb_index],\n",
        "                 ReplayMemory.acts_memory[mb_index],ReplayMemory.rewards_memory[mb_index],\n",
        "                 ReplayMemory.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrEa4wpGG1DF"
      },
      "source": [
        "class Actor(Brain, ReplayMemory):\n",
        "    def __init__(self, masterbrain, max_size, batch_size = 32):\n",
        "\n",
        "        Brain.__init__(self, masterbrain)\n",
        "        ReplayMemory.__init__(self, max_size, batch_size)\n",
        "        self.epsilon = 1.0\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42NIN-PGBOc8"
      },
      "source": [
        "class Learner(Brain, ReplayMemory):\n",
        "    def __init__(self, batch_size = 32):\n",
        "\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learn(self):\n",
        "        if ReplayMemory.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.predict(next_states), axis=1)\n",
        "\n",
        "        target_full = self.predict(states)\n",
        "\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.train_on_batch(states, target_full)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, actor, learner, num, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.actor = actor\n",
        "        self.learner = learner\n",
        "        self.num = str(num)\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.actor.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "        self.actor.layering()\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.actor.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.actor.store_transition(state, action, reward, next_state, done)\n",
        "                    self.learner.learn()\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                learner.integration()\n",
        "                actor.layering()\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save_scaler()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.actor.load('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.actor.save('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "eef86d4c-1ce9-4eda-ea02-260a61244abf"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 50\n",
        "batch_size = 32\n",
        "max_size = 500\n",
        "\n",
        "masterbrain = ParameterServer()\n",
        "\n",
        "thread_num = 4\n",
        "envs = []\n",
        "for i in range(thread_num):\n",
        "    env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "    actor = Actor(masterbrain, max_size, batch_size)\n",
        "    learner = Learner(batch_size)\n",
        "    main = Main(env, actor, learner, i, mdl_dir, name, episodes_times, mode)\n",
        "    envs.append(main)\n",
        "\n",
        "datas = []\n",
        "with ThreadPoolExecutor(max_workers=thread_num) as executor:\n",
        "    for env in envs:\n",
        "        job = lambda: env.play_game()\n",
        "        datas.append(executor.submit(job))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/50 RapTime: 0:02:59.520308 FixedProfit: 1138214\n",
            "Episode: 1/50 RapTime: 0:03:08.535179 FixedProfit: 1083302\n",
            "Episode: 1/50 RapTime: 0:03:09.763828 FixedProfit: 1068071\n",
            "Episode: 1/50 RapTime: 0:03:10.390625 FixedProfit: 995329\n",
            "Episode: 2/50 RapTime: 0:03:08.954042 FixedProfit: 1009165\n",
            "Episode: 2/50 RapTime: 0:03:11.450844 FixedProfit: 964614\n",
            "Episode: 2/50 RapTime: 0:03:12.664699 FixedProfit: 1198761\n",
            "Episode: 2/50 RapTime: 0:03:11.108179 FixedProfit: 1250482\n",
            "Episode: 3/50 RapTime: 0:03:12.372680 FixedProfit: 987218\n",
            "Episode: 3/50 RapTime: 0:03:11.099339 FixedProfit: 1218280\n",
            "Episode: 3/50 RapTime: 0:03:10.801313 FixedProfit: 1109053\n",
            "Episode: 3/50 RapTime: 0:03:13.473286 FixedProfit: 1327670\n",
            "Episode: 4/50 RapTime: 0:03:14.105448 FixedProfit: 1047224\n",
            "Episode: 4/50 RapTime: 0:03:11.830805 FixedProfit: 1026006\n",
            "Episode: 4/50 RapTime: 0:03:14.440105 FixedProfit: 1170409\n",
            "Episode: 4/50 RapTime: 0:03:16.805691 FixedProfit: 1278124\n",
            "Episode: 5/50 RapTime: 0:03:14.547223 FixedProfit: 977693\n",
            "Episode: 5/50 RapTime: 0:03:12.046375 FixedProfit: 905381\n",
            "Episode: 5/50 RapTime: 0:03:17.762253 FixedProfit: 1024584\n",
            "Episode: 5/50 RapTime: 0:03:18.201209 FixedProfit: 963133\n",
            "Episode: 6/50 RapTime: 0:03:18.545064 FixedProfit: 990392\n",
            "Episode: 6/50 RapTime: 0:03:17.555769 FixedProfit: 1077392\n",
            "Episode: 6/50 RapTime: 0:03:14.935791 FixedProfit: 1005807\n",
            "Episode: 6/50 RapTime: 0:03:15.711034 FixedProfit: 1007856\n",
            "Episode: 7/50 RapTime: 0:03:16.728526 FixedProfit: 966239\n",
            "Episode: 7/50 RapTime: 0:03:16.075508 FixedProfit: 1025735\n",
            "Episode: 7/50 RapTime: 0:03:19.176241 FixedProfit: 982532\n",
            "Episode: 7/50 RapTime: 0:03:19.068406 FixedProfit: 1204499\n",
            "Episode: 8/50 RapTime: 0:03:17.849435 FixedProfit: 1175470\n",
            "Episode: 8/50 RapTime: 0:03:17.907528 FixedProfit: 1236572\n",
            "Episode: 8/50 RapTime: 0:03:19.258237 FixedProfit: 1246144\n",
            "Episode: 8/50 RapTime: 0:03:18.327119 FixedProfit: 1115726\n",
            "Episode: 9/50 RapTime: 0:03:24.511237 FixedProfit: 1102405\n",
            "Episode: 9/50 RapTime: 0:03:26.341105 FixedProfit: 1152025\n",
            "Episode: 9/50 RapTime: 0:03:26.190089 FixedProfit: 1227575\n",
            "Episode: 9/50 RapTime: 0:03:25.608059 FixedProfit: 963702\n",
            "Episode: 10/50 RapTime: 0:03:24.823217 FixedProfit: 1307246\n",
            "Episode: 10/50 RapTime: 0:03:28.719936 FixedProfit: 998337\n",
            "Episode: 10/50 RapTime: 0:03:27.146060 FixedProfit: 1214081\n",
            "Episode: 10/50 RapTime: 0:03:24.853888 FixedProfit: 960347\n",
            "Episode: 11/50 RapTime: 0:03:29.655132 FixedProfit: 1074344\n",
            "Episode: 11/50 RapTime: 0:03:29.832562 FixedProfit: 1062100\n",
            "Episode: 11/50 RapTime: 0:03:25.432011 FixedProfit: 1180749\n",
            "Episode: 11/50 RapTime: 0:03:29.172990 FixedProfit: 959088\n",
            "Episode: 12/50 RapTime: 0:03:27.198808 FixedProfit: 1006618\n",
            "Episode: 12/50 RapTime: 0:03:27.700459 FixedProfit: 1136854\n",
            "Episode: 12/50 RapTime: 0:03:30.103550 FixedProfit: 998710\n",
            "Episode: 12/50 RapTime: 0:03:31.226379 FixedProfit: 1009137\n",
            "Episode: 13/50 RapTime: 0:03:30.655321 FixedProfit: 1120851\n",
            "Episode: 13/50 RapTime: 0:03:29.063522 FixedProfit: 1176324\n",
            "Episode: 13/50 RapTime: 0:03:38.860296 FixedProfit: 967099\n",
            "Episode: 13/50 RapTime: 0:03:32.226595 FixedProfit: 1175329\n",
            "Episode: 14/50 RapTime: 0:03:33.194593 FixedProfit: 1352907\n",
            "Episode: 14/50 RapTime: 0:03:33.819410 FixedProfit: 965976\n",
            "Episode: 14/50 RapTime: 0:03:33.633672 FixedProfit: 1112396\n",
            "Episode: 14/50 RapTime: 0:03:34.941182 FixedProfit: 964650\n",
            "Episode: 15/50 RapTime: 0:03:33.185651 FixedProfit: 1028862\n",
            "Episode: 15/50 RapTime: 0:03:32.000043 FixedProfit: 1070242\n",
            "Episode: 15/50 RapTime: 0:03:37.890999 FixedProfit: 910465\n",
            "Episode: 15/50 RapTime: 0:03:37.798474 FixedProfit: 1106921\n",
            "Episode: 16/50 RapTime: 0:03:35.963980 FixedProfit: 1415352\n",
            "Episode: 16/50 RapTime: 0:03:35.181498 FixedProfit: 1012550\n",
            "Episode: 16/50 RapTime: 0:03:39.200340 FixedProfit: 1176708\n",
            "Episode: 16/50 RapTime: 0:03:36.368235 FixedProfit: 1025837\n",
            "Episode: 17/50 RapTime: 0:03:36.403979 FixedProfit: 1164900\n",
            "Episode: 17/50 RapTime: 0:03:36.944604 FixedProfit: 1048167\n",
            "Episode: 17/50 RapTime: 0:03:41.165825 FixedProfit: 1093574\n",
            "Episode: 17/50 RapTime: 0:03:37.922282 FixedProfit: 925162\n",
            "Episode: 18/50 RapTime: 0:03:41.628738 FixedProfit: 1043757\n",
            "Episode: 18/50 RapTime: 0:03:37.556930 FixedProfit: 1164754\n",
            "Episode: 18/50 RapTime: 0:03:40.235890 FixedProfit: 1129396\n",
            "Episode: 18/50 RapTime: 0:03:37.403528 FixedProfit: 1039943\n",
            "Episode: 19/50 RapTime: 0:03:41.426167 FixedProfit: 1111328\n",
            "Episode: 19/50 RapTime: 0:03:40.373028 FixedProfit: 947103\n",
            "Episode: 19/50 RapTime: 0:03:40.862685 FixedProfit: 1166779\n",
            "Episode: 19/50 RapTime: 0:03:44.185691 FixedProfit: 1210329\n",
            "Episode: 20/50 RapTime: 0:03:38.151756 FixedProfit: 1082374\n",
            "Episode: 20/50 RapTime: 0:03:31.729698 FixedProfit: 915856\n",
            "Episode: 20/50 RapTime: 0:03:31.952557 FixedProfit: 1026952\n",
            "Episode: 21/50 RapTime: 0:02:40.311249 FixedProfit: 1201086\n",
            "Episode: 21/50 RapTime: 0:02:40.227168 FixedProfit: 1016691\n",
            "Episode: 21/50 RapTime: 0:02:40.378986 FixedProfit: 1127367\n",
            "Episode: 22/50 RapTime: 0:02:39.594217 FixedProfit: 1048091\n",
            "Episode: 22/50 RapTime: 0:02:40.820881 FixedProfit: 1291883\n",
            "Episode: 22/50 RapTime: 0:02:41.753212 FixedProfit: 1019160\n",
            "Episode: 23/50 RapTime: 0:02:40.882979 FixedProfit: 930819\n",
            "Episode: 23/50 RapTime: 0:02:43.671331 FixedProfit: 1071741\n",
            "Episode: 23/50 RapTime: 0:02:41.920922 FixedProfit: 1105405\n",
            "Episode: 24/50 RapTime: 0:02:41.374191 FixedProfit: 1068363\n",
            "Episode: 24/50 RapTime: 0:02:42.674629 FixedProfit: 927266\n",
            "Episode: 24/50 RapTime: 0:02:43.083941 FixedProfit: 1087185\n",
            "Episode: 25/50 RapTime: 0:02:41.490441 FixedProfit: 1205990\n",
            "Episode: 25/50 RapTime: 0:02:43.653751 FixedProfit: 981221\n",
            "Episode: 25/50 RapTime: 0:02:45.086081 FixedProfit: 1289996\n",
            "Episode: 26/50 RapTime: 0:02:47.882331 FixedProfit: 1187037\n",
            "Episode: 26/50 RapTime: 0:02:43.879287 FixedProfit: 1077278\n",
            "Episode: 26/50 RapTime: 0:02:43.834787 FixedProfit: 941421\n",
            "Episode: 27/50 RapTime: 0:02:47.200557 FixedProfit: 1153945\n",
            "Episode: 27/50 RapTime: 0:02:44.955962 FixedProfit: 996259\n",
            "Episode: 27/50 RapTime: 0:02:45.691386 FixedProfit: 985245\n",
            "Episode: 28/50 RapTime: 0:02:47.909314 FixedProfit: 1177474\n",
            "Episode: 28/50 RapTime: 0:02:46.132187 FixedProfit: 1199665\n",
            "Episode: 28/50 RapTime: 0:02:47.149295 FixedProfit: 934167\n",
            "Episode: 29/50 RapTime: 0:02:46.997255 FixedProfit: 1010052\n",
            "Episode: 29/50 RapTime: 0:02:46.881208 FixedProfit: 1168895\n",
            "Episode: 29/50 RapTime: 0:02:48.359647 FixedProfit: 1165377\n",
            "Episode: 30/50 RapTime: 0:02:49.198105 FixedProfit: 997585\n",
            "Episode: 30/50 RapTime: 0:02:51.207601 FixedProfit: 1098859\n",
            "Episode: 30/50 RapTime: 0:02:50.785607 FixedProfit: 1072589\n",
            "Episode: 31/50 RapTime: 0:02:48.870847 FixedProfit: 1148015\n",
            "Episode: 31/50 RapTime: 0:02:50.403998 FixedProfit: 941094\n",
            "Episode: 31/50 RapTime: 0:02:49.914729 FixedProfit: 1275787\n",
            "Episode: 32/50 RapTime: 0:02:52.685211 FixedProfit: 946297\n",
            "Episode: 32/50 RapTime: 0:02:50.264068 FixedProfit: 1185143\n",
            "Episode: 32/50 RapTime: 0:02:54.346177 FixedProfit: 1232084\n",
            "Episode: 33/50 RapTime: 0:02:53.634185 FixedProfit: 1182480\n",
            "Episode: 33/50 RapTime: 0:02:52.890257 FixedProfit: 924541\n",
            "Episode: 33/50 RapTime: 0:02:54.057054 FixedProfit: 1155996\n",
            "Episode: 34/50 RapTime: 0:02:52.514104 FixedProfit: 1284633\n",
            "Episode: 34/50 RapTime: 0:02:54.473255 FixedProfit: 1004618\n",
            "Episode: 34/50 RapTime: 0:02:54.989372 FixedProfit: 1154092\n",
            "Episode: 35/50 RapTime: 0:02:55.114332 FixedProfit: 1027824\n",
            "Episode: 35/50 RapTime: 0:02:55.576161 FixedProfit: 960943\n",
            "Episode: 35/50 RapTime: 0:02:58.341237 FixedProfit: 1080955\n",
            "Episode: 36/50 RapTime: 0:02:56.974030 FixedProfit: 1079759\n",
            "Episode: 36/50 RapTime: 0:02:54.616317 FixedProfit: 1187369\n",
            "Episode: 36/50 RapTime: 0:02:57.941679 FixedProfit: 1131056\n",
            "Episode: 37/50 RapTime: 0:02:57.277766 FixedProfit: 1056614\n",
            "Episode: 37/50 RapTime: 0:02:57.296417 FixedProfit: 1046316\n",
            "Episode: 37/50 RapTime: 0:03:00.858034 FixedProfit: 1278443\n",
            "Episode: 38/50 RapTime: 0:02:58.998068 FixedProfit: 1215476\n",
            "Episode: 38/50 RapTime: 0:02:59.262986 FixedProfit: 894902\n",
            "Episode: 38/50 RapTime: 0:02:57.856868 FixedProfit: 1147193\n",
            "Episode: 39/50 RapTime: 0:03:00.612457 FixedProfit: 1017428\n",
            "Episode: 39/50 RapTime: 0:03:01.109746 FixedProfit: 1145719\n",
            "Episode: 39/50 RapTime: 0:02:59.693161 FixedProfit: 963945\n",
            "Episode: 40/50 RapTime: 0:03:02.783606 FixedProfit: 991696\n",
            "Episode: 40/50 RapTime: 0:03:04.675347 FixedProfit: 1132040\n",
            "Episode: 40/50 RapTime: 0:03:00.623535 FixedProfit: 963573\n",
            "Episode: 41/50 RapTime: 0:03:01.933385 FixedProfit: 1003800\n",
            "Episode: 41/50 RapTime: 0:03:01.916717 FixedProfit: 1179079\n",
            "Episode: 41/50 RapTime: 0:03:02.953789 FixedProfit: 1018351\n",
            "Episode: 42/50 RapTime: 0:03:04.880576 FixedProfit: 927343\n",
            "Episode: 42/50 RapTime: 0:03:03.408543 FixedProfit: 1091446\n",
            "Episode: 42/50 RapTime: 0:03:05.386921 FixedProfit: 1083859\n",
            "Episode: 43/50 RapTime: 0:03:04.573134 FixedProfit: 1042961\n",
            "Episode: 43/50 RapTime: 0:03:04.609042 FixedProfit: 1079601\n",
            "Episode: 43/50 RapTime: 0:03:06.108296 FixedProfit: 1074298\n",
            "Episode: 44/50 RapTime: 0:02:58.876157 FixedProfit: 1327151\n",
            "Episode: 44/50 RapTime: 0:03:02.582048 FixedProfit: 1136747\n",
            "Episode: 44/50 RapTime: 0:03:01.646629 FixedProfit: 1135415\n",
            "Episode: 45/50 RapTime: 0:03:03.005989 FixedProfit: 1138895\n",
            "Episode: 45/50 RapTime: 0:03:02.483503 FixedProfit: 1113520\n",
            "Episode: 45/50 RapTime: 0:03:00.841034 FixedProfit: 1247398\n",
            "Episode: 46/50 RapTime: 0:03:02.416214 FixedProfit: 1055126\n",
            "Episode: 46/50 RapTime: 0:03:03.190312 FixedProfit: 1050612\n",
            "Episode: 46/50 RapTime: 0:03:02.100084 FixedProfit: 1002991\n",
            "Episode: 47/50 RapTime: 0:03:04.116264 FixedProfit: 1143267\n",
            "Episode: 47/50 RapTime: 0:03:07.180516 FixedProfit: 1157459\n",
            "Episode: 47/50 RapTime: 0:03:03.849639 FixedProfit: 995802\n",
            "Episode: 48/50 RapTime: 0:03:03.691598 FixedProfit: 1073858\n",
            "Episode: 48/50 RapTime: 0:03:09.266302 FixedProfit: 1096095\n",
            "Episode: 48/50 RapTime: 0:03:06.922205 FixedProfit: 1236747\n",
            "Episode: 49/50 RapTime: 0:03:09.022664 FixedProfit: 1097851\n",
            "Episode: 49/50 RapTime: 0:03:10.031863 FixedProfit: 1253408\n",
            "Episode: 49/50 RapTime: 0:03:10.334133 FixedProfit: 997885\n",
            "Episode: 50/50 RapTime: 0:03:09.188686 FixedProfit: 1031335\n",
            "Episode: 50/50 RapTime: 0:03:00.358121 FixedProfit: 1176728\n",
            "Episode: 50/50 RapTime: 0:02:57.105221 FixedProfit: 1164348\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}