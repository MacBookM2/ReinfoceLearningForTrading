{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gorila_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPwrTAUwtx2lgtYymAr+xgK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/gorila_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "4f158eb2-69c5-490d-ad15-46f36fde8941"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_train.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'gorila_train.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=1000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self):\n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "        else:\n",
        "            if self.action_space[0] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1 \n",
        "            if self.action_space[2] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U1RNmtkaZ2W"
      },
      "source": [
        "class ParameterServer:\n",
        "    def __init__(self):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        mastermodel = Sequential()\n",
        "        mastermodel.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_mid))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_action))\n",
        "        mastermodel.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((mastermodel.summary()))\n",
        "        self.mastermodel = mastermodel\n",
        "    \n",
        "    def load(self, name):\n",
        "        self.mastermodel.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.mastermodel.save_weights(name)\n",
        "\n",
        "    def placement(self, model):\n",
        "        for m, mm in zip(model.trainable_weights, self.mastermodel.trainable_weights):\n",
        "            m.assign(mm)\n",
        "\n",
        "    def integration(self, model):\n",
        "        for mm, m in zip(self.mastermodel.trainable_weights, model.trainable_weights):\n",
        "            mm.assign(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, masterbrain):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "        self.masterbrain = masterbrain\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def train_on_batch(self, state, target_full):\n",
        "        self.model.train_on_batch(state, target_full)\n",
        "\n",
        "    def layering(self):\n",
        "        self.masterbrain.placement(self.model)\n",
        "\n",
        "    def integration(self):\n",
        "        self.masterbrain.integration(self.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULBV5XpsbOjq"
      },
      "source": [
        "def make_scaler(env):\n",
        "\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Actor:\n",
        "    def __init__(self, brain, memory):\n",
        "\n",
        "        self.brain = brain\n",
        "        self.memory = memory\n",
        "        self.epsilon = 1.0\n",
        "  \n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        self.memory.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.brain.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def layering(self):\n",
        "        self.brain.layering()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1_BMH7hLQ8"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size, batch_size=32):\n",
        "\n",
        "        self.cntr = 0\n",
        "        self.size = 0\n",
        "        self.max_size = max_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.next_states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.acts_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "        self.rewards_memory = np.zeros(self.max_size, dtype=np.float32)\n",
        "        self.done_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        self.states_memory[self.cntr] = state\n",
        "        self.next_states_memory[self.cntr] = next_state\n",
        "        self.acts_memory[self.cntr] = act\n",
        "        self.rewards_memory[self.cntr] = reward\n",
        "        self.done_memory[self.cntr] = done\n",
        "        self.cntr = (self.cntr+1) % self.max_size\n",
        "        self.size = min(self.size+1, self.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(self.size, self.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [self.states_memory[mb_index],self.next_states_memory[mb_index],self.acts_memory[mb_index],self.rewards_memory[mb_index],self.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42NIN-PGBOc8"
      },
      "source": [
        "class Learner:\n",
        "    def __init__(self, brain, memory, batch_size=32):\n",
        "\n",
        "        self.brain = brain\n",
        "        self.memory = memory\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learn(self):\n",
        "        if self.memory.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.memory.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.brain.predict(next_states), axis=1)\n",
        "\n",
        "        target_full = self.brain.predict(states)\n",
        "\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.brain.train_on_batch(states, target_full)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "\n",
        "    def integration(self):\n",
        "        self.brain.integration()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, actor, learner, scaler, episodes_times = 25, mode = 'test'):\n",
        "\n",
        "    actor.layering()\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "       \n",
        "        while not done:\n",
        "            action = actor.act(state)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "\n",
        "            if mode == 'train':\n",
        "                actor.store_transition(state, action, reward, next_state, done)\n",
        "                learner.learn()\n",
        "\n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            with open(csv_path, 'a') as f:\n",
        "                row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            learner.integration()\n",
        "            actor.layering()\n",
        "            print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "            with open(csv_path, 'a') as f:\n",
        "                row = str(info['cur_revenue'])\n",
        "                print(row, file=f)\n",
        "        \n",
        "        state = next_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "5dbe9770-3b47-4b51-d7d9-1e80e990d21a"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 50\n",
        "batch_size = 32\n",
        "mode = 'train'\n",
        "max_size = 500\n",
        "\n",
        "masterbrain = ParameterServer()\n",
        "\n",
        "if mode == 'test':\n",
        "    masterbrain.load(f'{models_folder}/gorila_model.h5')\n",
        "\n",
        "    with open(csv_path, 'w') as f:\n",
        "        row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "        print(row, file=f)\n",
        "else:\n",
        "    with open(csv_path, 'w') as f:\n",
        "        row = 'FixedProfit'\n",
        "        print(row, file=f)\n",
        "\n",
        "thread_num = 4\n",
        "envs = []\n",
        "for i in range(thread_num):\n",
        "    e = Environment(df, initial_money=initial_money, mode = mode)\n",
        "    brain = Brain(masterbrain)\n",
        "    model = brain.model\n",
        "    memory = ReplayMemory(max_size, batch_size)\n",
        "    a = Actor(brain, memory)\n",
        "    l = Learner(brain, memory, batch_size)\n",
        "    if mode == 'test':\n",
        "        a.epsilon = 0.01\n",
        "    s = make_scaler(e)\n",
        "    arr = [e,a,l,s]\n",
        "    envs.append(arr)\n",
        "\n",
        "datas = []\n",
        "with ThreadPoolExecutor(max_workers=thread_num) as executor:\n",
        "    for env in envs:\n",
        "        job = lambda: play_game(env[0], env[1], env[2], env[3], episodes_times, mode)\n",
        "        datas.append(executor.submit(job))\n",
        "\n",
        "if mode == 'train':\n",
        "    masterbrain.save(f'{models_folder}/gorila_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/50 RapTime: 0:03:00.670709 FixedProfit: 903324\n",
            "Episode: 1/50 RapTime: 0:03:01.407496 FixedProfit: 1323409\n",
            "Episode: 1/50 RapTime: 0:03:02.168119 FixedProfit: 1094085\n",
            "Episode: 1/50 RapTime: 0:03:03.624802 FixedProfit: 1160537\n",
            "Episode: 2/50 RapTime: 0:03:11.143463 FixedProfit: 1062951\n",
            "Episode: 2/50 RapTime: 0:03:10.441134 FixedProfit: 1004338\n",
            "Episode: 2/50 RapTime: 0:03:10.732302 FixedProfit: 1263147\n",
            "Episode: 2/50 RapTime: 0:03:09.395704 FixedProfit: 976652\n",
            "Episode: 3/50 RapTime: 0:03:08.464437 FixedProfit: 982691\n",
            "Episode: 3/50 RapTime: 0:03:12.263099 FixedProfit: 1067840\n",
            "Episode: 3/50 RapTime: 0:03:13.530824 FixedProfit: 1004489\n",
            "Episode: 3/50 RapTime: 0:03:13.648565 FixedProfit: 1206909\n",
            "Episode: 4/50 RapTime: 0:03:13.080278 FixedProfit: 1234128\n",
            "Episode: 4/50 RapTime: 0:03:13.562628 FixedProfit: 986726\n",
            "Episode: 4/50 RapTime: 0:03:11.191875 FixedProfit: 988528\n",
            "Episode: 4/50 RapTime: 0:03:14.793490 FixedProfit: 1072617\n",
            "Episode: 5/50 RapTime: 0:03:14.697179 FixedProfit: 1242381\n",
            "Episode: 5/50 RapTime: 0:03:12.024264 FixedProfit: 1086083\n",
            "Episode: 5/50 RapTime: 0:03:13.066010 FixedProfit: 901264\n",
            "Episode: 5/50 RapTime: 0:03:17.550389 FixedProfit: 1126265\n",
            "Episode: 6/50 RapTime: 0:03:12.693469 FixedProfit: 1074414\n",
            "Episode: 6/50 RapTime: 0:03:14.693164 FixedProfit: 1124047\n",
            "Episode: 6/50 RapTime: 0:03:19.929319 FixedProfit: 1206591\n",
            "Episode: 6/50 RapTime: 0:03:15.032657 FixedProfit: 1324411\n",
            "Episode: 7/50 RapTime: 0:03:17.710863 FixedProfit: 1197964\n",
            "Episode: 7/50 RapTime: 0:03:19.518338 FixedProfit: 1153210\n",
            "Episode: 7/50 RapTime: 0:03:21.042542 FixedProfit: 1265124\n",
            "Episode: 7/50 RapTime: 0:03:23.168770 FixedProfit: 1245584\n",
            "Episode: 8/50 RapTime: 0:03:17.569823 FixedProfit: 1136128\n",
            "Episode: 8/50 RapTime: 0:03:21.460479 FixedProfit: 1000108\n",
            "Episode: 8/50 RapTime: 0:03:22.020719 FixedProfit: 1167636\n",
            "Episode: 8/50 RapTime: 0:03:21.682288 FixedProfit: 1115316\n",
            "Episode: 9/50 RapTime: 0:03:19.964757 FixedProfit: 1112806\n",
            "Episode: 9/50 RapTime: 0:03:19.481630 FixedProfit: 1025327\n",
            "Episode: 9/50 RapTime: 0:03:21.556093 FixedProfit: 1267426\n",
            "Episode: 9/50 RapTime: 0:03:21.998933 FixedProfit: 1100558\n",
            "Episode: 10/50 RapTime: 0:03:20.420369 FixedProfit: 1159620\n",
            "Episode: 10/50 RapTime: 0:03:23.449582 FixedProfit: 1059602\n",
            "Episode: 10/50 RapTime: 0:03:24.323471 FixedProfit: 964725\n",
            "Episode: 10/50 RapTime: 0:03:21.820264 FixedProfit: 932220\n",
            "Episode: 11/50 RapTime: 0:03:27.708295 FixedProfit: 1126338\n",
            "Episode: 11/50 RapTime: 0:03:22.350050 FixedProfit: 1029211\n",
            "Episode: 11/50 RapTime: 0:03:23.538269 FixedProfit: 1141836\n",
            "Episode: 11/50 RapTime: 0:03:22.694484 FixedProfit: 952875\n",
            "Episode: 12/50 RapTime: 0:03:24.505582 FixedProfit: 1070716\n",
            "Episode: 12/50 RapTime: 0:03:22.586537 FixedProfit: 1054689\n",
            "Episode: 12/50 RapTime: 0:03:27.774071 FixedProfit: 1038722\n",
            "Episode: 12/50 RapTime: 0:03:27.885837 FixedProfit: 1035305\n",
            "Episode: 13/50 RapTime: 0:03:27.182105 FixedProfit: 1136461\n",
            "Episode: 13/50 RapTime: 0:03:28.249767 FixedProfit: 1099409\n",
            "Episode: 13/50 RapTime: 0:03:28.701359 FixedProfit: 1027143\n",
            "Episode: 13/50 RapTime: 0:03:27.825703 FixedProfit: 1046365\n",
            "Episode: 14/50 RapTime: 0:03:30.230129 FixedProfit: 1041121\n",
            "Episode: 14/50 RapTime: 0:03:29.506032 FixedProfit: 886821\n",
            "Episode: 14/50 RapTime: 0:03:28.676122 FixedProfit: 1086552\n",
            "Episode: 14/50 RapTime: 0:03:29.817920 FixedProfit: 1140256\n",
            "Episode: 15/50 RapTime: 0:03:30.362427 FixedProfit: 1000700\n",
            "Episode: 15/50 RapTime: 0:03:31.690008 FixedProfit: 1052414\n",
            "Episode: 15/50 RapTime: 0:03:30.729195 FixedProfit: 1066536\n",
            "Episode: 15/50 RapTime: 0:03:33.431657 FixedProfit: 1122956\n",
            "Episode: 16/50 RapTime: 0:03:31.382273 FixedProfit: 1031745\n",
            "Episode: 16/50 RapTime: 0:03:29.773541 FixedProfit: 1038476\n",
            "Episode: 16/50 RapTime: 0:03:32.121713 FixedProfit: 1300603\n",
            "Episode: 16/50 RapTime: 0:03:36.514211 FixedProfit: 1056323\n",
            "Episode: 17/50 RapTime: 0:03:32.452393 FixedProfit: 1282675\n",
            "Episode: 17/50 RapTime: 0:03:32.760072 FixedProfit: 856915\n",
            "Episode: 17/50 RapTime: 0:03:34.502197 FixedProfit: 1196603\n",
            "Episode: 17/50 RapTime: 0:03:35.088516 FixedProfit: 997530\n",
            "Episode: 18/50 RapTime: 0:03:36.694172 FixedProfit: 1070621\n",
            "Episode: 18/50 RapTime: 0:03:35.765808 FixedProfit: 1033080\n",
            "Episode: 18/50 RapTime: 0:03:43.542970 FixedProfit: 1042256\n",
            "Episode: 18/50 RapTime: 0:03:40.340554 FixedProfit: 1171175\n",
            "Episode: 19/50 RapTime: 0:03:39.800161 FixedProfit: 1019558\n",
            "Episode: 19/50 RapTime: 0:03:42.071234 FixedProfit: 1009039\n",
            "Episode: 19/50 RapTime: 0:03:38.551982 FixedProfit: 973415\n",
            "Episode: 19/50 RapTime: 0:03:41.870476 FixedProfit: 1005077\n",
            "Episode: 20/50 RapTime: 0:03:39.531209 FixedProfit: 1252522\n",
            "Episode: 20/50 RapTime: 0:03:42.426216 FixedProfit: 1272886\n",
            "Episode: 20/50 RapTime: 0:03:40.638390 FixedProfit: 1155365\n",
            "Episode: 20/50 RapTime: 0:03:40.095310 FixedProfit: 1057189\n",
            "Episode: 21/50 RapTime: 0:03:39.666509 FixedProfit: 1107359\n",
            "Episode: 21/50 RapTime: 0:03:41.903410 FixedProfit: 1177604\n",
            "Episode: 21/50 RapTime: 0:03:43.037827 FixedProfit: 943684\n",
            "Episode: 21/50 RapTime: 0:03:39.612982 FixedProfit: 1192820\n",
            "Episode: 22/50 RapTime: 0:03:42.830824 FixedProfit: 990576\n",
            "Episode: 22/50 RapTime: 0:03:40.531818 FixedProfit: 1194662\n",
            "Episode: 22/50 RapTime: 0:03:42.265017 FixedProfit: 1027422\n",
            "Episode: 22/50 RapTime: 0:03:44.148913 FixedProfit: 1329167\n",
            "Episode: 23/50 RapTime: 0:03:37.277488 FixedProfit: 1085850\n",
            "Episode: 23/50 RapTime: 0:03:47.417619 FixedProfit: 1235532\n",
            "Episode: 23/50 RapTime: 0:03:43.723210 FixedProfit: 1080225\n",
            "Episode: 23/50 RapTime: 0:03:44.867195 FixedProfit: 1003056\n",
            "Episode: 24/50 RapTime: 0:03:42.728337 FixedProfit: 1266980\n",
            "Episode: 24/50 RapTime: 0:03:46.756680 FixedProfit: 1363020\n",
            "Episode: 24/50 RapTime: 0:03:42.605877 FixedProfit: 1092941\n",
            "Episode: 24/50 RapTime: 0:03:42.230421 FixedProfit: 930504\n",
            "Episode: 25/50 RapTime: 0:03:45.004069 FixedProfit: 1149167\n",
            "Episode: 25/50 RapTime: 0:03:44.010626 FixedProfit: 1147437\n",
            "Episode: 25/50 RapTime: 0:03:47.797777 FixedProfit: 953140\n",
            "Episode: 25/50 RapTime: 0:03:47.748897 FixedProfit: 1124547\n",
            "Episode: 26/50 RapTime: 0:03:47.369939 FixedProfit: 1099401\n",
            "Episode: 26/50 RapTime: 0:03:45.296591 FixedProfit: 1275899\n",
            "Episode: 26/50 RapTime: 0:03:52.030766 FixedProfit: 1036342\n",
            "Episode: 26/50 RapTime: 0:03:47.782706 FixedProfit: 1213542\n",
            "Episode: 27/50 RapTime: 0:03:45.112808 FixedProfit: 1094828\n",
            "Episode: 27/50 RapTime: 0:03:48.823028 FixedProfit: 1108662\n",
            "Episode: 27/50 RapTime: 0:03:52.126456 FixedProfit: 1112103\n",
            "Episode: 27/50 RapTime: 0:03:48.870685 FixedProfit: 1108642\n",
            "Episode: 28/50 RapTime: 0:03:51.330490 FixedProfit: 964017\n",
            "Episode: 28/50 RapTime: 0:03:53.047600 FixedProfit: 970826\n",
            "Episode: 28/50 RapTime: 0:03:53.373972 FixedProfit: 1127566\n",
            "Episode: 28/50 RapTime: 0:03:53.561588 FixedProfit: 1090293\n",
            "Episode: 29/50 RapTime: 0:03:57.200627 FixedProfit: 1089464\n",
            "Episode: 29/50 RapTime: 0:04:00.666942 FixedProfit: 1110488\n",
            "Episode: 29/50 RapTime: 0:03:55.305595 FixedProfit: 1153831\n",
            "Episode: 29/50 RapTime: 0:03:59.771554 FixedProfit: 1275511\n",
            "Episode: 30/50 RapTime: 0:03:54.343156 FixedProfit: 1052217\n",
            "Episode: 30/50 RapTime: 0:04:01.632502 FixedProfit: 954409\n",
            "Episode: 30/50 RapTime: 0:04:01.021087 FixedProfit: 1113351\n",
            "Episode: 30/50 RapTime: 0:03:58.610313 FixedProfit: 1353891\n",
            "Episode: 31/50 RapTime: 0:03:53.545946 FixedProfit: 1188725\n",
            "Episode: 31/50 RapTime: 0:04:01.058730 FixedProfit: 996261\n",
            "Episode: 31/50 RapTime: 0:03:56.441079 FixedProfit: 1054259\n",
            "Episode: 31/50 RapTime: 0:03:59.814844 FixedProfit: 851927\n",
            "Episode: 32/50 RapTime: 0:03:55.923179 FixedProfit: 998915\n",
            "Episode: 32/50 RapTime: 0:04:07.919814 FixedProfit: 987421\n",
            "Episode: 32/50 RapTime: 0:03:59.662723 FixedProfit: 1172320\n",
            "Episode: 32/50 RapTime: 0:04:01.655666 FixedProfit: 1212058\n",
            "Episode: 33/50 RapTime: 0:04:00.994172 FixedProfit: 1001169\n",
            "Episode: 33/50 RapTime: 0:03:57.290139 FixedProfit: 1168056\n",
            "Episode: 33/50 RapTime: 0:04:02.031619 FixedProfit: 1107342\n",
            "Episode: 33/50 RapTime: 0:04:04.303126 FixedProfit: 1057418\n",
            "Episode: 34/50 RapTime: 0:04:00.762865 FixedProfit: 1256666\n",
            "Episode: 34/50 RapTime: 0:04:00.903436 FixedProfit: 1107329\n",
            "Episode: 34/50 RapTime: 0:04:03.523269 FixedProfit: 910138\n",
            "Episode: 34/50 RapTime: 0:04:02.843889 FixedProfit: 1306108\n",
            "Episode: 35/50 RapTime: 0:04:02.353881 FixedProfit: 1048764\n",
            "Episode: 35/50 RapTime: 0:04:06.408428 FixedProfit: 992694\n",
            "Episode: 35/50 RapTime: 0:04:01.446130 FixedProfit: 1283925\n",
            "Episode: 35/50 RapTime: 0:04:02.892289 FixedProfit: 1086802\n",
            "Episode: 36/50 RapTime: 0:04:07.167692 FixedProfit: 998952\n",
            "Episode: 36/50 RapTime: 0:04:05.556422 FixedProfit: 921747\n",
            "Episode: 36/50 RapTime: 0:04:08.452177 FixedProfit: 1077769\n",
            "Episode: 36/50 RapTime: 0:04:03.481444 FixedProfit: 1062700\n",
            "Episode: 37/50 RapTime: 0:04:05.977303 FixedProfit: 1227908\n",
            "Episode: 37/50 RapTime: 0:04:04.624153 FixedProfit: 1051299\n",
            "Episode: 37/50 RapTime: 0:04:07.416339 FixedProfit: 973797\n",
            "Episode: 37/50 RapTime: 0:04:10.911543 FixedProfit: 1067489\n",
            "Episode: 38/50 RapTime: 0:04:05.500494 FixedProfit: 945498\n",
            "Episode: 38/50 RapTime: 0:04:07.156610 FixedProfit: 1115082\n",
            "Episode: 38/50 RapTime: 0:04:11.576048 FixedProfit: 1002468\n",
            "Episode: 38/50 RapTime: 0:04:11.989106 FixedProfit: 1219435\n",
            "Episode: 39/50 RapTime: 0:04:15.776338 FixedProfit: 841548\n",
            "Episode: 39/50 RapTime: 0:04:10.929561 FixedProfit: 1238988\n",
            "Episode: 39/50 RapTime: 0:04:09.543413 FixedProfit: 923901\n",
            "Episode: 39/50 RapTime: 0:04:11.018851 FixedProfit: 1116146\n",
            "Episode: 40/50 RapTime: 0:04:12.481384 FixedProfit: 1124175\n",
            "Episode: 40/50 RapTime: 0:04:17.026145 FixedProfit: 1219541\n",
            "Episode: 40/50 RapTime: 0:04:09.628446 FixedProfit: 1038157\n",
            "Episode: 40/50 RapTime: 0:04:12.291191 FixedProfit: 1073173\n",
            "Episode: 41/50 RapTime: 0:04:14.779583 FixedProfit: 1080006\n",
            "Episode: 41/50 RapTime: 0:04:20.343885 FixedProfit: 1111833\n",
            "Episode: 41/50 RapTime: 0:04:17.039796 FixedProfit: 1310943\n",
            "Episode: 41/50 RapTime: 0:04:11.870437 FixedProfit: 911691\n",
            "Episode: 42/50 RapTime: 0:04:17.666246 FixedProfit: 1043377\n",
            "Episode: 42/50 RapTime: 0:04:17.173150 FixedProfit: 1148529\n",
            "Episode: 42/50 RapTime: 0:04:18.798156 FixedProfit: 1206470\n",
            "Episode: 42/50 RapTime: 0:04:16.241435 FixedProfit: 1098367\n",
            "Episode: 43/50 RapTime: 0:04:18.454576 FixedProfit: 1405205\n",
            "Episode: 43/50 RapTime: 0:04:25.144733 FixedProfit: 1211982\n",
            "Episode: 43/50 RapTime: 0:04:23.188679 FixedProfit: 1133271\n",
            "Episode: 43/50 RapTime: 0:04:24.217557 FixedProfit: 1016080\n",
            "Episode: 44/50 RapTime: 0:04:24.855765 FixedProfit: 1060058\n",
            "Episode: 44/50 RapTime: 0:04:25.806732 FixedProfit: 1130165\n",
            "Episode: 44/50 RapTime: 0:04:22.993964 FixedProfit: 1043076\n",
            "Episode: 44/50 RapTime: 0:04:30.910694 FixedProfit: 1032464\n",
            "Episode: 45/50 RapTime: 0:04:26.040977 FixedProfit: 1046076\n",
            "Episode: 45/50 RapTime: 0:04:27.604708 FixedProfit: 1054895\n",
            "Episode: 45/50 RapTime: 0:04:28.942172 FixedProfit: 1179600\n",
            "Episode: 45/50 RapTime: 0:04:34.581992 FixedProfit: 1193561\n",
            "Episode: 46/50 RapTime: 0:04:31.984036 FixedProfit: 1106489\n",
            "Episode: 46/50 RapTime: 0:04:29.867570 FixedProfit: 1095188\n",
            "Episode: 46/50 RapTime: 0:04:28.159662 FixedProfit: 1037282\n",
            "Episode: 46/50 RapTime: 0:04:33.860753 FixedProfit: 1481411\n",
            "Episode: 47/50 RapTime: 0:04:33.690770 FixedProfit: 872205\n",
            "Episode: 47/50 RapTime: 0:04:38.199445 FixedProfit: 929456\n",
            "Episode: 47/50 RapTime: 0:04:36.432708 FixedProfit: 1218516\n",
            "Episode: 47/50 RapTime: 0:04:34.679231 FixedProfit: 1235936\n",
            "Episode: 48/50 RapTime: 0:04:39.326297 FixedProfit: 1095018\n",
            "Episode: 48/50 RapTime: 0:04:38.930906 FixedProfit: 1167617\n",
            "Episode: 48/50 RapTime: 0:04:38.741834 FixedProfit: 1029005\n",
            "Episode: 48/50 RapTime: 0:04:33.731728 FixedProfit: 1164059\n",
            "Episode: 49/50 RapTime: 0:04:45.599301 FixedProfit: 1201867\n",
            "Episode: 49/50 RapTime: 0:04:35.277076 FixedProfit: 1165945\n",
            "Episode: 49/50 RapTime: 0:04:33.843493 FixedProfit: 1371362\n",
            "Episode: 49/50 RapTime: 0:04:42.838528 FixedProfit: 1041191\n",
            "Episode: 50/50 RapTime: 0:04:42.317935 FixedProfit: 970754\n",
            "Episode: 50/50 RapTime: 0:04:24.375756 FixedProfit: 1277614\n",
            "Episode: 50/50 RapTime: 0:04:14.600893 FixedProfit: 1038148\n",
            "Episode: 50/50 RapTime: 0:04:10.916121 FixedProfit: 1021248\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}