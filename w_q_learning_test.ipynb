{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w_q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNfuTOEri+p7fv1509j5opZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/w_q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "5b9cc723-a867-4e29-eaf4-56932219b1e9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'test'\n",
        "name = 'w_qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        model.summary()\n",
        "        self.model = model\n",
        "    \n",
        "        model_2 = Sequential()\n",
        "        model_2.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_mid))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_action))\n",
        "        model_2.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        model_2.summary()\n",
        "        self.model_2 = model_2\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done, s_flag):\n",
        "\n",
        "        next_act_values = self._predict(next_state,s_flag)\n",
        "        next_action =np.argmax(next_act_values)\n",
        "\n",
        "        if s_flag == 11:\n",
        "            q = self.model.predict(state)  \n",
        "            next_q = self.model_2.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            target[:, action] = reward + (1 - done) * self.gamma*np.max(next_q, axis=1)\n",
        "            self.model.train_on_batch(state, target)\n",
        "        else:\n",
        "            q = self.model_2.predict(state)  \n",
        "            next_q = self.model.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            target[:, action] = reward + (1 - done) * self.gamma*np.max(next_q, axis=1)\n",
        "            self.model_2.train_on_batch(state, target)\n",
        "\n",
        "\n",
        "    def _predict(self, state, s_flag = 12):\n",
        "        values = None\n",
        "        q1 = self.model.predict(state)\n",
        "        q2 = self.model_2.predict(state)\n",
        "        if s_flag == 12:\n",
        "            values = np.array([q1[0,a] + q2[0,a] for a in range(3)])\n",
        "        elif s_flag == 11:\n",
        "            values = np.array([q1[0,a] + q1[0,a] for a in range(3)])\n",
        "        else:\n",
        "            values = np.array([q2[0,a] + q2[0,a] for a in range(3)])\n",
        "        return values\n",
        "\n",
        "    def load(self, name, name2):\n",
        "        self.model.load_weights(name)\n",
        "        self.model_2.load_weights(name2)\n",
        "\n",
        "    def save(self, name, name2):\n",
        "        self.model.save_weights(name)\n",
        "        self.model_2.save_weights(name2)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state,s_flag=12):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self._predict(state,s_flag)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                s_flag = 12\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    rand = np.random.random()\n",
        "                    if rand <= 0.5:\n",
        "                        s_flag = 11\n",
        "                    else:\n",
        "                        s_flag = 22\n",
        "                    agent.train(state, action, reward, next_state, done, s_flag)\n",
        "                    \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "ce80abdf-34ca-4f05-e08b-1b045b606454"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Episode: 1/100 RapTime: 0:01:11.748833 FixedProfit: 1608450 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 2/100 RapTime: 0:01:09.172041 FixedProfit: 1303634 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 3/100 RapTime: 0:01:09.599048 FixedProfit: 1716088 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 4/100 RapTime: 0:01:09.920835 FixedProfit: 1118309 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 5/100 RapTime: 0:01:10.120807 FixedProfit: 1422101 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 6/100 RapTime: 0:01:10.603985 FixedProfit: 1617088 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 7/100 RapTime: 0:01:10.349310 FixedProfit: 1153233 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 8/100 RapTime: 0:01:11.328713 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 9/100 RapTime: 0:01:10.184178 FixedProfit: 994106 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 10/100 RapTime: 0:01:10.683518 FixedProfit: 1213850 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 11/100 RapTime: 0:01:10.787602 FixedProfit: 1597816 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 12/100 RapTime: 0:01:10.817967 FixedProfit: 1033713 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 13/100 RapTime: 0:01:11.032298 FixedProfit: 1111103 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 14/100 RapTime: 0:01:10.539822 FixedProfit: 945890 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 15/100 RapTime: 0:01:11.012161 FixedProfit: 998237 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 16/100 RapTime: 0:01:10.337577 FixedProfit: 1065990 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 17/100 RapTime: 0:01:10.152407 FixedProfit: 1055388 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 18/100 RapTime: 0:01:09.733954 FixedProfit: 1267381 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 19/100 RapTime: 0:01:10.404597 FixedProfit: 1186555 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 20/100 RapTime: 0:01:10.451136 FixedProfit: 1128178 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 21/100 RapTime: 0:01:10.773691 FixedProfit: 1222130 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 22/100 RapTime: 0:01:10.850915 FixedProfit: 1450775 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 23/100 RapTime: 0:01:10.720701 FixedProfit: 1330668 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 24/100 RapTime: 0:01:11.215782 FixedProfit: 1308674 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 25/100 RapTime: 0:01:12.780386 FixedProfit: 1271215 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 26/100 RapTime: 0:01:10.860202 FixedProfit: 1345918 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 27/100 RapTime: 0:01:11.357194 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 28/100 RapTime: 0:01:11.082129 FixedProfit: 1017007 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 29/100 RapTime: 0:01:11.338838 FixedProfit: 1188972 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 30/100 RapTime: 0:01:11.962469 FixedProfit: 1510673 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 31/100 RapTime: 0:01:10.925001 FixedProfit: 1211409 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 32/100 RapTime: 0:01:11.545703 FixedProfit: 1208450 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 33/100 RapTime: 0:01:11.604253 FixedProfit: 1527476 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 34/100 RapTime: 0:01:11.881306 FixedProfit: 1069767 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 35/100 RapTime: 0:01:12.472804 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 36/100 RapTime: 0:01:11.967259 FixedProfit: 1039095 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:01:12.105851 FixedProfit: 1121385 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 38/100 RapTime: 0:01:11.957475 FixedProfit: 1304052 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 39/100 RapTime: 0:01:11.964710 FixedProfit: 1134659 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 40/100 RapTime: 0:01:11.199929 FixedProfit: 1296476 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 41/100 RapTime: 0:01:11.358941 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 42/100 RapTime: 0:01:10.895820 FixedProfit: 1319418 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 43/100 RapTime: 0:01:10.972723 FixedProfit: 1166969 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 44/100 RapTime: 0:01:11.523567 FixedProfit: 1390883 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 45/100 RapTime: 0:01:11.186286 FixedProfit: 1079900 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 46/100 RapTime: 0:01:10.681633 FixedProfit: 1215842 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 47/100 RapTime: 0:01:10.608320 FixedProfit: 1098049 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 48/100 RapTime: 0:01:10.038516 FixedProfit: 1179313 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 49/100 RapTime: 0:01:10.584677 FixedProfit: 1380836 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 50/100 RapTime: 0:01:10.098891 FixedProfit: 1319769 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 51/100 RapTime: 0:01:10.286838 FixedProfit: 1241192 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 52/100 RapTime: 0:01:10.604963 FixedProfit: 1323544 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 53/100 RapTime: 0:01:10.561666 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 54/100 RapTime: 0:01:10.346266 FixedProfit: 1579111 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 55/100 RapTime: 0:01:10.456225 FixedProfit: 942941 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 56/100 RapTime: 0:01:11.919273 FixedProfit: 1063611 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 57/100 RapTime: 0:01:10.698468 FixedProfit: 1388355 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 58/100 RapTime: 0:01:10.671606 FixedProfit: 1341729 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 59/100 RapTime: 0:01:10.521170 FixedProfit: 1271025 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 60/100 RapTime: 0:01:11.244814 FixedProfit: 1188209 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 61/100 RapTime: 0:01:10.725251 FixedProfit: 984838 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 62/100 RapTime: 0:01:10.989046 FixedProfit: 1217083 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 63/100 RapTime: 0:01:10.642383 FixedProfit: 1105241 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 64/100 RapTime: 0:01:10.191995 FixedProfit: 1315097 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 65/100 RapTime: 0:01:10.580384 FixedProfit: 1168690 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 66/100 RapTime: 0:01:10.304475 FixedProfit: 1168450 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 67/100 RapTime: 0:01:10.737244 FixedProfit: 1073133 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 68/100 RapTime: 0:01:09.897833 FixedProfit: 1286075 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 69/100 RapTime: 0:01:09.998857 FixedProfit: 1141860 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 70/100 RapTime: 0:01:10.051616 FixedProfit: 1349763 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 71/100 RapTime: 0:01:09.645040 FixedProfit: 1187553 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 72/100 RapTime: 0:01:10.215422 FixedProfit: 1005557 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 73/100 RapTime: 0:01:09.966858 FixedProfit: 1085276 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 74/100 RapTime: 0:01:09.858956 FixedProfit: 1123159 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 75/100 RapTime: 0:01:09.447041 FixedProfit: 1026647 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 76/100 RapTime: 0:01:10.441858 FixedProfit: 1226315 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 77/100 RapTime: 0:01:10.388371 FixedProfit: 1150279 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 78/100 RapTime: 0:01:10.457113 FixedProfit: 1242007 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 79/100 RapTime: 0:01:10.204964 FixedProfit: 1308024 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 80/100 RapTime: 0:01:09.914075 FixedProfit: 1263380 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 81/100 RapTime: 0:01:09.750475 FixedProfit: 1099518 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 82/100 RapTime: 0:01:10.027432 FixedProfit: 946033 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 83/100 RapTime: 0:01:10.152750 FixedProfit: 1236782 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 84/100 RapTime: 0:01:09.934361 FixedProfit: 1365211 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 85/100 RapTime: 0:01:10.509402 FixedProfit: 1304558 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 86/100 RapTime: 0:01:09.884109 FixedProfit: 1191477 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 87/100 RapTime: 0:01:09.753540 FixedProfit: 988258 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 88/100 RapTime: 0:01:10.007757 FixedProfit: 1146708 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 89/100 RapTime: 0:01:09.915994 FixedProfit: 1429756 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 90/100 RapTime: 0:01:10.097276 FixedProfit: 1025067 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 91/100 RapTime: 0:01:10.018261 FixedProfit: 1126983 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 92/100 RapTime: 0:01:09.739106 FixedProfit: 1339359 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 93/100 RapTime: 0:01:09.361961 FixedProfit: 1274078 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 94/100 RapTime: 0:01:08.893625 FixedProfit: 1260627 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 95/100 RapTime: 0:01:09.508617 FixedProfit: 1039812 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 96/100 RapTime: 0:01:09.937093 FixedProfit: 1382632 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 97/100 RapTime: 0:01:09.729621 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 98/100 RapTime: 0:01:10.271877 FixedProfit: 1364456 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 99/100 RapTime: 0:01:09.507460 FixedProfit: 1391780 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 100/100 RapTime: 0:01:09.698192 FixedProfit: 1132494 TradeTimes: 3 TradeWin: 2\n"
          ]
        }
      ]
    }
  ]
}