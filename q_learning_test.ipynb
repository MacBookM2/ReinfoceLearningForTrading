{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMRlXyGaLd2SMt4h9D4YLHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "31b3ec8f-e1fb-4ec9-8fe4-f8021d0a057f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'test'\n",
        "name = 'qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        target = np.copy(q)\n",
        "        if done:\n",
        "            target[:, action] = reward\n",
        "        else:\n",
        "            target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, target)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "                self.scaler = pickle.load(f)\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.agent.train(state, action, reward, next_state, done)\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save_scaler()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _save_scaler(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "6778ba17-ecde-49fa-c870-8ab33f482d51"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:29.092401 FixedProfit: 1582215 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 2/100 RapTime: 0:00:26.609655 FixedProfit: 1520043 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 3/100 RapTime: 0:00:27.168073 FixedProfit: 1477994 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 4/100 RapTime: 0:00:27.880340 FixedProfit: 1511966 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 5/100 RapTime: 0:00:26.962846 FixedProfit: 1548473 TradeTimes: 8 TradeWin: 7\n",
            "Episode: 6/100 RapTime: 0:00:29.296711 FixedProfit: 1536366 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 7/100 RapTime: 0:00:29.044251 FixedProfit: 1477098 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 8/100 RapTime: 0:00:27.915541 FixedProfit: 1545992 TradeTimes: 9 TradeWin: 5\n",
            "Episode: 9/100 RapTime: 0:00:29.208729 FixedProfit: 1538085 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 10/100 RapTime: 0:00:28.606189 FixedProfit: 1533211 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 11/100 RapTime: 0:00:27.568805 FixedProfit: 1521642 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 12/100 RapTime: 0:00:28.294125 FixedProfit: 1544127 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 13/100 RapTime: 0:00:26.977021 FixedProfit: 1534441 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 14/100 RapTime: 0:00:28.655434 FixedProfit: 1553543 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 15/100 RapTime: 0:00:27.142026 FixedProfit: 1525328 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 16/100 RapTime: 0:00:27.574134 FixedProfit: 1524088 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 17/100 RapTime: 0:00:27.919812 FixedProfit: 1601426 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 18/100 RapTime: 0:00:27.185960 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 19/100 RapTime: 0:00:26.086178 FixedProfit: 1544589 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 20/100 RapTime: 0:00:27.904919 FixedProfit: 1537939 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 21/100 RapTime: 0:00:26.138566 FixedProfit: 1530571 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 22/100 RapTime: 0:00:27.371375 FixedProfit: 1515992 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 23/100 RapTime: 0:00:26.903931 FixedProfit: 1538055 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 24/100 RapTime: 0:00:26.334741 FixedProfit: 1564770 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 25/100 RapTime: 0:00:27.657371 FixedProfit: 1553144 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 26/100 RapTime: 0:00:26.622949 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 27/100 RapTime: 0:00:27.517255 FixedProfit: 1528251 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 28/100 RapTime: 0:00:26.871476 FixedProfit: 1540126 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 29/100 RapTime: 0:00:26.564634 FixedProfit: 1564951 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 30/100 RapTime: 0:00:27.330618 FixedProfit: 1550163 TradeTimes: 9 TradeWin: 6\n",
            "Episode: 31/100 RapTime: 0:00:27.844476 FixedProfit: 1623611 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 32/100 RapTime: 0:00:26.503279 FixedProfit: 1531539 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 33/100 RapTime: 0:00:27.401240 FixedProfit: 1541764 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 34/100 RapTime: 0:00:26.837838 FixedProfit: 1537897 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 35/100 RapTime: 0:00:26.612721 FixedProfit: 1600182 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 36/100 RapTime: 0:00:28.083414 FixedProfit: 1518729 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:00:26.519659 FixedProfit: 1480575 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 38/100 RapTime: 0:00:27.729278 FixedProfit: 1545616 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 39/100 RapTime: 0:00:26.763368 FixedProfit: 1493695 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 40/100 RapTime: 0:00:26.873837 FixedProfit: 1462979 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 41/100 RapTime: 0:00:27.655283 FixedProfit: 1464184 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 42/100 RapTime: 0:00:27.756317 FixedProfit: 1557377 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 43/100 RapTime: 0:00:26.097293 FixedProfit: 1615354 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 44/100 RapTime: 0:00:27.246904 FixedProfit: 1598876 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 45/100 RapTime: 0:00:27.060625 FixedProfit: 1517556 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 46/100 RapTime: 0:00:26.268559 FixedProfit: 1538456 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 47/100 RapTime: 0:00:27.595338 FixedProfit: 1534650 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 48/100 RapTime: 0:00:26.264645 FixedProfit: 1457845 TradeTimes: 8 TradeWin: 7\n",
            "Episode: 49/100 RapTime: 0:00:27.426500 FixedProfit: 1526067 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 50/100 RapTime: 0:00:27.000079 FixedProfit: 1489841 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 51/100 RapTime: 0:00:26.449545 FixedProfit: 1541045 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 52/100 RapTime: 0:00:26.925424 FixedProfit: 1541864 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 53/100 RapTime: 0:00:27.475359 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 54/100 RapTime: 0:00:25.725851 FixedProfit: 1545464 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 55/100 RapTime: 0:00:26.644706 FixedProfit: 1548906 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 56/100 RapTime: 0:00:27.104254 FixedProfit: 1567099 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 57/100 RapTime: 0:00:26.413555 FixedProfit: 1523734 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 58/100 RapTime: 0:00:27.865388 FixedProfit: 1534844 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 59/100 RapTime: 0:00:26.652699 FixedProfit: 1538545 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 60/100 RapTime: 0:00:27.494883 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 61/100 RapTime: 0:00:26.893168 FixedProfit: 1532856 TradeTimes: 6 TradeWin: 6\n",
            "Episode: 62/100 RapTime: 0:00:26.473261 FixedProfit: 1493313 TradeTimes: 7 TradeWin: 7\n",
            "Episode: 63/100 RapTime: 0:00:27.613620 FixedProfit: 1543229 TradeTimes: 6 TradeWin: 6\n",
            "Episode: 64/100 RapTime: 0:00:26.534238 FixedProfit: 1543973 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 65/100 RapTime: 0:00:27.297113 FixedProfit: 1552217 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 66/100 RapTime: 0:00:27.358328 FixedProfit: 1537200 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 67/100 RapTime: 0:00:27.098126 FixedProfit: 1607832 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 68/100 RapTime: 0:00:26.281970 FixedProfit: 1483116 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 69/100 RapTime: 0:00:27.698154 FixedProfit: 1567966 TradeTimes: 8 TradeWin: 6\n",
            "Episode: 70/100 RapTime: 0:00:26.210486 FixedProfit: 1541571 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 71/100 RapTime: 0:00:27.364302 FixedProfit: 1496854 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 72/100 RapTime: 0:00:26.877864 FixedProfit: 1521913 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 73/100 RapTime: 0:00:26.324353 FixedProfit: 1647287 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 74/100 RapTime: 0:00:27.532494 FixedProfit: 1574047 TradeTimes: 8 TradeWin: 6\n",
            "Episode: 75/100 RapTime: 0:00:26.096749 FixedProfit: 1551837 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 76/100 RapTime: 0:00:27.406368 FixedProfit: 1544446 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 77/100 RapTime: 0:00:27.570190 FixedProfit: 1552490 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 78/100 RapTime: 0:00:27.296376 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 79/100 RapTime: 0:00:26.336740 FixedProfit: 1518984 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 80/100 RapTime: 0:00:27.715974 FixedProfit: 1570371 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 81/100 RapTime: 0:00:26.275042 FixedProfit: 1571491 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 82/100 RapTime: 0:00:27.196626 FixedProfit: 1534156 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 83/100 RapTime: 0:00:26.950096 FixedProfit: 1578617 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 84/100 RapTime: 0:00:26.680540 FixedProfit: 1556067 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 85/100 RapTime: 0:00:27.626663 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 86/100 RapTime: 0:00:26.242599 FixedProfit: 1567478 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 87/100 RapTime: 0:00:27.238490 FixedProfit: 1593249 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 88/100 RapTime: 0:00:26.795935 FixedProfit: 1519253 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 89/100 RapTime: 0:00:26.555317 FixedProfit: 1517800 TradeTimes: 6 TradeWin: 6\n",
            "Episode: 90/100 RapTime: 0:00:27.464135 FixedProfit: 1534092 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 91/100 RapTime: 0:00:27.634444 FixedProfit: 1563113 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 92/100 RapTime: 0:00:26.481891 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 93/100 RapTime: 0:00:27.308064 FixedProfit: 1542135 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 94/100 RapTime: 0:00:26.869586 FixedProfit: 1544186 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 95/100 RapTime: 0:00:26.460927 FixedProfit: 1563542 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 96/100 RapTime: 0:00:27.890666 FixedProfit: 1511384 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 97/100 RapTime: 0:00:26.185386 FixedProfit: 1519414 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 98/100 RapTime: 0:00:27.463104 FixedProfit: 1542179 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 99/100 RapTime: 0:00:26.078208 FixedProfit: 1531377 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 100/100 RapTime: 0:00:25.909707 FixedProfit: 1496272 TradeTimes: 6 TradeWin: 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}