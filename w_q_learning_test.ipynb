{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w_q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM2/eSdBLRtqqinP2f4a/0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/w_q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "f00f5e8f-3736-4d86-e56d-89ed13c8bdfb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'test'\n",
        "name = 'w_qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "    \n",
        "        model_2 = Sequential()\n",
        "        model_2.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_mid))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_action))\n",
        "        model_2.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model_2.summary()))\n",
        "        self.model_2 = model_2\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done, s_flag):\n",
        "\n",
        "        next_act_values = self.model.predict(next_state,s_flag)\n",
        "        next_action =np.argmax(next_act_values[0])\n",
        "\n",
        "        if s_flag == 11:\n",
        "            q = self.model.predict(state)  \n",
        "            next_q = self.model_2.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model.train_on_batch(state, target)\n",
        "        else:\n",
        "            q = self.model_2.predict(state)  \n",
        "            next_q = self.model.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model_2.train_on_batch(state, target)\n",
        "\n",
        "\n",
        "    def predict(self, state, s_flag = 12):\n",
        "        values = None\n",
        "        q1 = self.model.predict(state)\n",
        "        q2 = self.model_2.predict(state)\n",
        "        if s_flag == 12:\n",
        "            values = np.array([q1[0,a] + q2[0,a] for a in range(2)])\n",
        "        elif s_flag == 11:\n",
        "            values = np.array([q1[0,a] + q1[0,a] for a in range(2)])\n",
        "        else:\n",
        "            values = np.array([q2[0,a] + q2[0,a] for a in range(2)])\n",
        "        return values\n",
        "\n",
        "    def load(self, name, name2):\n",
        "        self.model.load_weights(name)\n",
        "        self.model_2.load_weights(name2)\n",
        "\n",
        "    def save(self, name, name2):\n",
        "        self.model.save_weights(name)\n",
        "        self.model_2.save_weights(name2)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state,s_flag=12):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state,s_flag)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                s_flag = 12\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    rand = np.random.random()\n",
        "                    if rand <= 0.5:\n",
        "                        s_flag = 11\n",
        "                    else:\n",
        "                        s_flag = 22\n",
        "                    agent.train(state, action, reward, next_state, done, s_flag)\n",
        "                    \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "5ac5ce9c-0a1f-4f9b-8033-4299b1ca454f"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:56.920317 FixedProfit: 1531643 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 2/100 RapTime: 0:00:56.647020 FixedProfit: 1510862 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 3/100 RapTime: 0:00:56.086035 FixedProfit: 1562703 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 4/100 RapTime: 0:00:57.103863 FixedProfit: 1596891 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 5/100 RapTime: 0:00:56.807077 FixedProfit: 1529858 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 6/100 RapTime: 0:00:56.673252 FixedProfit: 1538373 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 7/100 RapTime: 0:00:55.942808 FixedProfit: 1524500 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 8/100 RapTime: 0:00:56.234186 FixedProfit: 1560549 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 9/100 RapTime: 0:00:56.340227 FixedProfit: 1539403 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 10/100 RapTime: 0:00:56.323568 FixedProfit: 1510481 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 11/100 RapTime: 0:00:56.086194 FixedProfit: 1521770 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 12/100 RapTime: 0:00:56.622764 FixedProfit: 1543950 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 13/100 RapTime: 0:00:55.997784 FixedProfit: 1521455 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 14/100 RapTime: 0:00:56.106588 FixedProfit: 1530290 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 15/100 RapTime: 0:00:57.114230 FixedProfit: 1557377 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 16/100 RapTime: 0:00:57.699995 FixedProfit: 1533314 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 17/100 RapTime: 0:00:55.839434 FixedProfit: 1542695 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 18/100 RapTime: 0:00:56.666934 FixedProfit: 1537527 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 19/100 RapTime: 0:00:57.688415 FixedProfit: 1568519 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 20/100 RapTime: 0:00:56.495605 FixedProfit: 1537837 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 21/100 RapTime: 0:00:57.829164 FixedProfit: 1538973 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 22/100 RapTime: 0:00:56.282089 FixedProfit: 1493056 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 23/100 RapTime: 0:00:55.861648 FixedProfit: 1630582 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 24/100 RapTime: 0:00:56.672978 FixedProfit: 1575359 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 25/100 RapTime: 0:00:56.430608 FixedProfit: 1410575 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 26/100 RapTime: 0:00:56.337332 FixedProfit: 1542227 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 27/100 RapTime: 0:00:56.027741 FixedProfit: 1574011 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 28/100 RapTime: 0:00:56.075563 FixedProfit: 1551308 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 29/100 RapTime: 0:00:56.136777 FixedProfit: 1538344 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 30/100 RapTime: 0:00:56.388982 FixedProfit: 1534887 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 31/100 RapTime: 0:00:55.089377 FixedProfit: 1516830 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 32/100 RapTime: 0:00:54.844934 FixedProfit: 1492342 TradeTimes: 6 TradeWin: 6\n",
            "Episode: 33/100 RapTime: 0:00:56.953424 FixedProfit: 1546653 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 34/100 RapTime: 0:00:55.273078 FixedProfit: 1540522 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 35/100 RapTime: 0:00:55.066885 FixedProfit: 1542011 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 36/100 RapTime: 0:00:55.894418 FixedProfit: 1523706 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:00:55.427044 FixedProfit: 1536699 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 38/100 RapTime: 0:00:55.658762 FixedProfit: 1530953 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 39/100 RapTime: 0:00:56.128342 FixedProfit: 1526419 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 40/100 RapTime: 0:00:55.883297 FixedProfit: 1587737 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 41/100 RapTime: 0:00:55.837869 FixedProfit: 1523258 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 42/100 RapTime: 0:00:55.676360 FixedProfit: 1455728 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 43/100 RapTime: 0:00:54.924909 FixedProfit: 1512325 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 44/100 RapTime: 0:00:54.936591 FixedProfit: 1566708 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 45/100 RapTime: 0:00:56.766784 FixedProfit: 1553733 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 46/100 RapTime: 0:00:55.467287 FixedProfit: 1570529 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 47/100 RapTime: 0:00:55.684864 FixedProfit: 1522284 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 48/100 RapTime: 0:00:55.639761 FixedProfit: 1545053 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 49/100 RapTime: 0:00:55.683424 FixedProfit: 1611938 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 50/100 RapTime: 0:00:56.088139 FixedProfit: 1492191 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 51/100 RapTime: 0:00:56.168902 FixedProfit: 1547956 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 52/100 RapTime: 0:00:55.903546 FixedProfit: 1519574 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 53/100 RapTime: 0:00:55.384385 FixedProfit: 1555284 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 54/100 RapTime: 0:00:55.348055 FixedProfit: 1510690 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 55/100 RapTime: 0:00:55.454103 FixedProfit: 1544526 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 56/100 RapTime: 0:00:55.329176 FixedProfit: 1549561 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 57/100 RapTime: 0:00:56.469342 FixedProfit: 1454668 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 58/100 RapTime: 0:00:55.915764 FixedProfit: 1518261 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 59/100 RapTime: 0:00:55.215131 FixedProfit: 1597792 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 60/100 RapTime: 0:00:55.581163 FixedProfit: 1468719 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 61/100 RapTime: 0:00:55.550237 FixedProfit: 1516575 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 62/100 RapTime: 0:00:57.134830 FixedProfit: 1556770 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 63/100 RapTime: 0:00:55.433806 FixedProfit: 1537914 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 64/100 RapTime: 0:00:55.402014 FixedProfit: 1555368 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 65/100 RapTime: 0:00:56.269364 FixedProfit: 1564116 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 66/100 RapTime: 0:00:55.142069 FixedProfit: 1633293 TradeTimes: 8 TradeWin: 7\n",
            "Episode: 67/100 RapTime: 0:00:55.590239 FixedProfit: 1551516 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 68/100 RapTime: 0:00:55.847842 FixedProfit: 1551512 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 69/100 RapTime: 0:00:56.408987 FixedProfit: 1539466 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 70/100 RapTime: 0:00:55.550529 FixedProfit: 1556565 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 71/100 RapTime: 0:00:55.321149 FixedProfit: 1549689 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 72/100 RapTime: 0:00:55.104421 FixedProfit: 1517311 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 73/100 RapTime: 0:00:55.589937 FixedProfit: 1519327 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 74/100 RapTime: 0:00:57.017345 FixedProfit: 1526162 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 75/100 RapTime: 0:00:54.894583 FixedProfit: 1556191 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 76/100 RapTime: 0:00:54.796407 FixedProfit: 1491366 TradeTimes: 6 TradeWin: 6\n",
            "Episode: 77/100 RapTime: 0:00:55.563578 FixedProfit: 1504087 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 78/100 RapTime: 0:00:55.471597 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 79/100 RapTime: 0:00:55.491939 FixedProfit: 1531041 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 80/100 RapTime: 0:00:55.809607 FixedProfit: 1555681 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 81/100 RapTime: 0:00:55.853386 FixedProfit: 1529155 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 82/100 RapTime: 0:00:56.001198 FixedProfit: 1512994 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 83/100 RapTime: 0:00:55.874337 FixedProfit: 1541439 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 84/100 RapTime: 0:00:55.162700 FixedProfit: 1529001 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 85/100 RapTime: 0:00:54.763886 FixedProfit: 1538227 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 86/100 RapTime: 0:00:57.652241 FixedProfit: 1598068 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 87/100 RapTime: 0:00:56.359247 FixedProfit: 1537021 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 88/100 RapTime: 0:00:54.763844 FixedProfit: 1560170 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 89/100 RapTime: 0:00:54.788077 FixedProfit: 1549058 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 90/100 RapTime: 0:00:56.470850 FixedProfit: 1534971 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 91/100 RapTime: 0:00:56.132688 FixedProfit: 1536492 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 92/100 RapTime: 0:00:55.912702 FixedProfit: 1567890 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 93/100 RapTime: 0:00:56.120742 FixedProfit: 1540528 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 94/100 RapTime: 0:00:55.815805 FixedProfit: 1570445 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 95/100 RapTime: 0:00:57.000336 FixedProfit: 1544094 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 96/100 RapTime: 0:00:55.116343 FixedProfit: 1759146 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 97/100 RapTime: 0:00:54.843546 FixedProfit: 1520547 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 98/100 RapTime: 0:00:55.726554 FixedProfit: 1535523 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 99/100 RapTime: 0:00:55.577837 FixedProfit: 1510238 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 100/100 RapTime: 0:00:55.965857 FixedProfit: 1529868 TradeTimes: 2 TradeWin: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}