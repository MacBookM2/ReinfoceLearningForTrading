{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOwG8u7UyE5Kc9wkYF9lTUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/sarsa_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "49820633-b8a2-4e8b-e738-0365ad9aa9ca"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'train'\n",
        "name = 'sarsa'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, next_act, done):\n",
        "        q = self.model.predict(state)  \n",
        "        target = np.copy(q)\n",
        "        if done:\n",
        "            target[:, action] = reward\n",
        "        else:\n",
        "            target[:, action] = reward + self.gamma*next_act\n",
        "        self.model.train_on_batch(state, target)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state, act, reward, info, next_state, done, mode = 'train'):\n",
        "\n",
        "        next_act = self._next_act(state)\n",
        "        if mode == 'train':\n",
        "            self.train(state, act, reward, next_state, next_act, done)\n",
        "\n",
        "        return next_act\n",
        "\n",
        "    def _next_act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "                self.scaler = pickle.load(f)\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "            reward = 0.0\n",
        "            info = None\n",
        "            next_state = copy.copy(state)\n",
        "            next_act = 1\n",
        "            act = 1\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state, act, reward, info, next_state, done, mode)\n",
        "                state = next_state\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "                act = copy.copy(action)\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save_scaler()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _save_scaler(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "4fb785da-374d-4f49-8333-4c3a8fefb00a"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:22.890813 FixedProfit: 1163718\n",
            "Episode: 2/100 RapTime: 0:00:22.891678 FixedProfit: 1009920\n",
            "Episode: 3/100 RapTime: 0:00:21.809319 FixedProfit: 1186214\n",
            "Episode: 4/100 RapTime: 0:00:21.449529 FixedProfit: 953630\n",
            "Episode: 5/100 RapTime: 0:00:22.841223 FixedProfit: 1120391\n",
            "Episode: 6/100 RapTime: 0:00:22.563005 FixedProfit: 1156772\n",
            "Episode: 7/100 RapTime: 0:00:22.453756 FixedProfit: 1131276\n",
            "Episode: 8/100 RapTime: 0:00:21.298013 FixedProfit: 986856\n",
            "Episode: 9/100 RapTime: 0:00:22.165696 FixedProfit: 1101012\n",
            "Episode: 10/100 RapTime: 0:00:22.731498 FixedProfit: 1018855\n",
            "Episode: 11/100 RapTime: 0:00:21.587006 FixedProfit: 1180711\n",
            "Episode: 12/100 RapTime: 0:00:22.226431 FixedProfit: 932225\n",
            "Episode: 13/100 RapTime: 0:00:22.412460 FixedProfit: 1076383\n",
            "Episode: 14/100 RapTime: 0:00:21.688396 FixedProfit: 1571182\n",
            "Episode: 15/100 RapTime: 0:00:22.231354 FixedProfit: 1061499\n",
            "Episode: 16/100 RapTime: 0:00:22.377912 FixedProfit: 1302985\n",
            "Episode: 17/100 RapTime: 0:00:21.372691 FixedProfit: 1154146\n",
            "Episode: 18/100 RapTime: 0:00:22.236099 FixedProfit: 1066362\n",
            "Episode: 19/100 RapTime: 0:00:22.461879 FixedProfit: 1183300\n",
            "Episode: 20/100 RapTime: 0:00:21.331977 FixedProfit: 1096881\n",
            "Episode: 21/100 RapTime: 0:00:22.209657 FixedProfit: 1175504\n",
            "Episode: 22/100 RapTime: 0:00:22.202295 FixedProfit: 1213511\n",
            "Episode: 23/100 RapTime: 0:00:22.979205 FixedProfit: 923820\n",
            "Episode: 24/100 RapTime: 0:00:21.477416 FixedProfit: 992432\n",
            "Episode: 25/100 RapTime: 0:00:21.660162 FixedProfit: 1214257\n",
            "Episode: 26/100 RapTime: 0:00:23.005151 FixedProfit: 1187007\n",
            "Episode: 27/100 RapTime: 0:00:21.796057 FixedProfit: 1125676\n",
            "Episode: 28/100 RapTime: 0:00:21.404026 FixedProfit: 1010500\n",
            "Episode: 29/100 RapTime: 0:00:22.984281 FixedProfit: 1137305\n",
            "Episode: 30/100 RapTime: 0:00:21.426851 FixedProfit: 865096\n",
            "Episode: 31/100 RapTime: 0:00:21.587935 FixedProfit: 1080555\n",
            "Episode: 32/100 RapTime: 0:00:22.930377 FixedProfit: 1147267\n",
            "Episode: 33/100 RapTime: 0:00:21.335692 FixedProfit: 947627\n",
            "Episode: 34/100 RapTime: 0:00:21.317468 FixedProfit: 1021457\n",
            "Episode: 35/100 RapTime: 0:00:22.881706 FixedProfit: 1279752\n",
            "Episode: 36/100 RapTime: 0:00:22.301186 FixedProfit: 977854\n",
            "Episode: 37/100 RapTime: 0:00:22.199771 FixedProfit: 960545\n",
            "Episode: 38/100 RapTime: 0:00:21.228132 FixedProfit: 1220904\n",
            "Episode: 39/100 RapTime: 0:00:22.447457 FixedProfit: 1033433\n",
            "Episode: 40/100 RapTime: 0:00:22.721575 FixedProfit: 1359307\n",
            "Episode: 41/100 RapTime: 0:00:21.535462 FixedProfit: 901654\n",
            "Episode: 42/100 RapTime: 0:00:22.688283 FixedProfit: 1154616\n",
            "Episode: 43/100 RapTime: 0:00:24.721216 FixedProfit: 927259\n",
            "Episode: 44/100 RapTime: 0:00:22.909664 FixedProfit: 1052386\n",
            "Episode: 45/100 RapTime: 0:00:22.654771 FixedProfit: 1112811\n",
            "Episode: 46/100 RapTime: 0:00:21.767197 FixedProfit: 1339632\n",
            "Episode: 47/100 RapTime: 0:00:21.418942 FixedProfit: 1225619\n",
            "Episode: 48/100 RapTime: 0:00:22.691595 FixedProfit: 1080165\n",
            "Episode: 49/100 RapTime: 0:00:21.899676 FixedProfit: 997486\n",
            "Episode: 50/100 RapTime: 0:00:21.362008 FixedProfit: 987273\n",
            "Episode: 51/100 RapTime: 0:00:22.490422 FixedProfit: 1121593\n",
            "Episode: 52/100 RapTime: 0:00:22.493569 FixedProfit: 1093135\n",
            "Episode: 53/100 RapTime: 0:00:22.958162 FixedProfit: 968819\n",
            "Episode: 54/100 RapTime: 0:00:21.527554 FixedProfit: 1168646\n",
            "Episode: 55/100 RapTime: 0:00:21.773282 FixedProfit: 1027188\n",
            "Episode: 56/100 RapTime: 0:00:22.664566 FixedProfit: 1092416\n",
            "Episode: 57/100 RapTime: 0:00:21.318834 FixedProfit: 1239061\n",
            "Episode: 58/100 RapTime: 0:00:21.865900 FixedProfit: 1085806\n",
            "Episode: 59/100 RapTime: 0:00:22.561326 FixedProfit: 927622\n",
            "Episode: 60/100 RapTime: 0:00:21.808901 FixedProfit: 1054825\n",
            "Episode: 61/100 RapTime: 0:00:21.845555 FixedProfit: 792335\n",
            "Episode: 62/100 RapTime: 0:00:22.662334 FixedProfit: 1224980\n",
            "Episode: 63/100 RapTime: 0:00:21.511114 FixedProfit: 1066311\n",
            "Episode: 64/100 RapTime: 0:00:22.196714 FixedProfit: 1154668\n",
            "Episode: 65/100 RapTime: 0:00:23.212507 FixedProfit: 1123199\n",
            "Episode: 66/100 RapTime: 0:00:22.902655 FixedProfit: 992496\n",
            "Episode: 67/100 RapTime: 0:00:21.845353 FixedProfit: 1020898\n",
            "Episode: 68/100 RapTime: 0:00:21.322532 FixedProfit: 1285104\n",
            "Episode: 69/100 RapTime: 0:00:22.863010 FixedProfit: 1472370\n",
            "Episode: 70/100 RapTime: 0:00:21.709396 FixedProfit: 1286957\n",
            "Episode: 71/100 RapTime: 0:00:21.182336 FixedProfit: 1050556\n",
            "Episode: 72/100 RapTime: 0:00:22.508553 FixedProfit: 1246760\n",
            "Episode: 73/100 RapTime: 0:00:21.752224 FixedProfit: 1226690\n",
            "Episode: 74/100 RapTime: 0:00:21.228437 FixedProfit: 1024007\n",
            "Episode: 75/100 RapTime: 0:00:22.507782 FixedProfit: 1117568\n",
            "Episode: 76/100 RapTime: 0:00:21.778003 FixedProfit: 1229471\n",
            "Episode: 77/100 RapTime: 0:00:21.372691 FixedProfit: 899855\n",
            "Episode: 78/100 RapTime: 0:00:22.459737 FixedProfit: 973440\n",
            "Episode: 79/100 RapTime: 0:00:21.901664 FixedProfit: 1056989\n",
            "Episode: 80/100 RapTime: 0:00:21.763244 FixedProfit: 1110024\n",
            "Episode: 81/100 RapTime: 0:00:22.984099 FixedProfit: 1044007\n",
            "Episode: 82/100 RapTime: 0:00:22.065650 FixedProfit: 942341\n",
            "Episode: 83/100 RapTime: 0:00:21.379193 FixedProfit: 1003167\n",
            "Episode: 84/100 RapTime: 0:00:22.578008 FixedProfit: 1035513\n",
            "Episode: 85/100 RapTime: 0:00:22.425230 FixedProfit: 1211758\n",
            "Episode: 86/100 RapTime: 0:00:22.609963 FixedProfit: 982187\n",
            "Episode: 87/100 RapTime: 0:00:21.395199 FixedProfit: 975706\n",
            "Episode: 88/100 RapTime: 0:00:21.838758 FixedProfit: 1164767\n",
            "Episode: 89/100 RapTime: 0:00:22.301834 FixedProfit: 1014538\n",
            "Episode: 90/100 RapTime: 0:00:21.508758 FixedProfit: 1106093\n",
            "Episode: 91/100 RapTime: 0:00:21.978955 FixedProfit: 1077973\n",
            "Episode: 92/100 RapTime: 0:00:22.325401 FixedProfit: 1013087\n",
            "Episode: 93/100 RapTime: 0:00:21.314696 FixedProfit: 1247756\n",
            "Episode: 94/100 RapTime: 0:00:21.960265 FixedProfit: 1004695\n",
            "Episode: 95/100 RapTime: 0:00:22.717140 FixedProfit: 1195290\n",
            "Episode: 96/100 RapTime: 0:00:22.560360 FixedProfit: 1121765\n",
            "Episode: 97/100 RapTime: 0:00:21.692323 FixedProfit: 1090843\n",
            "Episode: 98/100 RapTime: 0:00:21.504910 FixedProfit: 1044311\n",
            "Episode: 99/100 RapTime: 0:00:22.653400 FixedProfit: 961523\n",
            "Episode: 100/100 RapTime: 0:00:21.720210 FixedProfit: 998182\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}