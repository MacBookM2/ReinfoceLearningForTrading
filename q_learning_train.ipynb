{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPRRQ2lrWvtAUXX896Ub0Xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "919df950-7518-4d97-b093-aaec352982ab"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'train'\n",
        "name = 'qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        target = np.copy(q)\n",
        "        if done:\n",
        "            target[:, action] = reward\n",
        "        else:\n",
        "            target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, target)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "                self.scaler = pickle.load(f)\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.agent.train(state, action, reward, next_state, done)\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save_scaler()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _save_scaler(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "2b563605-7357-4ee1-a035-736d39455629"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:55.844885 FixedProfit: 1191450\n",
            "Episode: 2/100 RapTime: 0:00:54.697686 FixedProfit: 1075725\n",
            "Episode: 3/100 RapTime: 0:00:54.976735 FixedProfit: 1093623\n",
            "Episode: 4/100 RapTime: 0:00:55.203011 FixedProfit: 911970\n",
            "Episode: 5/100 RapTime: 0:00:54.208202 FixedProfit: 1011417\n",
            "Episode: 6/100 RapTime: 0:00:54.059982 FixedProfit: 1136076\n",
            "Episode: 7/100 RapTime: 0:00:54.033137 FixedProfit: 1187047\n",
            "Episode: 8/100 RapTime: 0:00:53.933533 FixedProfit: 1203755\n",
            "Episode: 9/100 RapTime: 0:00:53.772864 FixedProfit: 1015000\n",
            "Episode: 10/100 RapTime: 0:00:53.639186 FixedProfit: 1199075\n",
            "Episode: 11/100 RapTime: 0:00:53.914483 FixedProfit: 1001755\n",
            "Episode: 12/100 RapTime: 0:00:53.862061 FixedProfit: 1118991\n",
            "Episode: 13/100 RapTime: 0:00:54.306236 FixedProfit: 1197591\n",
            "Episode: 14/100 RapTime: 0:00:54.667896 FixedProfit: 1059406\n",
            "Episode: 15/100 RapTime: 0:00:56.424895 FixedProfit: 1265030\n",
            "Episode: 16/100 RapTime: 0:00:55.932842 FixedProfit: 1125928\n",
            "Episode: 17/100 RapTime: 0:00:55.733382 FixedProfit: 1083742\n",
            "Episode: 18/100 RapTime: 0:00:56.112523 FixedProfit: 1049643\n",
            "Episode: 19/100 RapTime: 0:00:54.059469 FixedProfit: 1301237\n",
            "Episode: 20/100 RapTime: 0:00:53.892114 FixedProfit: 1429392\n",
            "Episode: 21/100 RapTime: 0:00:53.651226 FixedProfit: 1243713\n",
            "Episode: 22/100 RapTime: 0:00:53.763432 FixedProfit: 1331771\n",
            "Episode: 23/100 RapTime: 0:00:53.549300 FixedProfit: 909099\n",
            "Episode: 24/100 RapTime: 0:00:53.884790 FixedProfit: 996817\n",
            "Episode: 25/100 RapTime: 0:00:53.686560 FixedProfit: 1060778\n",
            "Episode: 26/100 RapTime: 0:00:53.525755 FixedProfit: 1029483\n",
            "Episode: 27/100 RapTime: 0:00:53.606642 FixedProfit: 1010996\n",
            "Episode: 28/100 RapTime: 0:00:53.677280 FixedProfit: 1147330\n",
            "Episode: 29/100 RapTime: 0:00:53.885365 FixedProfit: 1168050\n",
            "Episode: 30/100 RapTime: 0:00:53.648158 FixedProfit: 1138644\n",
            "Episode: 31/100 RapTime: 0:00:53.680511 FixedProfit: 1079595\n",
            "Episode: 32/100 RapTime: 0:00:54.648672 FixedProfit: 920655\n",
            "Episode: 33/100 RapTime: 0:00:56.066292 FixedProfit: 1169468\n",
            "Episode: 34/100 RapTime: 0:00:56.281011 FixedProfit: 954540\n",
            "Episode: 35/100 RapTime: 0:00:55.558495 FixedProfit: 1114917\n",
            "Episode: 36/100 RapTime: 0:00:55.999096 FixedProfit: 1099849\n",
            "Episode: 37/100 RapTime: 0:00:54.202161 FixedProfit: 1097198\n",
            "Episode: 38/100 RapTime: 0:00:53.522140 FixedProfit: 995801\n",
            "Episode: 39/100 RapTime: 0:00:53.880475 FixedProfit: 1092081\n",
            "Episode: 40/100 RapTime: 0:00:53.465720 FixedProfit: 1257253\n",
            "Episode: 41/100 RapTime: 0:00:53.675323 FixedProfit: 855636\n",
            "Episode: 42/100 RapTime: 0:00:53.447629 FixedProfit: 1108692\n",
            "Episode: 43/100 RapTime: 0:00:53.903714 FixedProfit: 1132375\n",
            "Episode: 44/100 RapTime: 0:00:53.734083 FixedProfit: 1077583\n",
            "Episode: 45/100 RapTime: 0:00:53.772598 FixedProfit: 1300928\n",
            "Episode: 46/100 RapTime: 0:00:54.250347 FixedProfit: 1031176\n",
            "Episode: 47/100 RapTime: 0:00:54.076119 FixedProfit: 919457\n",
            "Episode: 48/100 RapTime: 0:00:53.839428 FixedProfit: 911981\n",
            "Episode: 49/100 RapTime: 0:00:54.185409 FixedProfit: 1209356\n",
            "Episode: 50/100 RapTime: 0:00:54.155255 FixedProfit: 932898\n",
            "Episode: 51/100 RapTime: 0:00:55.767543 FixedProfit: 874166\n",
            "Episode: 52/100 RapTime: 0:00:56.164336 FixedProfit: 1124708\n",
            "Episode: 53/100 RapTime: 0:00:56.354973 FixedProfit: 1213551\n",
            "Episode: 54/100 RapTime: 0:00:55.935278 FixedProfit: 980799\n",
            "Episode: 55/100 RapTime: 0:00:55.166780 FixedProfit: 1299210\n",
            "Episode: 56/100 RapTime: 0:00:54.139928 FixedProfit: 1015249\n",
            "Episode: 57/100 RapTime: 0:00:53.816453 FixedProfit: 1046096\n",
            "Episode: 58/100 RapTime: 0:00:54.284180 FixedProfit: 1303480\n",
            "Episode: 59/100 RapTime: 0:00:54.227442 FixedProfit: 1146141\n",
            "Episode: 60/100 RapTime: 0:00:54.390247 FixedProfit: 1025297\n",
            "Episode: 61/100 RapTime: 0:00:54.322112 FixedProfit: 1000172\n",
            "Episode: 62/100 RapTime: 0:00:54.383767 FixedProfit: 994211\n",
            "Episode: 63/100 RapTime: 0:00:54.689798 FixedProfit: 1191444\n",
            "Episode: 64/100 RapTime: 0:00:54.689718 FixedProfit: 1103242\n",
            "Episode: 65/100 RapTime: 0:00:54.570569 FixedProfit: 1133219\n",
            "Episode: 66/100 RapTime: 0:00:54.719068 FixedProfit: 1028990\n",
            "Episode: 67/100 RapTime: 0:00:54.946916 FixedProfit: 1041632\n",
            "Episode: 68/100 RapTime: 0:00:54.541083 FixedProfit: 971218\n",
            "Episode: 69/100 RapTime: 0:00:56.398356 FixedProfit: 1198041\n",
            "Episode: 70/100 RapTime: 0:00:57.232194 FixedProfit: 1028388\n",
            "Episode: 71/100 RapTime: 0:00:56.899751 FixedProfit: 1059946\n",
            "Episode: 72/100 RapTime: 0:00:57.073504 FixedProfit: 1072788\n",
            "Episode: 73/100 RapTime: 0:00:56.506764 FixedProfit: 1322364\n",
            "Episode: 74/100 RapTime: 0:00:54.852299 FixedProfit: 1045780\n",
            "Episode: 75/100 RapTime: 0:00:54.950311 FixedProfit: 1266142\n",
            "Episode: 76/100 RapTime: 0:00:54.853951 FixedProfit: 1054353\n",
            "Episode: 77/100 RapTime: 0:00:55.287837 FixedProfit: 1027612\n",
            "Episode: 78/100 RapTime: 0:00:54.899495 FixedProfit: 1228082\n",
            "Episode: 79/100 RapTime: 0:00:55.278095 FixedProfit: 1134373\n",
            "Episode: 80/100 RapTime: 0:00:54.940436 FixedProfit: 1151573\n",
            "Episode: 81/100 RapTime: 0:00:55.030892 FixedProfit: 1077111\n",
            "Episode: 82/100 RapTime: 0:00:55.076875 FixedProfit: 1124637\n",
            "Episode: 83/100 RapTime: 0:00:55.560311 FixedProfit: 1002858\n",
            "Episode: 84/100 RapTime: 0:00:56.147755 FixedProfit: 1222700\n",
            "Episode: 85/100 RapTime: 0:00:54.959691 FixedProfit: 1081568\n",
            "Episode: 86/100 RapTime: 0:00:55.509549 FixedProfit: 1041816\n",
            "Episode: 87/100 RapTime: 0:00:57.179000 FixedProfit: 1121188\n",
            "Episode: 88/100 RapTime: 0:00:57.163347 FixedProfit: 1297642\n",
            "Episode: 89/100 RapTime: 0:00:56.923953 FixedProfit: 985708\n",
            "Episode: 90/100 RapTime: 0:00:56.711214 FixedProfit: 1038148\n",
            "Episode: 91/100 RapTime: 0:00:55.195152 FixedProfit: 1011247\n",
            "Episode: 92/100 RapTime: 0:00:54.573675 FixedProfit: 1210118\n",
            "Episode: 93/100 RapTime: 0:00:54.430421 FixedProfit: 1217018\n",
            "Episode: 94/100 RapTime: 0:00:54.281482 FixedProfit: 1383157\n",
            "Episode: 95/100 RapTime: 0:00:54.613641 FixedProfit: 986527\n",
            "Episode: 96/100 RapTime: 0:00:54.487283 FixedProfit: 1145842\n",
            "Episode: 97/100 RapTime: 0:00:54.417655 FixedProfit: 852187\n",
            "Episode: 98/100 RapTime: 0:00:54.555421 FixedProfit: 1104865\n",
            "Episode: 99/100 RapTime: 0:00:54.452031 FixedProfit: 990237\n",
            "Episode: 100/100 RapTime: 0:00:54.773357 FixedProfit: 1034753\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}