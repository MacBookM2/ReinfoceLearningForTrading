{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNhwy8KzdoUN1T7l0ybNhB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "597a42d6-a634-4178-81e6-bd20ff3a5594"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'test'\n",
        "name = 'qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        target = np.copy(q)\n",
        "        if done:\n",
        "            target[:, action] = reward\n",
        "        else:\n",
        "            target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, target)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.agent.train(state, action, reward, next_state, done)\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "652ec167-2a32-40aa-d8cf-c01a112d5c67"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:27.113806 FixedProfit: 1080390 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 2/100 RapTime: 0:00:26.842171 FixedProfit: 1142946 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 3/100 RapTime: 0:00:27.364317 FixedProfit: 1386782 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 4/100 RapTime: 0:00:25.939893 FixedProfit: 1111176 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 5/100 RapTime: 0:00:26.831606 FixedProfit: 1143613 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 6/100 RapTime: 0:00:26.721964 FixedProfit: 1425681 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 7/100 RapTime: 0:00:25.713558 FixedProfit: 1195447 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 8/100 RapTime: 0:00:27.277441 FixedProfit: 1124115 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 9/100 RapTime: 0:00:25.818809 FixedProfit: 1120597 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 10/100 RapTime: 0:00:26.628051 FixedProfit: 799573 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 11/100 RapTime: 0:00:26.648011 FixedProfit: 906115 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 12/100 RapTime: 0:00:26.148846 FixedProfit: 1334662 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 13/100 RapTime: 0:00:27.150613 FixedProfit: 1446211 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 14/100 RapTime: 0:00:26.022784 FixedProfit: 1124235 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 15/100 RapTime: 0:00:26.802476 FixedProfit: 1220769 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 16/100 RapTime: 0:00:27.097629 FixedProfit: 1502637 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 17/100 RapTime: 0:00:26.986817 FixedProfit: 1144403 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 18/100 RapTime: 0:00:25.874247 FixedProfit: 1214328 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 19/100 RapTime: 0:00:27.021229 FixedProfit: 1352969 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 20/100 RapTime: 0:00:26.170409 FixedProfit: 996438 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 21/100 RapTime: 0:00:26.319249 FixedProfit: 1209162 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 22/100 RapTime: 0:00:26.836454 FixedProfit: 1263639 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 23/100 RapTime: 0:00:26.053211 FixedProfit: 1091138 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 24/100 RapTime: 0:00:27.098145 FixedProfit: 1110929 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 25/100 RapTime: 0:00:26.254554 FixedProfit: 1180988 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 26/100 RapTime: 0:00:26.374260 FixedProfit: 1154988 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 27/100 RapTime: 0:00:27.119562 FixedProfit: 873391 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 28/100 RapTime: 0:00:27.147876 FixedProfit: 1002432 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 29/100 RapTime: 0:00:25.630643 FixedProfit: 1360060 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 30/100 RapTime: 0:00:27.027875 FixedProfit: 1176823 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 31/100 RapTime: 0:00:26.447174 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 32/100 RapTime: 0:00:26.268882 FixedProfit: 1247598 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 33/100 RapTime: 0:00:27.142048 FixedProfit: 1067314 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 34/100 RapTime: 0:00:25.934797 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 35/100 RapTime: 0:00:26.946566 FixedProfit: 1336809 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 36/100 RapTime: 0:00:26.711329 FixedProfit: 1112442 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:00:26.153004 FixedProfit: 1369866 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 38/100 RapTime: 0:00:27.161710 FixedProfit: 1364851 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 39/100 RapTime: 0:00:25.993275 FixedProfit: 1030596 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 40/100 RapTime: 0:00:26.822844 FixedProfit: 1287439 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 41/100 RapTime: 0:00:27.181621 FixedProfit: 1190862 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 42/100 RapTime: 0:00:26.716971 FixedProfit: 1072358 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 43/100 RapTime: 0:00:25.979201 FixedProfit: 1380836 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 44/100 RapTime: 0:00:27.547276 FixedProfit: 1361975 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 45/100 RapTime: 0:00:26.002469 FixedProfit: 1192840 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 46/100 RapTime: 0:00:26.377108 FixedProfit: 1165585 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 47/100 RapTime: 0:00:27.179046 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 48/100 RapTime: 0:00:25.971325 FixedProfit: 1334038 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 49/100 RapTime: 0:00:27.190962 FixedProfit: 1345956 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 50/100 RapTime: 0:00:25.958342 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 51/100 RapTime: 0:00:26.692711 FixedProfit: 1032550 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 52/100 RapTime: 0:00:27.263073 FixedProfit: 1188515 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 53/100 RapTime: 0:00:26.733814 FixedProfit: 1016898 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 54/100 RapTime: 0:00:25.929382 FixedProfit: 1083716 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 55/100 RapTime: 0:00:27.190850 FixedProfit: 1321085 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 56/100 RapTime: 0:00:25.948396 FixedProfit: 1135935 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 57/100 RapTime: 0:00:26.525198 FixedProfit: 1165134 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 58/100 RapTime: 0:00:27.041178 FixedProfit: 1169139 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 59/100 RapTime: 0:00:26.182360 FixedProfit: 1368470 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 60/100 RapTime: 0:00:27.184030 FixedProfit: 1274647 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 61/100 RapTime: 0:00:26.146376 FixedProfit: 1107371 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 62/100 RapTime: 0:00:26.241690 FixedProfit: 1560690 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 63/100 RapTime: 0:00:26.913014 FixedProfit: 1069247 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 64/100 RapTime: 0:00:25.973721 FixedProfit: 953087 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 65/100 RapTime: 0:00:26.984697 FixedProfit: 1316522 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 66/100 RapTime: 0:00:26.958465 FixedProfit: 1209427 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 67/100 RapTime: 0:00:26.378405 FixedProfit: 1128711 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 68/100 RapTime: 0:00:26.071504 FixedProfit: 956943 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 69/100 RapTime: 0:00:26.997081 FixedProfit: 1104366 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 70/100 RapTime: 0:00:26.007214 FixedProfit: 1030067 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 71/100 RapTime: 0:00:26.712982 FixedProfit: 1047939 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 72/100 RapTime: 0:00:26.485153 FixedProfit: 1221789 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 73/100 RapTime: 0:00:26.065359 FixedProfit: 812825 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 74/100 RapTime: 0:00:27.056033 FixedProfit: 1127208 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 75/100 RapTime: 0:00:26.112919 FixedProfit: 1050476 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 76/100 RapTime: 0:00:26.624127 FixedProfit: 1015946 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 77/100 RapTime: 0:00:26.924647 FixedProfit: 1414078 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 78/100 RapTime: 0:00:26.784194 FixedProfit: 1052304 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 79/100 RapTime: 0:00:26.014929 FixedProfit: 1278418 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 80/100 RapTime: 0:00:27.284245 FixedProfit: 1261878 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 81/100 RapTime: 0:00:26.070093 FixedProfit: 991201 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 82/100 RapTime: 0:00:26.283084 FixedProfit: 1242489 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 83/100 RapTime: 0:00:26.730376 FixedProfit: 1455584 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 84/100 RapTime: 0:00:26.044591 FixedProfit: 766481 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 85/100 RapTime: 0:00:27.369765 FixedProfit: 1088407 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 86/100 RapTime: 0:00:25.902982 FixedProfit: 1579640 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 87/100 RapTime: 0:00:26.409566 FixedProfit: 1219554 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 88/100 RapTime: 0:00:26.773683 FixedProfit: 992666 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 89/100 RapTime: 0:00:26.937314 FixedProfit: 1076474 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 90/100 RapTime: 0:00:25.843612 FixedProfit: 1018967 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 91/100 RapTime: 0:00:27.082884 FixedProfit: 1041877 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 92/100 RapTime: 0:00:26.313708 FixedProfit: 1479096 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 93/100 RapTime: 0:00:26.311019 FixedProfit: 1217548 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 94/100 RapTime: 0:00:27.099539 FixedProfit: 1079872 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 95/100 RapTime: 0:00:26.089375 FixedProfit: 1327439 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 96/100 RapTime: 0:00:27.041348 FixedProfit: 1135826 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 97/100 RapTime: 0:00:26.411287 FixedProfit: 1102790 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 98/100 RapTime: 0:00:25.956472 FixedProfit: 867569 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 99/100 RapTime: 0:00:27.260090 FixedProfit: 902700 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 100/100 RapTime: 0:00:26.270474 FixedProfit: 1058646 TradeTimes: 3 TradeWin: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}