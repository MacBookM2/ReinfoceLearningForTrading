{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ddqn_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNli2Ln2acVXJOJGDuzPJad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/ddqn_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "05b61318-7817-4662-f564-ac5c40383a05"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "mode = 'train'\n",
        "name = 'ddqn'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evsq8JqfWNoj"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "\n",
        "        self.cntr = 0\n",
        "        self.size = 0\n",
        "        self.max_size = max_size\n",
        "        self.batch_size = batch_size\n",
        "        self.states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.next_states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.acts_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "        self.rewards_memory = np.zeros(self.max_size, dtype=np.float32)\n",
        "        self.done_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        self.states_memory[self.cntr] = state\n",
        "        self.next_states_memory[self.cntr] = next_state\n",
        "        self.acts_memory[self.cntr] = act\n",
        "        self.rewards_memory[self.cntr] = reward\n",
        "        self.done_memory[self.cntr] = done\n",
        "        self.cntr = (self.cntr+1) % self.max_size\n",
        "        self.size = min(self.size+1, self.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(self.size, self.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [self.states_memory[mb_index],self.next_states_memory[mb_index],\n",
        "                 self.acts_memory[mb_index],self.rewards_memory[mb_index],\n",
        "                 self.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        model1 = Sequential()\n",
        "        model1.add(Dense(3, input_shape=(3,)))\n",
        "        model1.add(ReLU()) \n",
        "        model1.add(Dense(3))\n",
        "        model1.add(ReLU()) \n",
        "        model1.add(Dense(3))\n",
        "        model1.compile(loss=\"mse\", optimizer=optimizer)\n",
        "        model1.summary()\n",
        "        self.model1 = model1\n",
        "\n",
        "        model2 = Sequential()\n",
        "        model2.add(Dense(3, input_shape=(3,)))\n",
        "        model2.add(ReLU()) \n",
        "        model2.add(Dense(3))\n",
        "        model2.add(ReLU()) \n",
        "        model2.add(Dense(3))\n",
        "        model2.compile(loss=\"mse\", optimizer=optimizer)\n",
        "        model2.summary()\n",
        "        self.model2 = model2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain, ReplayMemory):\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "        self.batch_size = batch_size\n",
        "        Brain.__init__(self)\n",
        "        ReplayMemory.__init__(self, max_size, batch_size)\n",
        "\n",
        "    def update_replay_memory(self, state, action, reward, next_state, done):\n",
        "        self.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "    def act(self, state,s_flag=12):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state,s_flag)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def predict(self, state, s_flag = 12):\n",
        "        values = None\n",
        "        q1 = self.model1.predict(state)\n",
        "        q2 = self.model2.predict(state)\n",
        "        if s_flag == 12:\n",
        "            values = np.array([q1[0,a] + q2[0,a] for a in range(2)])\n",
        "        elif s_flag == 11:\n",
        "            values = np.array([q1[0,a] + q1[0,a] for a in range(2)])\n",
        "        else:\n",
        "            values = np.array([q2[0,a] + q2[0,a] for a in range(2)])\n",
        "        return values\n",
        "\n",
        "    def replay(self, s_flag):\n",
        "        if self.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "\n",
        "        '''\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.model.predict(next_states), axis=1)\n",
        "        target_full = self.model.predict(states)\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.model.train_on_batch(states, target_full)\n",
        "        '''\n",
        "\n",
        "        next_act_values = self.model1.predict(next_states,s_flag)\n",
        "        next_action =np.argmax(next_act_values)\n",
        "\n",
        "        if s_flag == 11:\n",
        "            q = self.model1.predict(states)  \n",
        "            next_q = self.model2.predict(next_states)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            target[:, actions] = rewards + (1 - done) * self.gamma*np.max(next_q, axis=1)\n",
        "            self.model1.train_on_batch(states, target)\n",
        "        else:\n",
        "            q = self.model2.predict(states)  \n",
        "            next_q = self.model1.predict(next_states)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            target[:, actions] = rewards + (1 - done) * self.gamma*np.max(next_q, axis=1)\n",
        "            self.model2.train_on_batch(states, target)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "\n",
        "    def load(self, name, name2):\n",
        "        self.model1.load_weights(name)\n",
        "        self.model2.load_weights(name2)\n",
        "\n",
        "    def save(self, name, name2):\n",
        "        self.model1.save_weights(name)\n",
        "        self.model2.save_weights(name2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 200, mode = 'test'):\n",
        "        self.env            = env\n",
        "        self.agent          = agent\n",
        "        self.mdl_dir        = mdl_dir\n",
        "        self.scaler         = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode           = mode\n",
        "        self.name           = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done  = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                s_flag = 12\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    rand = np.random.random()\n",
        "                    if rand <= 0.5:\n",
        "                        s_flag = 11\n",
        "                    else:\n",
        "                        s_flag = 22\n",
        "                    self.agent.update_replay_memory(state, action, reward, next_state, done)\n",
        "                    self.agent.replay(s_flag)                \n",
        "            play_time = datetime.now() - start_time\n",
        "\n",
        "            if self.mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}_1.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}_1.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "9f2960ca-c150-4497-c1e5-f76181040e0c"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 200\n",
        "batch_size = 32\n",
        "max_size = 500\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "agent = Agent(max_size, batch_size)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Episode: 1/200 RapTime: 0:01:24.669779 FixedProfit: 1222932\n",
            "Episode: 2/200 RapTime: 0:01:36.342231 FixedProfit: 1207601\n",
            "Episode: 3/200 RapTime: 0:01:36.256368 FixedProfit: 1184177\n",
            "Episode: 4/200 RapTime: 0:01:36.616891 FixedProfit: 1206001\n",
            "Episode: 5/200 RapTime: 0:01:36.452543 FixedProfit: 1177871\n",
            "Episode: 6/200 RapTime: 0:01:36.540956 FixedProfit: 1190983\n",
            "Episode: 7/200 RapTime: 0:01:36.720194 FixedProfit: 1217645\n",
            "Episode: 8/200 RapTime: 0:01:36.614251 FixedProfit: 1197165\n",
            "Episode: 9/200 RapTime: 0:01:36.787421 FixedProfit: 1198391\n",
            "Episode: 10/200 RapTime: 0:01:36.472368 FixedProfit: 1193690\n",
            "Episode: 11/200 RapTime: 0:01:36.509775 FixedProfit: 1198058\n",
            "Episode: 12/200 RapTime: 0:01:36.060666 FixedProfit: 1197813\n",
            "Episode: 13/200 RapTime: 0:01:35.988909 FixedProfit: 1223257\n",
            "Episode: 14/200 RapTime: 0:01:36.247273 FixedProfit: 1200887\n",
            "Episode: 15/200 RapTime: 0:01:36.552207 FixedProfit: 1142493\n",
            "Episode: 16/200 RapTime: 0:01:36.642987 FixedProfit: 1189362\n",
            "Episode: 17/200 RapTime: 0:01:36.827731 FixedProfit: 1199409\n",
            "Episode: 18/200 RapTime: 0:01:36.286040 FixedProfit: 1196167\n",
            "Episode: 19/200 RapTime: 0:01:36.077209 FixedProfit: 1191518\n",
            "Episode: 20/200 RapTime: 0:01:36.237101 FixedProfit: 1207664\n",
            "Episode: 21/200 RapTime: 0:01:36.343885 FixedProfit: 1215325\n",
            "Episode: 22/200 RapTime: 0:01:36.149065 FixedProfit: 1195333\n",
            "Episode: 23/200 RapTime: 0:01:36.315741 FixedProfit: 1211477\n",
            "Episode: 24/200 RapTime: 0:01:36.566030 FixedProfit: 1220929\n",
            "Episode: 25/200 RapTime: 0:01:36.707419 FixedProfit: 1171391\n",
            "Episode: 26/200 RapTime: 0:01:36.254815 FixedProfit: 1220512\n",
            "Episode: 27/200 RapTime: 0:01:37.016236 FixedProfit: 1181848\n",
            "Episode: 28/200 RapTime: 0:01:36.078481 FixedProfit: 1192368\n",
            "Episode: 29/200 RapTime: 0:01:36.575442 FixedProfit: 1197165\n",
            "Episode: 30/200 RapTime: 0:01:37.409163 FixedProfit: 1200835\n",
            "Episode: 31/200 RapTime: 0:01:36.495767 FixedProfit: 1195629\n",
            "Episode: 32/200 RapTime: 0:01:36.723491 FixedProfit: 1198517\n",
            "Episode: 33/200 RapTime: 0:01:36.689549 FixedProfit: 1197165\n",
            "Episode: 34/200 RapTime: 0:01:36.448506 FixedProfit: 1190333\n",
            "Episode: 35/200 RapTime: 0:01:36.563452 FixedProfit: 1210959\n",
            "Episode: 36/200 RapTime: 0:01:36.871024 FixedProfit: 1198793\n",
            "Episode: 37/200 RapTime: 0:01:36.109047 FixedProfit: 1191071\n",
            "Episode: 38/200 RapTime: 0:01:36.434785 FixedProfit: 1198241\n",
            "Episode: 39/200 RapTime: 0:01:36.424032 FixedProfit: 1196004\n",
            "Episode: 40/200 RapTime: 0:01:36.424866 FixedProfit: 1190899\n",
            "Episode: 41/200 RapTime: 0:01:36.926678 FixedProfit: 1205038\n",
            "Episode: 42/200 RapTime: 0:01:36.634760 FixedProfit: 1196513\n",
            "Episode: 43/200 RapTime: 0:01:36.712994 FixedProfit: 1187542\n",
            "Episode: 44/200 RapTime: 0:01:36.803031 FixedProfit: 1200692\n",
            "Episode: 45/200 RapTime: 0:01:36.280915 FixedProfit: 1199704\n",
            "Episode: 46/200 RapTime: 0:01:36.421054 FixedProfit: 1262276\n",
            "Episode: 47/200 RapTime: 0:01:36.626676 FixedProfit: 1205627\n",
            "Episode: 48/200 RapTime: 0:01:36.932017 FixedProfit: 1197165\n",
            "Episode: 49/200 RapTime: 0:01:36.710493 FixedProfit: 1198430\n",
            "Episode: 50/200 RapTime: 0:01:36.718334 FixedProfit: 1197165\n",
            "Episode: 51/200 RapTime: 0:01:36.358209 FixedProfit: 1193618\n",
            "Episode: 52/200 RapTime: 0:01:36.366686 FixedProfit: 1210735\n",
            "Episode: 53/200 RapTime: 0:01:36.595453 FixedProfit: 1200276\n",
            "Episode: 54/200 RapTime: 0:01:36.705591 FixedProfit: 1181462\n",
            "Episode: 55/200 RapTime: 0:01:36.087949 FixedProfit: 1203544\n",
            "Episode: 56/200 RapTime: 0:01:36.569231 FixedProfit: 1197165\n",
            "Episode: 57/200 RapTime: 0:01:37.007874 FixedProfit: 1197165\n",
            "Episode: 58/200 RapTime: 0:01:36.576775 FixedProfit: 1200276\n",
            "Episode: 59/200 RapTime: 0:01:36.887512 FixedProfit: 1197165\n",
            "Episode: 60/200 RapTime: 0:01:36.639879 FixedProfit: 1199037\n",
            "Episode: 61/200 RapTime: 0:01:36.376723 FixedProfit: 1206619\n",
            "Episode: 62/200 RapTime: 0:01:36.889432 FixedProfit: 1186825\n",
            "Episode: 63/200 RapTime: 0:01:36.702399 FixedProfit: 1221538\n",
            "Episode: 64/200 RapTime: 0:01:36.262813 FixedProfit: 1183304\n",
            "Episode: 65/200 RapTime: 0:01:36.831343 FixedProfit: 1197165\n",
            "Episode: 66/200 RapTime: 0:01:36.733011 FixedProfit: 1202131\n",
            "Episode: 67/200 RapTime: 0:01:36.148116 FixedProfit: 1203185\n",
            "Episode: 68/200 RapTime: 0:01:36.631085 FixedProfit: 1184233\n",
            "Episode: 69/200 RapTime: 0:01:36.481715 FixedProfit: 1207807\n",
            "Episode: 70/200 RapTime: 0:01:36.532998 FixedProfit: 1191259\n",
            "Episode: 71/200 RapTime: 0:01:36.609140 FixedProfit: 1173823\n",
            "Episode: 72/200 RapTime: 0:01:36.556809 FixedProfit: 1179586\n",
            "Episode: 73/200 RapTime: 0:01:36.678696 FixedProfit: 1197165\n",
            "Episode: 74/200 RapTime: 0:01:36.436078 FixedProfit: 1203108\n",
            "Episode: 75/200 RapTime: 0:01:36.608626 FixedProfit: 1203114\n",
            "Episode: 76/200 RapTime: 0:01:36.126540 FixedProfit: 1186625\n",
            "Episode: 77/200 RapTime: 0:01:36.638355 FixedProfit: 1196133\n",
            "Episode: 78/200 RapTime: 0:01:37.302078 FixedProfit: 1184151\n",
            "Episode: 79/200 RapTime: 0:01:36.384439 FixedProfit: 1198525\n",
            "Episode: 80/200 RapTime: 0:01:36.258256 FixedProfit: 1190021\n",
            "Episode: 81/200 RapTime: 0:01:36.645842 FixedProfit: 1197165\n",
            "Episode: 82/200 RapTime: 0:01:36.432248 FixedProfit: 1197165\n",
            "Episode: 83/200 RapTime: 0:01:36.262453 FixedProfit: 1188307\n",
            "Episode: 84/200 RapTime: 0:01:36.208928 FixedProfit: 1192120\n",
            "Episode: 85/200 RapTime: 0:01:33.313482 FixedProfit: 1196958\n",
            "Episode: 86/200 RapTime: 0:01:33.042172 FixedProfit: 1202790\n",
            "Episode: 87/200 RapTime: 0:01:32.474827 FixedProfit: 1210174\n",
            "Episode: 88/200 RapTime: 0:01:33.167265 FixedProfit: 1194980\n",
            "Episode: 89/200 RapTime: 0:01:32.318803 FixedProfit: 1212321\n",
            "Episode: 90/200 RapTime: 0:01:32.465500 FixedProfit: 1200686\n",
            "Episode: 91/200 RapTime: 0:01:32.569450 FixedProfit: 1212546\n",
            "Episode: 92/200 RapTime: 0:01:32.837882 FixedProfit: 1180839\n",
            "Episode: 93/200 RapTime: 0:01:32.996046 FixedProfit: 1218225\n",
            "Episode: 94/200 RapTime: 0:01:33.553244 FixedProfit: 1203818\n",
            "Episode: 95/200 RapTime: 0:01:33.191292 FixedProfit: 1176202\n",
            "Episode: 96/200 RapTime: 0:01:33.050774 FixedProfit: 1216585\n",
            "Episode: 97/200 RapTime: 0:01:33.210722 FixedProfit: 1197165\n",
            "Episode: 98/200 RapTime: 0:01:32.702791 FixedProfit: 1197714\n",
            "Episode: 99/200 RapTime: 0:01:32.897801 FixedProfit: 1188284\n",
            "Episode: 100/200 RapTime: 0:01:32.514040 FixedProfit: 1201166\n",
            "Episode: 101/200 RapTime: 0:01:32.816276 FixedProfit: 1185965\n",
            "Episode: 102/200 RapTime: 0:01:32.889179 FixedProfit: 1195886\n",
            "Episode: 103/200 RapTime: 0:01:34.658529 FixedProfit: 1192432\n",
            "Episode: 104/200 RapTime: 0:01:32.674443 FixedProfit: 1201731\n",
            "Episode: 105/200 RapTime: 0:01:33.536943 FixedProfit: 1199725\n",
            "Episode: 106/200 RapTime: 0:01:32.700397 FixedProfit: 1191781\n",
            "Episode: 107/200 RapTime: 0:01:34.682900 FixedProfit: 1200839\n",
            "Episode: 108/200 RapTime: 0:01:33.681084 FixedProfit: 1185268\n",
            "Episode: 109/200 RapTime: 0:01:32.803860 FixedProfit: 1199685\n",
            "Episode: 110/200 RapTime: 0:01:33.074152 FixedProfit: 1192362\n",
            "Episode: 111/200 RapTime: 0:01:33.123688 FixedProfit: 1180544\n",
            "Episode: 112/200 RapTime: 0:01:32.689098 FixedProfit: 1201750\n",
            "Episode: 113/200 RapTime: 0:01:32.915613 FixedProfit: 1197165\n",
            "Episode: 114/200 RapTime: 0:01:33.015531 FixedProfit: 1199131\n",
            "Episode: 115/200 RapTime: 0:01:33.639837 FixedProfit: 1179981\n",
            "Episode: 116/200 RapTime: 0:01:33.272683 FixedProfit: 1192058\n",
            "Episode: 117/200 RapTime: 0:01:32.805552 FixedProfit: 1185187\n",
            "Episode: 118/200 RapTime: 0:01:33.341389 FixedProfit: 1197165\n",
            "Episode: 119/200 RapTime: 0:01:32.932406 FixedProfit: 1210252\n",
            "Episode: 120/200 RapTime: 0:01:32.950058 FixedProfit: 1202975\n",
            "Episode: 121/200 RapTime: 0:01:32.980821 FixedProfit: 1185054\n",
            "Episode: 122/200 RapTime: 0:01:32.702937 FixedProfit: 1196824\n",
            "Episode: 123/200 RapTime: 0:01:32.931232 FixedProfit: 1194368\n",
            "Episode: 124/200 RapTime: 0:01:32.971718 FixedProfit: 1208148\n",
            "Episode: 125/200 RapTime: 0:01:33.040147 FixedProfit: 1184352\n",
            "Episode: 126/200 RapTime: 0:01:32.802491 FixedProfit: 1197338\n",
            "Episode: 127/200 RapTime: 0:01:32.920898 FixedProfit: 1184677\n",
            "Episode: 128/200 RapTime: 0:01:33.355509 FixedProfit: 1201495\n",
            "Episode: 129/200 RapTime: 0:01:33.073328 FixedProfit: 1207868\n",
            "Episode: 130/200 RapTime: 0:01:32.963674 FixedProfit: 1197165\n",
            "Episode: 131/200 RapTime: 0:01:33.206685 FixedProfit: 1181710\n",
            "Episode: 132/200 RapTime: 0:01:32.746739 FixedProfit: 1211238\n",
            "Episode: 133/200 RapTime: 0:01:32.694548 FixedProfit: 1190799\n",
            "Episode: 134/200 RapTime: 0:01:32.861852 FixedProfit: 1199268\n",
            "Episode: 135/200 RapTime: 0:01:32.957496 FixedProfit: 1198793\n",
            "Episode: 136/200 RapTime: 0:01:32.657327 FixedProfit: 1191271\n",
            "Episode: 137/200 RapTime: 0:01:32.590466 FixedProfit: 1170749\n",
            "Episode: 138/200 RapTime: 0:01:32.629679 FixedProfit: 1190162\n",
            "Episode: 139/200 RapTime: 0:01:32.801898 FixedProfit: 1203522\n",
            "Episode: 140/200 RapTime: 0:01:32.706622 FixedProfit: 1206510\n",
            "Episode: 141/200 RapTime: 0:01:32.938261 FixedProfit: 1184700\n",
            "Episode: 142/200 RapTime: 0:01:32.781043 FixedProfit: 1198778\n",
            "Episode: 143/200 RapTime: 0:01:32.985985 FixedProfit: 1189854\n",
            "Episode: 144/200 RapTime: 0:01:33.077735 FixedProfit: 1193760\n",
            "Episode: 145/200 RapTime: 0:01:33.583855 FixedProfit: 1208636\n",
            "Episode: 146/200 RapTime: 0:01:33.345307 FixedProfit: 1202979\n",
            "Episode: 147/200 RapTime: 0:01:33.484958 FixedProfit: 1219838\n",
            "Episode: 148/200 RapTime: 0:01:33.264541 FixedProfit: 1189856\n",
            "Episode: 149/200 RapTime: 0:01:32.795603 FixedProfit: 1197165\n",
            "Episode: 150/200 RapTime: 0:01:33.101453 FixedProfit: 1214122\n",
            "Episode: 151/200 RapTime: 0:01:32.934611 FixedProfit: 1205181\n",
            "Episode: 152/200 RapTime: 0:01:32.913433 FixedProfit: 1197165\n",
            "Episode: 153/200 RapTime: 0:01:32.631943 FixedProfit: 1208795\n",
            "Episode: 154/200 RapTime: 0:01:33.336376 FixedProfit: 1186141\n",
            "Episode: 155/200 RapTime: 0:01:33.132975 FixedProfit: 1194805\n",
            "Episode: 156/200 RapTime: 0:01:33.277559 FixedProfit: 1210562\n",
            "Episode: 157/200 RapTime: 0:01:32.994461 FixedProfit: 1194651\n",
            "Episode: 158/200 RapTime: 0:01:32.922052 FixedProfit: 1190268\n",
            "Episode: 159/200 RapTime: 0:01:32.854643 FixedProfit: 1205588\n",
            "Episode: 160/200 RapTime: 0:01:33.282646 FixedProfit: 1197165\n",
            "Episode: 161/200 RapTime: 0:01:34.737303 FixedProfit: 1186746\n",
            "Episode: 162/200 RapTime: 0:01:32.644708 FixedProfit: 1200689\n",
            "Episode: 163/200 RapTime: 0:01:32.537131 FixedProfit: 1200347\n",
            "Episode: 164/200 RapTime: 0:01:32.918744 FixedProfit: 1197165\n",
            "Episode: 165/200 RapTime: 0:01:32.419888 FixedProfit: 1203442\n",
            "Episode: 166/200 RapTime: 0:01:32.641391 FixedProfit: 1178289\n",
            "Episode: 167/200 RapTime: 0:01:32.841055 FixedProfit: 1190820\n",
            "Episode: 168/200 RapTime: 0:01:33.121777 FixedProfit: 1194812\n",
            "Episode: 169/200 RapTime: 0:01:32.934740 FixedProfit: 1195827\n",
            "Episode: 170/200 RapTime: 0:01:32.258023 FixedProfit: 1174674\n",
            "Episode: 171/200 RapTime: 0:01:32.989367 FixedProfit: 1220746\n",
            "Episode: 172/200 RapTime: 0:01:32.722976 FixedProfit: 1211048\n",
            "Episode: 173/200 RapTime: 0:01:32.885854 FixedProfit: 1185669\n",
            "Episode: 174/200 RapTime: 0:01:32.911889 FixedProfit: 1196002\n",
            "Episode: 175/200 RapTime: 0:01:32.841465 FixedProfit: 1200803\n",
            "Episode: 176/200 RapTime: 0:01:32.708297 FixedProfit: 1169987\n",
            "Episode: 177/200 RapTime: 0:01:33.190508 FixedProfit: 1191984\n",
            "Episode: 178/200 RapTime: 0:01:33.518709 FixedProfit: 1205724\n",
            "Episode: 179/200 RapTime: 0:01:32.766039 FixedProfit: 1207648\n",
            "Episode: 180/200 RapTime: 0:01:32.533877 FixedProfit: 1200795\n",
            "Episode: 181/200 RapTime: 0:01:32.598857 FixedProfit: 1197165\n",
            "Episode: 182/200 RapTime: 0:01:32.855514 FixedProfit: 1194651\n",
            "Episode: 183/200 RapTime: 0:01:32.396161 FixedProfit: 1191609\n",
            "Episode: 184/200 RapTime: 0:01:33.587428 FixedProfit: 1199121\n",
            "Episode: 185/200 RapTime: 0:01:40.261416 FixedProfit: 1207300\n",
            "Episode: 186/200 RapTime: 0:01:34.747488 FixedProfit: 1213499\n",
            "Episode: 187/200 RapTime: 0:01:33.696338 FixedProfit: 1199407\n",
            "Episode: 188/200 RapTime: 0:01:33.750706 FixedProfit: 1201400\n",
            "Episode: 189/200 RapTime: 0:01:33.841167 FixedProfit: 1199222\n",
            "Episode: 190/200 RapTime: 0:01:34.075564 FixedProfit: 1186722\n",
            "Episode: 191/200 RapTime: 0:01:34.195989 FixedProfit: 1195906\n",
            "Episode: 192/200 RapTime: 0:01:34.135650 FixedProfit: 1203110\n",
            "Episode: 193/200 RapTime: 0:01:33.965000 FixedProfit: 1187815\n",
            "Episode: 194/200 RapTime: 0:01:33.766212 FixedProfit: 1187361\n",
            "Episode: 195/200 RapTime: 0:01:33.669442 FixedProfit: 1196375\n",
            "Episode: 196/200 RapTime: 0:01:33.700473 FixedProfit: 1219652\n",
            "Episode: 197/200 RapTime: 0:01:33.695795 FixedProfit: 1179824\n",
            "Episode: 198/200 RapTime: 0:01:33.957040 FixedProfit: 1206876\n",
            "Episode: 199/200 RapTime: 0:01:33.724147 FixedProfit: 1198010\n",
            "Episode: 200/200 RapTime: 0:01:33.483827 FixedProfit: 1201548\n"
          ]
        }
      ]
    }
  ]
}