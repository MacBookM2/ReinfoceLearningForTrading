{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNOMenGLAS+nArF++WYN555",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "7c370c42-1c5f-4679-97e0-6036c2d75ded"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_test.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'qlearning_test.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self):\n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "        else:\n",
        "            if self.action_space[0] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1 \n",
        "            if self.action_space[2] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        self.brain.train(state, action, reward, next_state, done)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "\n",
        "            if mode == 'train':\n",
        "                agent.train(state, action, reward, next_state, done)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        state = next_state\n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "a0397e3b-325b-4d1e-9bfc-fbd6d5b3ab5f"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'test'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_ql.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_ql.h5')\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:27.516604 FixedProfit: 1012608 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 2/100 RapTime: 0:00:25.302690 FixedProfit: 991990 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 3/100 RapTime: 0:00:25.478049 FixedProfit: 1003127 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 4/100 RapTime: 0:00:26.260529 FixedProfit: 1019602 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 5/100 RapTime: 0:00:25.810302 FixedProfit: 988604 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 6/100 RapTime: 0:00:26.131748 FixedProfit: 1045327 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 7/100 RapTime: 0:00:26.329915 FixedProfit: 999057 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 8/100 RapTime: 0:00:25.871347 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 9/100 RapTime: 0:00:26.187237 FixedProfit: 1005364 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 10/100 RapTime: 0:00:26.088060 FixedProfit: 997199 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 11/100 RapTime: 0:00:26.107526 FixedProfit: 1002919 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 12/100 RapTime: 0:00:26.139674 FixedProfit: 1010287 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 13/100 RapTime: 0:00:26.066815 FixedProfit: 955275 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 14/100 RapTime: 0:00:26.114077 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 15/100 RapTime: 0:00:26.169247 FixedProfit: 994070 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 16/100 RapTime: 0:00:26.259507 FixedProfit: 996797 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 17/100 RapTime: 0:00:26.120592 FixedProfit: 998503 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 18/100 RapTime: 0:00:26.254580 FixedProfit: 980463 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 19/100 RapTime: 0:00:25.861648 FixedProfit: 966728 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 20/100 RapTime: 0:00:25.982675 FixedProfit: 996074 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 21/100 RapTime: 0:00:26.059489 FixedProfit: 1014449 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 22/100 RapTime: 0:00:26.251007 FixedProfit: 1001919 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 23/100 RapTime: 0:00:26.362460 FixedProfit: 996222 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 24/100 RapTime: 0:00:26.226383 FixedProfit: 987705 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 25/100 RapTime: 0:00:26.220480 FixedProfit: 1009518 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 26/100 RapTime: 0:00:26.086171 FixedProfit: 1019742 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 27/100 RapTime: 0:00:26.429240 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 28/100 RapTime: 0:00:26.170877 FixedProfit: 996703 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 29/100 RapTime: 0:00:25.858318 FixedProfit: 982563 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 30/100 RapTime: 0:00:26.217164 FixedProfit: 1006148 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 31/100 RapTime: 0:00:26.114953 FixedProfit: 996303 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 32/100 RapTime: 0:00:26.286433 FixedProfit: 1024550 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 33/100 RapTime: 0:00:25.949165 FixedProfit: 1000335 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 34/100 RapTime: 0:00:25.856281 FixedProfit: 979831 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 35/100 RapTime: 0:00:26.030030 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 36/100 RapTime: 0:00:26.097136 FixedProfit: 1019337 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:00:26.081692 FixedProfit: 1007374 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 38/100 RapTime: 0:00:26.124986 FixedProfit: 1016780 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 39/100 RapTime: 0:00:26.072075 FixedProfit: 1002947 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 40/100 RapTime: 0:00:25.863473 FixedProfit: 997139 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 41/100 RapTime: 0:00:25.949565 FixedProfit: 991061 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 42/100 RapTime: 0:00:26.083861 FixedProfit: 964853 TradeTimes: 7 TradeWin: 2\n",
            "Episode: 43/100 RapTime: 0:00:26.001512 FixedProfit: 999733 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 44/100 RapTime: 0:00:26.157263 FixedProfit: 1032799 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 45/100 RapTime: 0:00:26.066587 FixedProfit: 998233 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 46/100 RapTime: 0:00:26.067063 FixedProfit: 1003498 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 47/100 RapTime: 0:00:25.300766 FixedProfit: 1013451 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 48/100 RapTime: 0:00:25.396265 FixedProfit: 1078999 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 49/100 RapTime: 0:00:26.005557 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 50/100 RapTime: 0:00:26.185213 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 51/100 RapTime: 0:00:26.403207 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 52/100 RapTime: 0:00:26.035551 FixedProfit: 1012683 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 53/100 RapTime: 0:00:25.943993 FixedProfit: 1003126 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 54/100 RapTime: 0:00:25.909059 FixedProfit: 1048005 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 55/100 RapTime: 0:00:25.931411 FixedProfit: 1021095 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 56/100 RapTime: 0:00:25.915311 FixedProfit: 1015102 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 57/100 RapTime: 0:00:26.116005 FixedProfit: 974351 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 58/100 RapTime: 0:00:25.794106 FixedProfit: 995254 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 59/100 RapTime: 0:00:25.908718 FixedProfit: 1005394 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 60/100 RapTime: 0:00:26.256732 FixedProfit: 1008975 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 61/100 RapTime: 0:00:25.994544 FixedProfit: 1004984 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 62/100 RapTime: 0:00:26.084330 FixedProfit: 975099 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 63/100 RapTime: 0:00:26.279223 FixedProfit: 991879 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 64/100 RapTime: 0:00:26.266373 FixedProfit: 1019443 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 65/100 RapTime: 0:00:26.151322 FixedProfit: 1013982 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 66/100 RapTime: 0:00:26.121265 FixedProfit: 995551 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 67/100 RapTime: 0:00:25.842526 FixedProfit: 1004226 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 68/100 RapTime: 0:00:26.388956 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 69/100 RapTime: 0:00:26.519563 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 70/100 RapTime: 0:00:25.489093 FixedProfit: 1014254 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 71/100 RapTime: 0:00:25.432939 FixedProfit: 1008660 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 72/100 RapTime: 0:00:26.065021 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 73/100 RapTime: 0:00:25.914286 FixedProfit: 1009341 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 74/100 RapTime: 0:00:26.118000 FixedProfit: 1002056 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 75/100 RapTime: 0:00:26.355640 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 76/100 RapTime: 0:00:26.037689 FixedProfit: 976361 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 77/100 RapTime: 0:00:25.779267 FixedProfit: 991050 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 78/100 RapTime: 0:00:26.030474 FixedProfit: 1057562 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 79/100 RapTime: 0:00:25.916116 FixedProfit: 998845 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 80/100 RapTime: 0:00:26.085994 FixedProfit: 1009947 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 81/100 RapTime: 0:00:25.600399 FixedProfit: 1015884 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 82/100 RapTime: 0:00:25.995574 FixedProfit: 951266 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 83/100 RapTime: 0:00:25.996493 FixedProfit: 990668 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 84/100 RapTime: 0:00:25.831546 FixedProfit: 992346 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 85/100 RapTime: 0:00:26.001045 FixedProfit: 966565 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 86/100 RapTime: 0:00:25.793424 FixedProfit: 1007539 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 87/100 RapTime: 0:00:25.839295 FixedProfit: 1004600 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 88/100 RapTime: 0:00:25.887287 FixedProfit: 998301 TradeTimes: 7 TradeWin: 3\n",
            "Episode: 89/100 RapTime: 0:00:25.911655 FixedProfit: 1074450 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 90/100 RapTime: 0:00:25.815446 FixedProfit: 1020466 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 91/100 RapTime: 0:00:26.404164 FixedProfit: 964385 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 92/100 RapTime: 0:00:26.345266 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 93/100 RapTime: 0:00:25.901649 FixedProfit: 995955 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 94/100 RapTime: 0:00:26.121240 FixedProfit: 996261 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 95/100 RapTime: 0:00:25.843359 FixedProfit: 994638 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 96/100 RapTime: 0:00:25.858961 FixedProfit: 995085 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 97/100 RapTime: 0:00:26.209301 FixedProfit: 994764 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 98/100 RapTime: 0:00:25.869086 FixedProfit: 1004246 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 99/100 RapTime: 0:00:26.160721 FixedProfit: 1019611 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 100/100 RapTime: 0:00:26.069255 FixedProfit: 972152 TradeTimes: 2 TradeWin: 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}