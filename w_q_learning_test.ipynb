{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w_q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM2/eSdBLRtqqinP2f4a/0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/w_q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "c2760df9-e546-4d11-e7b0-cdb969f7e3ae"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'test'\n",
        "name = 'w_qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "    \n",
        "        model_2 = Sequential()\n",
        "        model_2.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_mid))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_action))\n",
        "        model_2.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model_2.summary()))\n",
        "        self.model_2 = model_2\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done, s_flag):\n",
        "\n",
        "        next_act_values = self.model.predict(next_state,s_flag)\n",
        "        next_action =np.argmax(next_act_values[0])\n",
        "\n",
        "        if s_flag == 11:\n",
        "            q = self.model.predict(state)  \n",
        "            next_q = self.model_2.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model.train_on_batch(state, target)\n",
        "        else:\n",
        "            q = self.model_2.predict(state)  \n",
        "            next_q = self.model.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model_2.train_on_batch(state, target)\n",
        "\n",
        "\n",
        "    def predict(self, state, s_flag = 12):\n",
        "        values = None\n",
        "        q1 = self.model.predict(state)\n",
        "        q2 = self.model_2.predict(state)\n",
        "        if s_flag == 12:\n",
        "            values = np.array([q1[0,a] + q2[0,a] for a in range(2)])\n",
        "        elif s_flag == 11:\n",
        "            values = np.array([q1[0,a] + q1[0,a] for a in range(2)])\n",
        "        else:\n",
        "            values = np.array([q2[0,a] + q2[0,a] for a in range(2)])\n",
        "        return values\n",
        "\n",
        "    def load(self, name, name2):\n",
        "        self.model.load_weights(name)\n",
        "        self.model_2.load_weights(name2)\n",
        "\n",
        "    def save(self, name, name2):\n",
        "        self.model.save_weights(name)\n",
        "        self.model_2.save_weights(name2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state,s_flag=12):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state,s_flag)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                s_flag = 12\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    rand = np.random.random()\n",
        "                    if rand <= 0.5:\n",
        "                        s_flag = 11\n",
        "                    else:\n",
        "                        s_flag = 22\n",
        "                    agent.train(state, action, reward, next_state, done, s_flag)\n",
        "                    \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "d2cb9a01-22ee-428d-daf5-74d9e89352ba"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:01:03.298862 FixedProfit: 1030990\n",
            "Episode: 2/100 RapTime: 0:00:59.128128 FixedProfit: 1034028\n",
            "Episode: 3/100 RapTime: 0:00:59.296401 FixedProfit: 1079966\n",
            "Episode: 4/100 RapTime: 0:00:59.264758 FixedProfit: 1240494\n",
            "Episode: 5/100 RapTime: 0:00:59.097434 FixedProfit: 1192239\n",
            "Episode: 6/100 RapTime: 0:01:01.029666 FixedProfit: 1038437\n",
            "Episode: 7/100 RapTime: 0:00:59.477110 FixedProfit: 1133910\n",
            "Episode: 8/100 RapTime: 0:00:59.356916 FixedProfit: 1177867\n",
            "Episode: 9/100 RapTime: 0:00:59.471716 FixedProfit: 1144861\n",
            "Episode: 10/100 RapTime: 0:00:59.146848 FixedProfit: 1059542\n",
            "Episode: 11/100 RapTime: 0:00:59.831127 FixedProfit: 1080625\n",
            "Episode: 12/100 RapTime: 0:01:00.912146 FixedProfit: 1027661\n",
            "Episode: 13/100 RapTime: 0:00:59.343341 FixedProfit: 994180\n",
            "Episode: 14/100 RapTime: 0:00:59.639814 FixedProfit: 1230735\n",
            "Episode: 15/100 RapTime: 0:00:59.088415 FixedProfit: 1161060\n",
            "Episode: 16/100 RapTime: 0:00:59.695203 FixedProfit: 1247891\n",
            "Episode: 17/100 RapTime: 0:01:01.204162 FixedProfit: 1244538\n",
            "Episode: 18/100 RapTime: 0:00:59.221128 FixedProfit: 1094867\n",
            "Episode: 19/100 RapTime: 0:00:59.286609 FixedProfit: 1035596\n",
            "Episode: 20/100 RapTime: 0:00:59.299230 FixedProfit: 1147064\n",
            "Episode: 21/100 RapTime: 0:00:59.470038 FixedProfit: 1145879\n",
            "Episode: 22/100 RapTime: 0:01:01.359678 FixedProfit: 983450\n",
            "Episode: 23/100 RapTime: 0:00:59.191835 FixedProfit: 1048374\n",
            "Episode: 24/100 RapTime: 0:00:59.156796 FixedProfit: 952705\n",
            "Episode: 25/100 RapTime: 0:00:59.413390 FixedProfit: 1194426\n",
            "Episode: 26/100 RapTime: 0:00:59.616287 FixedProfit: 1308042\n",
            "Episode: 27/100 RapTime: 0:00:59.657256 FixedProfit: 1217817\n",
            "Episode: 28/100 RapTime: 0:01:00.840336 FixedProfit: 1102491\n",
            "Episode: 29/100 RapTime: 0:00:59.675657 FixedProfit: 1108803\n",
            "Episode: 30/100 RapTime: 0:00:59.675126 FixedProfit: 1069003\n",
            "Episode: 31/100 RapTime: 0:00:59.433690 FixedProfit: 1218760\n",
            "Episode: 32/100 RapTime: 0:00:59.786839 FixedProfit: 904174\n",
            "Episode: 33/100 RapTime: 0:01:01.168317 FixedProfit: 1169614\n",
            "Episode: 34/100 RapTime: 0:00:59.349859 FixedProfit: 1120650\n",
            "Episode: 35/100 RapTime: 0:00:59.524759 FixedProfit: 1185357\n",
            "Episode: 36/100 RapTime: 0:00:59.197405 FixedProfit: 1060974\n",
            "Episode: 37/100 RapTime: 0:00:59.818566 FixedProfit: 1081934\n",
            "Episode: 38/100 RapTime: 0:00:59.642156 FixedProfit: 1152687\n",
            "Episode: 39/100 RapTime: 0:01:00.639969 FixedProfit: 1182205\n",
            "Episode: 40/100 RapTime: 0:00:59.615385 FixedProfit: 928185\n",
            "Episode: 41/100 RapTime: 0:00:59.152098 FixedProfit: 1164595\n",
            "Episode: 42/100 RapTime: 0:00:59.373040 FixedProfit: 1053118\n",
            "Episode: 43/100 RapTime: 0:00:59.692544 FixedProfit: 1236092\n",
            "Episode: 44/100 RapTime: 0:01:00.653764 FixedProfit: 1057168\n",
            "Episode: 45/100 RapTime: 0:00:59.473838 FixedProfit: 1284584\n",
            "Episode: 46/100 RapTime: 0:00:59.137659 FixedProfit: 1175513\n",
            "Episode: 47/100 RapTime: 0:00:59.225708 FixedProfit: 851008\n",
            "Episode: 48/100 RapTime: 0:00:59.774595 FixedProfit: 1093561\n",
            "Episode: 49/100 RapTime: 0:00:59.621083 FixedProfit: 1039346\n",
            "Episode: 50/100 RapTime: 0:01:01.050404 FixedProfit: 976947\n",
            "Episode: 51/100 RapTime: 0:00:59.357226 FixedProfit: 1054382\n",
            "Episode: 52/100 RapTime: 0:00:59.508265 FixedProfit: 1166881\n",
            "Episode: 53/100 RapTime: 0:00:59.979343 FixedProfit: 1195708\n",
            "Episode: 54/100 RapTime: 0:00:59.787878 FixedProfit: 1031904\n",
            "Episode: 55/100 RapTime: 0:01:00.954482 FixedProfit: 1102293\n",
            "Episode: 56/100 RapTime: 0:00:59.681309 FixedProfit: 998537\n",
            "Episode: 57/100 RapTime: 0:00:59.701647 FixedProfit: 980233\n",
            "Episode: 58/100 RapTime: 0:00:59.492305 FixedProfit: 1164934\n",
            "Episode: 59/100 RapTime: 0:00:59.851942 FixedProfit: 915493\n",
            "Episode: 60/100 RapTime: 0:01:00.130562 FixedProfit: 979825\n",
            "Episode: 61/100 RapTime: 0:01:00.622648 FixedProfit: 1104825\n",
            "Episode: 62/100 RapTime: 0:00:59.575325 FixedProfit: 923509\n",
            "Episode: 63/100 RapTime: 0:00:59.492966 FixedProfit: 1168101\n",
            "Episode: 64/100 RapTime: 0:00:59.881753 FixedProfit: 1058022\n",
            "Episode: 65/100 RapTime: 0:00:59.887913 FixedProfit: 978902\n",
            "Episode: 66/100 RapTime: 0:01:00.776786 FixedProfit: 1126856\n",
            "Episode: 67/100 RapTime: 0:00:59.549846 FixedProfit: 1073900\n",
            "Episode: 68/100 RapTime: 0:00:59.338398 FixedProfit: 990106\n",
            "Episode: 69/100 RapTime: 0:00:59.534228 FixedProfit: 1070708\n",
            "Episode: 70/100 RapTime: 0:00:59.570905 FixedProfit: 1161266\n",
            "Episode: 71/100 RapTime: 0:01:00.011518 FixedProfit: 1136614\n",
            "Episode: 72/100 RapTime: 0:01:00.102174 FixedProfit: 1105323\n",
            "Episode: 73/100 RapTime: 0:00:59.353829 FixedProfit: 951620\n",
            "Episode: 74/100 RapTime: 0:00:59.386581 FixedProfit: 1171870\n",
            "Episode: 75/100 RapTime: 0:00:59.647375 FixedProfit: 1242157\n",
            "Episode: 76/100 RapTime: 0:01:00.204585 FixedProfit: 1064046\n",
            "Episode: 77/100 RapTime: 0:01:00.485294 FixedProfit: 1002081\n",
            "Episode: 78/100 RapTime: 0:00:59.274611 FixedProfit: 1072482\n",
            "Episode: 79/100 RapTime: 0:00:59.553571 FixedProfit: 1055286\n",
            "Episode: 80/100 RapTime: 0:00:59.884474 FixedProfit: 1276428\n",
            "Episode: 81/100 RapTime: 0:01:00.026940 FixedProfit: 984254\n",
            "Episode: 82/100 RapTime: 0:01:00.456669 FixedProfit: 1061154\n",
            "Episode: 83/100 RapTime: 0:00:59.563987 FixedProfit: 1056692\n",
            "Episode: 84/100 RapTime: 0:00:59.502686 FixedProfit: 1009572\n",
            "Episode: 85/100 RapTime: 0:00:59.673509 FixedProfit: 1037270\n",
            "Episode: 86/100 RapTime: 0:00:59.980668 FixedProfit: 875639\n",
            "Episode: 87/100 RapTime: 0:01:00.054576 FixedProfit: 1222092\n",
            "Episode: 88/100 RapTime: 0:01:00.133375 FixedProfit: 1274979\n",
            "Episode: 89/100 RapTime: 0:00:59.382588 FixedProfit: 974676\n",
            "Episode: 90/100 RapTime: 0:00:59.642711 FixedProfit: 1138241\n",
            "Episode: 91/100 RapTime: 0:00:59.866923 FixedProfit: 1097967\n",
            "Episode: 92/100 RapTime: 0:01:00.058363 FixedProfit: 1198672\n",
            "Episode: 93/100 RapTime: 0:01:00.531614 FixedProfit: 1172419\n",
            "Episode: 94/100 RapTime: 0:00:59.309376 FixedProfit: 1241642\n",
            "Episode: 95/100 RapTime: 0:00:59.676144 FixedProfit: 983765\n",
            "Episode: 96/100 RapTime: 0:01:00.013203 FixedProfit: 1123904\n",
            "Episode: 97/100 RapTime: 0:01:00.161746 FixedProfit: 1041274\n",
            "Episode: 98/100 RapTime: 0:01:00.049153 FixedProfit: 916680\n",
            "Episode: 99/100 RapTime: 0:01:00.278668 FixedProfit: 1140760\n",
            "Episode: 100/100 RapTime: 0:00:59.327326 FixedProfit: 1127022\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}