{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gorila_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNXQypH5qXYK5uQxbLo6BvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/gorila_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "f64035d8-6b6e-4730-ae4d-c5a4a0ea03d0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "mode = 'train'\n",
        "name = 'gorila'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=1000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self):\n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "        else:\n",
        "            if self.action_space[0] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1 \n",
        "            if self.action_space[2] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U1RNmtkaZ2W"
      },
      "source": [
        "class ParameterServer:\n",
        "    def __init__(self):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        mastermodel = Sequential()\n",
        "        mastermodel.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_mid))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_action))\n",
        "        mastermodel.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((mastermodel.summary()))\n",
        "        self.mastermodel = mastermodel\n",
        "    \n",
        "    def load(self, name):\n",
        "        self.mastermodel.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.mastermodel.save_weights(name)\n",
        "\n",
        "    def placement(self, model):\n",
        "        for m, mm in zip(model.trainable_weights, self.mastermodel.trainable_weights):\n",
        "            m.assign(mm)\n",
        "\n",
        "    def integration(self, model):\n",
        "        for mm, m in zip(self.mastermodel.trainable_weights, model.trainable_weights):\n",
        "            mm.assign(m)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, masterbrain):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        Brain.model = model\n",
        "        Brain.masterbrain = masterbrain\n",
        "\n",
        "    def load(self, name):\n",
        "        Brain.mastermodel.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        Brain.mastermodel.save(name)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return Brain.model.predict(state)\n",
        "\n",
        "    def train_on_batch(self, state, target_full):\n",
        "        Brain.model.train_on_batch(state, target_full)\n",
        "\n",
        "    def layering(self):\n",
        "        Brain.masterbrain.placement(Brain.model)\n",
        "\n",
        "    def integration(self):\n",
        "        Brain.masterbrain.integration(Brain.model)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1_BMH7hLQ8"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size, batch_size=32):\n",
        "\n",
        "        ReplayMemory.cntr = 0\n",
        "        ReplayMemory.size = 0\n",
        "        ReplayMemory.max_size = max_size\n",
        "        ReplayMemory.batch_size = batch_size\n",
        "        ReplayMemory.states_memory = np.zeros([ReplayMemory.max_size, 3], dtype=np.float32)\n",
        "        ReplayMemory.next_states_memory = np.zeros([ReplayMemory.max_size, 3], dtype=np.float32)\n",
        "        ReplayMemory.acts_memory = np.zeros(ReplayMemory.max_size, dtype=np.uint8)\n",
        "        ReplayMemory.rewards_memory = np.zeros(ReplayMemory.max_size, dtype=np.float32)\n",
        "        ReplayMemory.done_memory = np.zeros(ReplayMemory.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        ReplayMemory.states_memory[ReplayMemory.cntr] = state\n",
        "        ReplayMemory.next_states_memory[ReplayMemory.cntr] = next_state\n",
        "        ReplayMemory.acts_memory[ReplayMemory.cntr] = act\n",
        "        ReplayMemory.rewards_memory[ReplayMemory.cntr] = reward\n",
        "        ReplayMemory.done_memory[ReplayMemory.cntr] = done\n",
        "        ReplayMemory.cntr = (ReplayMemory.cntr+1) % ReplayMemory.max_size\n",
        "        ReplayMemory.size = min(ReplayMemory.size+1, ReplayMemory.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(ReplayMemory.size, ReplayMemory.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [ReplayMemory.states_memory[mb_index],ReplayMemory.next_states_memory[mb_index],\n",
        "                 ReplayMemory.acts_memory[mb_index],ReplayMemory.rewards_memory[mb_index],\n",
        "                 ReplayMemory.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrEa4wpGG1DF"
      },
      "source": [
        "class Actor(Brain, ReplayMemory):\n",
        "    def __init__(self, masterbrain, max_size, batch_size = 32):\n",
        "\n",
        "        Brain.__init__(self, masterbrain)\n",
        "        ReplayMemory.__init__(self, max_size, batch_size)\n",
        "        self.epsilon = 1.0\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42NIN-PGBOc8"
      },
      "source": [
        "class Learner(Brain, ReplayMemory):\n",
        "    def __init__(self, batch_size = 32):\n",
        "\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learn(self):\n",
        "        if ReplayMemory.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.predict(next_states), axis=1)\n",
        "\n",
        "        target_full = self.predict(states)\n",
        "\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.train_on_batch(states, target_full)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, actor, learner, num, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.actor = actor\n",
        "        self.learner = learner\n",
        "        self.num = str(num)\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.actor.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "        self.actor.layering()\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.actor.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.actor.store_transition(state, action, reward, next_state, done)\n",
        "                    self.learner.learn()\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                learner.integration()\n",
        "                actor.layering()\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.actor.load('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "        self.actor.save('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "2be91e45-49d0-42c8-a068-128bd4ca363f"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 50\n",
        "batch_size = 32\n",
        "max_size = 500\n",
        "\n",
        "masterbrain = ParameterServer()\n",
        "\n",
        "thread_num = 4\n",
        "envs = []\n",
        "for i in range(thread_num):\n",
        "    env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "    actor = Actor(masterbrain, max_size, batch_size)\n",
        "    learner = Learner(batch_size)\n",
        "    main = Main(env, actor, learner, i, mdl_dir, name, episodes_times, mode)\n",
        "    envs.append(main)\n",
        "\n",
        "datas = []\n",
        "with ThreadPoolExecutor(max_workers=thread_num) as executor:\n",
        "    for env in envs:\n",
        "        job = lambda: env.play_game()\n",
        "        datas.append(executor.submit(job))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/50 RapTime: 0:03:12.866034 FixedProfit: 1011431\n",
            "Episode: 1/50 RapTime: 0:03:14.506136 FixedProfit: 1029475\n",
            "Episode: 1/50 RapTime: 0:03:19.095853 FixedProfit: 1082662\n",
            "Episode: 1/50 RapTime: 0:03:19.337289 FixedProfit: 1068813\n",
            "Episode: 2/50 RapTime: 0:03:20.315108 FixedProfit: 1166353\n",
            "Episode: 2/50 RapTime: 0:03:20.850004 FixedProfit: 986665\n",
            "Episode: 2/50 RapTime: 0:03:21.343834 FixedProfit: 1107697\n",
            "Episode: 2/50 RapTime: 0:03:22.655908 FixedProfit: 1051285\n",
            "Episode: 3/50 RapTime: 0:03:29.393507 FixedProfit: 1038419\n",
            "Episode: 3/50 RapTime: 0:03:32.007276 FixedProfit: 1104799\n",
            "Episode: 3/50 RapTime: 0:03:30.144580 FixedProfit: 1113709\n",
            "Episode: 3/50 RapTime: 0:03:32.155775 FixedProfit: 1044074\n",
            "Episode: 4/50 RapTime: 0:03:35.502446 FixedProfit: 1083708\n",
            "Episode: 4/50 RapTime: 0:03:36.097946 FixedProfit: 1026754\n",
            "Episode: 4/50 RapTime: 0:03:32.093230 FixedProfit: 1097238\n",
            "Episode: 4/50 RapTime: 0:03:32.216931 FixedProfit: 1155805\n",
            "Episode: 5/50 RapTime: 0:03:38.214855 FixedProfit: 1148667\n",
            "Episode: 5/50 RapTime: 0:03:34.697511 FixedProfit: 1109233\n",
            "Episode: 5/50 RapTime: 0:03:37.435680 FixedProfit: 1020931\n",
            "Episode: 5/50 RapTime: 0:03:37.295982 FixedProfit: 1103338\n",
            "Episode: 6/50 RapTime: 0:03:34.143316 FixedProfit: 1135477\n",
            "Episode: 6/50 RapTime: 0:03:36.659289 FixedProfit: 1027995\n",
            "Episode: 6/50 RapTime: 0:03:36.839925 FixedProfit: 924760\n",
            "Episode: 6/50 RapTime: 0:03:38.599058 FixedProfit: 974321\n",
            "Episode: 7/50 RapTime: 0:03:37.296338 FixedProfit: 1258952\n",
            "Episode: 7/50 RapTime: 0:03:38.366169 FixedProfit: 1058605\n",
            "Episode: 7/50 RapTime: 0:03:39.224456 FixedProfit: 1000099\n",
            "Episode: 7/50 RapTime: 0:03:40.781528 FixedProfit: 1029325\n",
            "Episode: 8/50 RapTime: 0:03:40.735896 FixedProfit: 1088941\n",
            "Episode: 8/50 RapTime: 0:03:44.761749 FixedProfit: 1085153\n",
            "Episode: 8/50 RapTime: 0:03:39.591196 FixedProfit: 1329012\n",
            "Episode: 8/50 RapTime: 0:03:40.545578 FixedProfit: 927944\n",
            "Episode: 9/50 RapTime: 0:03:42.613798 FixedProfit: 1168155\n",
            "Episode: 9/50 RapTime: 0:03:42.852692 FixedProfit: 1028044\n",
            "Episode: 9/50 RapTime: 0:03:43.292434 FixedProfit: 1069450\n",
            "Episode: 9/50 RapTime: 0:03:43.178508 FixedProfit: 1153003\n",
            "Episode: 10/50 RapTime: 0:03:48.991547 FixedProfit: 998066\n",
            "Episode: 10/50 RapTime: 0:03:46.532315 FixedProfit: 926340\n",
            "Episode: 10/50 RapTime: 0:03:45.463808 FixedProfit: 1214783\n",
            "Episode: 10/50 RapTime: 0:03:45.836465 FixedProfit: 1281214\n",
            "Episode: 11/50 RapTime: 0:03:49.521177 FixedProfit: 953748\n",
            "Episode: 11/50 RapTime: 0:03:49.078032 FixedProfit: 929697\n",
            "Episode: 11/50 RapTime: 0:03:47.077387 FixedProfit: 974506\n",
            "Episode: 11/50 RapTime: 0:03:49.295462 FixedProfit: 1167636\n",
            "Episode: 12/50 RapTime: 0:03:49.062964 FixedProfit: 1000057\n",
            "Episode: 12/50 RapTime: 0:03:52.320623 FixedProfit: 968533\n",
            "Episode: 12/50 RapTime: 0:03:48.873821 FixedProfit: 919247\n",
            "Episode: 12/50 RapTime: 0:03:55.961574 FixedProfit: 860812\n",
            "Episode: 13/50 RapTime: 0:03:50.880573 FixedProfit: 1250558\n",
            "Episode: 13/50 RapTime: 0:03:50.645028 FixedProfit: 921810\n",
            "Episode: 13/50 RapTime: 0:03:55.777711 FixedProfit: 1171207\n",
            "Episode: 13/50 RapTime: 0:03:52.888621 FixedProfit: 935643\n",
            "Episode: 14/50 RapTime: 0:03:52.695242 FixedProfit: 1230399\n",
            "Episode: 14/50 RapTime: 0:03:54.368565 FixedProfit: 906040\n",
            "Episode: 14/50 RapTime: 0:03:51.794990 FixedProfit: 1050397\n",
            "Episode: 14/50 RapTime: 0:04:00.432512 FixedProfit: 1187227\n",
            "Episode: 15/50 RapTime: 0:03:56.029717 FixedProfit: 1021801\n",
            "Episode: 15/50 RapTime: 0:03:55.019217 FixedProfit: 1174148\n",
            "Episode: 15/50 RapTime: 0:03:58.761596 FixedProfit: 1077567\n",
            "Episode: 15/50 RapTime: 0:03:55.388168 FixedProfit: 909443\n",
            "Episode: 16/50 RapTime: 0:03:50.222425 FixedProfit: 1113040\n",
            "Episode: 16/50 RapTime: 0:03:54.590805 FixedProfit: 1034704\n",
            "Episode: 16/50 RapTime: 0:03:55.173065 FixedProfit: 938076\n",
            "Episode: 16/50 RapTime: 0:03:56.305322 FixedProfit: 973444\n",
            "Episode: 17/50 RapTime: 0:03:44.806413 FixedProfit: 1043449\n",
            "Episode: 17/50 RapTime: 0:03:44.175866 FixedProfit: 1189107\n",
            "Episode: 17/50 RapTime: 0:03:44.915836 FixedProfit: 1071095\n",
            "Episode: 17/50 RapTime: 0:03:43.386175 FixedProfit: 939659\n",
            "Episode: 18/50 RapTime: 0:03:48.547685 FixedProfit: 958798\n",
            "Episode: 18/50 RapTime: 0:03:52.100445 FixedProfit: 1184514\n",
            "Episode: 18/50 RapTime: 0:03:57.204059 FixedProfit: 894457\n",
            "Episode: 18/50 RapTime: 0:03:54.629611 FixedProfit: 1051268\n",
            "Episode: 19/50 RapTime: 0:04:05.946884 FixedProfit: 1028382\n",
            "Episode: 19/50 RapTime: 0:04:06.669070 FixedProfit: 1015976\n",
            "Episode: 19/50 RapTime: 0:04:12.537625 FixedProfit: 1041984\n",
            "Episode: 19/50 RapTime: 0:04:10.558352 FixedProfit: 1085246\n",
            "Episode: 20/50 RapTime: 0:04:08.504381 FixedProfit: 926941\n",
            "Episode: 20/50 RapTime: 0:04:10.671753 FixedProfit: 1261750\n",
            "Episode: 20/50 RapTime: 0:04:07.290143 FixedProfit: 980248\n",
            "Episode: 20/50 RapTime: 0:04:12.004855 FixedProfit: 989875\n",
            "Episode: 21/50 RapTime: 0:04:14.217639 FixedProfit: 1111717\n",
            "Episode: 21/50 RapTime: 0:04:12.130053 FixedProfit: 941367\n",
            "Episode: 21/50 RapTime: 0:04:08.819302 FixedProfit: 1169170\n",
            "Episode: 21/50 RapTime: 0:04:13.142262 FixedProfit: 1018262\n",
            "Episode: 22/50 RapTime: 0:04:13.971303 FixedProfit: 1135412\n",
            "Episode: 22/50 RapTime: 0:04:17.197977 FixedProfit: 1020520\n",
            "Episode: 22/50 RapTime: 0:04:13.533888 FixedProfit: 1121612\n",
            "Episode: 22/50 RapTime: 0:04:11.131204 FixedProfit: 1116269\n",
            "Episode: 23/50 RapTime: 0:04:14.093646 FixedProfit: 980734\n",
            "Episode: 23/50 RapTime: 0:04:16.587434 FixedProfit: 1037568\n",
            "Episode: 23/50 RapTime: 0:04:15.253117 FixedProfit: 1093941\n",
            "Episode: 23/50 RapTime: 0:04:19.875888 FixedProfit: 1035469\n",
            "Episode: 24/50 RapTime: 0:04:20.885315 FixedProfit: 955288\n",
            "Episode: 24/50 RapTime: 0:04:20.485780 FixedProfit: 898460\n",
            "Episode: 24/50 RapTime: 0:04:20.380113 FixedProfit: 1146406\n",
            "Episode: 24/50 RapTime: 0:04:16.085008 FixedProfit: 1059797\n",
            "Episode: 25/50 RapTime: 0:04:24.974645 FixedProfit: 909417\n",
            "Episode: 25/50 RapTime: 0:04:17.989596 FixedProfit: 1224561\n",
            "Episode: 25/50 RapTime: 0:04:19.901663 FixedProfit: 1027018\n",
            "Episode: 25/50 RapTime: 0:04:25.422139 FixedProfit: 1008649\n",
            "Episode: 26/50 RapTime: 0:04:24.445507 FixedProfit: 1055980\n",
            "Episode: 26/50 RapTime: 0:04:25.910889 FixedProfit: 1155951\n",
            "Episode: 26/50 RapTime: 0:04:20.631948 FixedProfit: 1036571\n",
            "Episode: 26/50 RapTime: 0:04:26.592153 FixedProfit: 939162\n",
            "Episode: 27/50 RapTime: 0:04:24.891975 FixedProfit: 1278891\n",
            "Episode: 27/50 RapTime: 0:04:22.804221 FixedProfit: 1181563\n",
            "Episode: 27/50 RapTime: 0:04:30.855353 FixedProfit: 1149359\n",
            "Episode: 27/50 RapTime: 0:04:31.187576 FixedProfit: 1095112\n",
            "Episode: 28/50 RapTime: 0:04:26.824258 FixedProfit: 1248644\n",
            "Episode: 28/50 RapTime: 0:04:34.078739 FixedProfit: 1291540\n",
            "Episode: 28/50 RapTime: 0:04:28.176085 FixedProfit: 984289\n",
            "Episode: 28/50 RapTime: 0:04:31.004966 FixedProfit: 1172568\n",
            "Episode: 29/50 RapTime: 0:04:31.507385 FixedProfit: 1115602\n",
            "Episode: 29/50 RapTime: 0:04:34.887430 FixedProfit: 1013472\n",
            "Episode: 29/50 RapTime: 0:04:32.287654 FixedProfit: 1154883\n",
            "Episode: 29/50 RapTime: 0:04:31.032429 FixedProfit: 850521\n",
            "Episode: 30/50 RapTime: 0:04:35.065433 FixedProfit: 1012121\n",
            "Episode: 30/50 RapTime: 0:04:30.988248 FixedProfit: 1002693\n",
            "Episode: 30/50 RapTime: 0:04:34.901306 FixedProfit: 1146266\n",
            "Episode: 30/50 RapTime: 0:04:35.297483 FixedProfit: 1105075\n",
            "Episode: 31/50 RapTime: 0:04:16.606383 FixedProfit: 828190\n",
            "Episode: 31/50 RapTime: 0:04:16.373174 FixedProfit: 990425\n",
            "Episode: 31/50 RapTime: 0:04:16.930667 FixedProfit: 1301417\n",
            "Episode: 31/50 RapTime: 0:04:16.157179 FixedProfit: 1076763\n",
            "Episode: 32/50 RapTime: 0:04:29.849504 FixedProfit: 1170013\n",
            "Episode: 32/50 RapTime: 0:04:35.796993 FixedProfit: 1285240\n",
            "Episode: 32/50 RapTime: 0:04:35.171420 FixedProfit: 1090376\n",
            "Episode: 32/50 RapTime: 0:04:38.912982 FixedProfit: 1313030\n",
            "Episode: 33/50 RapTime: 0:04:52.880798 FixedProfit: 1026586\n",
            "Episode: 33/50 RapTime: 0:04:49.433186 FixedProfit: 1223606\n",
            "Episode: 33/50 RapTime: 0:04:48.625583 FixedProfit: 1102128\n",
            "Episode: 33/50 RapTime: 0:04:52.018477 FixedProfit: 1061832\n",
            "Episode: 34/50 RapTime: 0:04:54.929007 FixedProfit: 1078346\n",
            "Episode: 34/50 RapTime: 0:04:45.980392 FixedProfit: 1092586\n",
            "Episode: 34/50 RapTime: 0:04:53.563798 FixedProfit: 1009579\n",
            "Episode: 34/50 RapTime: 0:04:49.598688 FixedProfit: 1155898\n",
            "Episode: 35/50 RapTime: 0:04:55.558869 FixedProfit: 967530\n",
            "Episode: 35/50 RapTime: 0:04:48.651533 FixedProfit: 1059336\n",
            "Episode: 35/50 RapTime: 0:04:51.794688 FixedProfit: 1064948\n",
            "Episode: 35/50 RapTime: 0:04:54.857012 FixedProfit: 1238681\n",
            "Episode: 36/50 RapTime: 0:05:02.196964 FixedProfit: 1060613\n",
            "Episode: 36/50 RapTime: 0:04:56.734131 FixedProfit: 1029251\n",
            "Episode: 36/50 RapTime: 0:04:58.086273 FixedProfit: 1118446\n",
            "Episode: 36/50 RapTime: 0:04:51.384289 FixedProfit: 1278151\n",
            "Episode: 37/50 RapTime: 0:04:56.370054 FixedProfit: 933162\n",
            "Episode: 37/50 RapTime: 0:05:00.864099 FixedProfit: 1323339\n",
            "Episode: 37/50 RapTime: 0:05:00.548816 FixedProfit: 1056417\n",
            "Episode: 37/50 RapTime: 0:04:57.164745 FixedProfit: 1149437\n",
            "Episode: 38/50 RapTime: 0:05:01.722490 FixedProfit: 1186735\n",
            "Episode: 38/50 RapTime: 0:04:58.784881 FixedProfit: 1081618\n",
            "Episode: 38/50 RapTime: 0:05:02.245731 FixedProfit: 1184334\n",
            "Episode: 38/50 RapTime: 0:05:02.642330 FixedProfit: 1257558\n",
            "Episode: 39/50 RapTime: 0:05:03.945604 FixedProfit: 1090727\n",
            "Episode: 39/50 RapTime: 0:05:03.665010 FixedProfit: 1163718\n",
            "Episode: 39/50 RapTime: 0:05:08.953040 FixedProfit: 1102617\n",
            "Episode: 39/50 RapTime: 0:05:04.626077 FixedProfit: 1141053\n",
            "Episode: 40/50 RapTime: 0:05:02.976684 FixedProfit: 1127615\n",
            "Episode: 40/50 RapTime: 0:05:04.328906 FixedProfit: 1353767\n",
            "Episode: 40/50 RapTime: 0:05:06.172337 FixedProfit: 1210098\n",
            "Episode: 40/50 RapTime: 0:05:15.475164 FixedProfit: 1072710\n",
            "Episode: 41/50 RapTime: 0:05:12.887988 FixedProfit: 1043063\n",
            "Episode: 41/50 RapTime: 0:05:09.097231 FixedProfit: 1005297\n",
            "Episode: 41/50 RapTime: 0:05:08.205204 FixedProfit: 1053142\n",
            "Episode: 41/50 RapTime: 0:05:05.339026 FixedProfit: 1008499\n",
            "Episode: 42/50 RapTime: 0:05:11.372781 FixedProfit: 1157097\n",
            "Episode: 42/50 RapTime: 0:05:12.154954 FixedProfit: 1091596\n",
            "Episode: 42/50 RapTime: 0:05:14.838771 FixedProfit: 1230765\n",
            "Episode: 42/50 RapTime: 0:05:11.876755 FixedProfit: 1254482\n",
            "Episode: 43/50 RapTime: 0:04:46.615704 FixedProfit: 1095182\n",
            "Episode: 43/50 RapTime: 0:04:44.131879 FixedProfit: 1020520\n",
            "Episode: 43/50 RapTime: 0:04:49.006646 FixedProfit: 972802\n",
            "Episode: 43/50 RapTime: 0:04:52.837944 FixedProfit: 1075826\n",
            "Episode: 44/50 RapTime: 0:05:08.263443 FixedProfit: 949976\n",
            "Episode: 44/50 RapTime: 0:05:05.194940 FixedProfit: 1332666\n",
            "Episode: 44/50 RapTime: 0:05:06.802635 FixedProfit: 1100851\n",
            "Episode: 44/50 RapTime: 0:05:03.239542 FixedProfit: 1176227\n",
            "Episode: 45/50 RapTime: 0:05:23.895629 FixedProfit: 1300167\n",
            "Episode: 45/50 RapTime: 0:05:31.815691 FixedProfit: 1148176\n",
            "Episode: 45/50 RapTime: 0:05:26.274156 FixedProfit: 1199648\n",
            "Episode: 45/50 RapTime: 0:05:32.767129 FixedProfit: 1035260\n",
            "Episode: 46/50 RapTime: 0:05:32.204737 FixedProfit: 987275\n",
            "Episode: 46/50 RapTime: 0:05:34.212682 FixedProfit: 1098258\n",
            "Episode: 46/50 RapTime: 0:05:34.284371 FixedProfit: 1070268\n",
            "Episode: 46/50 RapTime: 0:05:30.537943 FixedProfit: 1028914\n",
            "Episode: 47/50 RapTime: 0:05:32.156397 FixedProfit: 1142268\n",
            "Episode: 47/50 RapTime: 0:05:29.870658 FixedProfit: 1054462\n",
            "Episode: 47/50 RapTime: 0:05:37.366931 FixedProfit: 935703\n",
            "Episode: 47/50 RapTime: 0:05:36.782597 FixedProfit: 957932\n",
            "Episode: 48/50 RapTime: 0:05:40.804647 FixedProfit: 1234037\n",
            "Episode: 48/50 RapTime: 0:05:41.368100 FixedProfit: 984744\n",
            "Episode: 48/50 RapTime: 0:05:39.991571 FixedProfit: 1257717\n",
            "Episode: 48/50 RapTime: 0:05:35.669726 FixedProfit: 1176138\n",
            "Episode: 49/50 RapTime: 0:05:33.592499 FixedProfit: 1127030\n",
            "Episode: 49/50 RapTime: 0:05:41.946528 FixedProfit: 1211318\n",
            "Episode: 49/50 RapTime: 0:05:41.338503 FixedProfit: 997673\n",
            "Episode: 49/50 RapTime: 0:05:41.773337 FixedProfit: 1105134\n",
            "Episode: 50/50 RapTime: 0:05:35.410305 FixedProfit: 912314\n",
            "Episode: 50/50 RapTime: 0:05:35.482498 FixedProfit: 966058\n",
            "Episode: 50/50 RapTime: 0:05:28.619975 FixedProfit: 1112338\n",
            "Episode: 50/50 RapTime: 0:05:26.508889 FixedProfit: 1250295\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}