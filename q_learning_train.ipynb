{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOXY5DEhR0xYO4z0Jrv/NAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "fad54a44-7c9d-4637-e075-5f0948dc2234"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_train.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'qlearning_train.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        prev_revenue = self._get_revenue()\n",
        "\n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self):\n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "        else:\n",
        "            if self.action_space[0] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1 \n",
        "            if self.action_space[2] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        self.brain.train(state, action, reward, next_state, done)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "\n",
        "            if mode == 'train':\n",
        "                agent.train(state, action, reward, next_state, done)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        state = next_state\n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "64bd881d-3f70-46cf-8e28-97f5b7dfb405"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'train'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_ql.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_ql.h5')\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:55.321493 FixedProfit: 887648\n",
            "Episode: 2/100 RapTime: 0:00:56.215753 FixedProfit: 1104215\n",
            "Episode: 3/100 RapTime: 0:00:53.359268 FixedProfit: 1250256\n",
            "Episode: 4/100 RapTime: 0:00:53.659483 FixedProfit: 1128864\n",
            "Episode: 5/100 RapTime: 0:00:54.018709 FixedProfit: 924644\n",
            "Episode: 6/100 RapTime: 0:00:53.735160 FixedProfit: 1100660\n",
            "Episode: 7/100 RapTime: 0:00:54.398111 FixedProfit: 946827\n",
            "Episode: 8/100 RapTime: 0:00:54.847799 FixedProfit: 1096691\n",
            "Episode: 9/100 RapTime: 0:00:53.941850 FixedProfit: 1173478\n",
            "Episode: 10/100 RapTime: 0:00:54.377417 FixedProfit: 1040970\n",
            "Episode: 11/100 RapTime: 0:00:53.673582 FixedProfit: 1192219\n",
            "Episode: 12/100 RapTime: 0:00:53.575460 FixedProfit: 1125197\n",
            "Episode: 13/100 RapTime: 0:00:53.669808 FixedProfit: 1050217\n",
            "Episode: 14/100 RapTime: 0:00:53.436778 FixedProfit: 930699\n",
            "Episode: 15/100 RapTime: 0:00:53.153614 FixedProfit: 1175466\n",
            "Episode: 16/100 RapTime: 0:00:53.340917 FixedProfit: 857198\n",
            "Episode: 17/100 RapTime: 0:00:53.261375 FixedProfit: 967156\n",
            "Episode: 18/100 RapTime: 0:00:53.726162 FixedProfit: 1221280\n",
            "Episode: 19/100 RapTime: 0:00:53.646513 FixedProfit: 1030249\n",
            "Episode: 20/100 RapTime: 0:00:53.693021 FixedProfit: 1086910\n",
            "Episode: 21/100 RapTime: 0:00:53.669456 FixedProfit: 1146993\n",
            "Episode: 22/100 RapTime: 0:00:53.929484 FixedProfit: 1242962\n",
            "Episode: 23/100 RapTime: 0:00:53.698759 FixedProfit: 1007150\n",
            "Episode: 24/100 RapTime: 0:00:54.001175 FixedProfit: 1142261\n",
            "Episode: 25/100 RapTime: 0:00:53.948862 FixedProfit: 956246\n",
            "Episode: 26/100 RapTime: 0:00:53.656159 FixedProfit: 1058137\n",
            "Episode: 27/100 RapTime: 0:00:53.751273 FixedProfit: 969119\n",
            "Episode: 28/100 RapTime: 0:00:53.882642 FixedProfit: 920387\n",
            "Episode: 29/100 RapTime: 0:00:53.886268 FixedProfit: 1181406\n",
            "Episode: 30/100 RapTime: 0:00:53.636697 FixedProfit: 1166774\n",
            "Episode: 31/100 RapTime: 0:00:53.898262 FixedProfit: 1106776\n",
            "Episode: 32/100 RapTime: 0:00:54.321998 FixedProfit: 988844\n",
            "Episode: 33/100 RapTime: 0:00:53.749569 FixedProfit: 1145310\n",
            "Episode: 34/100 RapTime: 0:00:53.511769 FixedProfit: 987836\n",
            "Episode: 35/100 RapTime: 0:00:53.440541 FixedProfit: 964255\n",
            "Episode: 36/100 RapTime: 0:00:54.222588 FixedProfit: 1082734\n",
            "Episode: 37/100 RapTime: 0:00:54.549804 FixedProfit: 988957\n",
            "Episode: 38/100 RapTime: 0:00:53.876891 FixedProfit: 1017969\n",
            "Episode: 39/100 RapTime: 0:00:55.002974 FixedProfit: 1063960\n",
            "Episode: 40/100 RapTime: 0:00:55.812071 FixedProfit: 1146868\n",
            "Episode: 41/100 RapTime: 0:00:56.079870 FixedProfit: 1099330\n",
            "Episode: 42/100 RapTime: 0:00:55.121957 FixedProfit: 794724\n",
            "Episode: 43/100 RapTime: 0:00:54.310088 FixedProfit: 1182129\n",
            "Episode: 44/100 RapTime: 0:00:55.262446 FixedProfit: 1153901\n",
            "Episode: 45/100 RapTime: 0:00:55.517446 FixedProfit: 1277365\n",
            "Episode: 46/100 RapTime: 0:00:55.455939 FixedProfit: 1025397\n",
            "Episode: 47/100 RapTime: 0:00:55.469711 FixedProfit: 1038173\n",
            "Episode: 48/100 RapTime: 0:00:55.690152 FixedProfit: 1023956\n",
            "Episode: 49/100 RapTime: 0:00:55.454213 FixedProfit: 1178049\n",
            "Episode: 50/100 RapTime: 0:00:55.434550 FixedProfit: 1257014\n",
            "Episode: 51/100 RapTime: 0:00:55.357349 FixedProfit: 1182077\n",
            "Episode: 52/100 RapTime: 0:00:55.548274 FixedProfit: 999276\n",
            "Episode: 53/100 RapTime: 0:00:56.195453 FixedProfit: 1060307\n",
            "Episode: 54/100 RapTime: 0:00:55.826196 FixedProfit: 1085184\n",
            "Episode: 55/100 RapTime: 0:00:55.524633 FixedProfit: 1207424\n",
            "Episode: 56/100 RapTime: 0:00:55.737224 FixedProfit: 1199827\n",
            "Episode: 57/100 RapTime: 0:00:55.508073 FixedProfit: 1217080\n",
            "Episode: 58/100 RapTime: 0:00:55.404395 FixedProfit: 961601\n",
            "Episode: 59/100 RapTime: 0:00:55.190638 FixedProfit: 1254213\n",
            "Episode: 60/100 RapTime: 0:00:55.320919 FixedProfit: 988905\n",
            "Episode: 61/100 RapTime: 0:00:55.050662 FixedProfit: 1217909\n",
            "Episode: 62/100 RapTime: 0:00:55.553724 FixedProfit: 879913\n",
            "Episode: 63/100 RapTime: 0:00:55.039146 FixedProfit: 1155353\n",
            "Episode: 64/100 RapTime: 0:00:55.402329 FixedProfit: 1205029\n",
            "Episode: 65/100 RapTime: 0:00:55.836706 FixedProfit: 1021112\n",
            "Episode: 66/100 RapTime: 0:00:55.311154 FixedProfit: 1298852\n",
            "Episode: 67/100 RapTime: 0:00:55.034423 FixedProfit: 1080058\n",
            "Episode: 68/100 RapTime: 0:00:54.776664 FixedProfit: 1318026\n",
            "Episode: 69/100 RapTime: 0:00:55.303339 FixedProfit: 903525\n",
            "Episode: 70/100 RapTime: 0:00:55.246836 FixedProfit: 1091143\n",
            "Episode: 71/100 RapTime: 0:00:54.992095 FixedProfit: 1049738\n",
            "Episode: 72/100 RapTime: 0:00:54.397566 FixedProfit: 1305251\n",
            "Episode: 73/100 RapTime: 0:00:56.019546 FixedProfit: 1109885\n",
            "Episode: 74/100 RapTime: 0:00:55.813088 FixedProfit: 1168797\n",
            "Episode: 75/100 RapTime: 0:00:54.415169 FixedProfit: 1002939\n",
            "Episode: 76/100 RapTime: 0:00:54.583488 FixedProfit: 1018359\n",
            "Episode: 77/100 RapTime: 0:00:54.062639 FixedProfit: 987504\n",
            "Episode: 78/100 RapTime: 0:00:54.193348 FixedProfit: 991079\n",
            "Episode: 79/100 RapTime: 0:00:54.318156 FixedProfit: 925399\n",
            "Episode: 80/100 RapTime: 0:00:54.274952 FixedProfit: 1123947\n",
            "Episode: 81/100 RapTime: 0:00:54.635783 FixedProfit: 1116847\n",
            "Episode: 82/100 RapTime: 0:00:54.026165 FixedProfit: 984222\n",
            "Episode: 83/100 RapTime: 0:00:54.174089 FixedProfit: 1150661\n",
            "Episode: 84/100 RapTime: 0:00:53.851366 FixedProfit: 1268978\n",
            "Episode: 85/100 RapTime: 0:00:54.186856 FixedProfit: 1057038\n",
            "Episode: 86/100 RapTime: 0:00:54.302220 FixedProfit: 985648\n",
            "Episode: 87/100 RapTime: 0:00:54.146770 FixedProfit: 1270568\n",
            "Episode: 88/100 RapTime: 0:00:53.790894 FixedProfit: 1307169\n",
            "Episode: 89/100 RapTime: 0:00:54.057931 FixedProfit: 1226656\n",
            "Episode: 90/100 RapTime: 0:00:54.050893 FixedProfit: 992386\n",
            "Episode: 91/100 RapTime: 0:00:53.912705 FixedProfit: 1103210\n",
            "Episode: 92/100 RapTime: 0:00:54.797050 FixedProfit: 1004471\n",
            "Episode: 93/100 RapTime: 0:00:53.606858 FixedProfit: 1011914\n",
            "Episode: 94/100 RapTime: 0:00:53.926642 FixedProfit: 1094961\n",
            "Episode: 95/100 RapTime: 0:00:53.699394 FixedProfit: 1048786\n",
            "Episode: 96/100 RapTime: 0:00:53.447313 FixedProfit: 1070129\n",
            "Episode: 97/100 RapTime: 0:00:54.121322 FixedProfit: 1409338\n",
            "Episode: 98/100 RapTime: 0:00:53.596028 FixedProfit: 1102985\n",
            "Episode: 99/100 RapTime: 0:00:54.157933 FixedProfit: 1256969\n",
            "Episode: 100/100 RapTime: 0:00:53.918302 FixedProfit: 1052097\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}