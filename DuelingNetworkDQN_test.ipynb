{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DuelingNetworkDQN_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNIFOMN/4TQhv9o/LAuOMNJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/DuelingNetworkDQN_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "4b4568fc-a0b2-40c8-b67a-db591d90bc62"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU, Conv1D, Input, Lambda\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "mode = 'test'\n",
        "name = 'dn_dqn'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evsq8JqfWNoj"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "\n",
        "        self.cntr = 0\n",
        "        self.size = 0\n",
        "        self.max_size = max_size\n",
        "        self.batch_size = batch_size\n",
        "        self.states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.next_states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.acts_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "        self.rewards_memory = np.zeros(self.max_size, dtype=np.float32)\n",
        "        self.done_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        self.states_memory[self.cntr] = state\n",
        "        self.next_states_memory[self.cntr] = next_state\n",
        "        self.acts_memory[self.cntr] = act\n",
        "        self.rewards_memory[self.cntr] = reward\n",
        "        self.done_memory[self.cntr] = done\n",
        "        self.cntr = (self.cntr+1) % self.max_size\n",
        "        self.size = min(self.size+1, self.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(self.size, self.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [self.states_memory[mb_index],self.next_states_memory[mb_index],\n",
        "                 self.acts_memory[mb_index],self.rewards_memory[mb_index],\n",
        "                 self.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        learning_rate = 0.00001\n",
        "        neurons_per_layer = 24\n",
        "\n",
        "        input = Input(shape=(3,))\n",
        "        common = Dense(neurons_per_layer*2, activation='relu')(input)\n",
        "        common = Dense(neurons_per_layer*4, activation='relu')(common)\n",
        "\n",
        "        common = Dense(4, activation='linear')(common)\n",
        "        output = Lambda(lambda a: K.expand_dims(a[:, 0], -1) + a[:, 1:] - 0.0*K.mean(a[:, 1:], keepdims=True),output_shape=(3,))(common)\n",
        "\n",
        "        model = keras.Model(inputs=input, outputs=output)\n",
        "\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        model.compile(loss=Huber(), optimizer=optimizer)\n",
        "        model.summary()\n",
        "        self.model = model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain, ReplayMemory):\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "        self.batch_size = batch_size\n",
        "        Brain.__init__(self)\n",
        "        ReplayMemory.__init__(self, max_size, batch_size)\n",
        "\n",
        "    def update_replay_memory(self, state, action, reward, next_state, done):\n",
        "        self.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def replay(self):\n",
        "        if self.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.model.predict(next_states), axis=1)\n",
        "\n",
        "        target_full = self.model.predict(states)\n",
        "\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.model.train_on_batch(states, target_full)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 200, mode = 'test'):\n",
        "        self.env            = env\n",
        "        self.agent          = agent\n",
        "        self.mdl_dir        = mdl_dir\n",
        "        self.scaler         = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode           = mode\n",
        "        self.name           = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done  = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.agent.update_replay_memory(state, action, reward, next_state, done)\n",
        "                    self.agent.replay()                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "08d82224-98cc-4eb7-8956-e562b363bb80"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 200\n",
        "batch_size = 32\n",
        "max_size = 500\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "agent = Agent(max_size, batch_size)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 3)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 48)                192       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 96)                4704      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 388       \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 5,284\n",
            "Trainable params: 5,284\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Episode: 1/200 RapTime: 0:01:04.076067 FixedProfit: 1168680\n",
            "Episode: 2/200 RapTime: 0:01:13.787689 FixedProfit: 979675\n",
            "Episode: 3/200 RapTime: 0:01:13.626748 FixedProfit: 1060792\n",
            "Episode: 4/200 RapTime: 0:01:14.155876 FixedProfit: 1000000\n",
            "Episode: 5/200 RapTime: 0:01:14.992339 FixedProfit: 1000000\n",
            "Episode: 6/200 RapTime: 0:01:13.624288 FixedProfit: 1075605\n",
            "Episode: 7/200 RapTime: 0:01:13.690029 FixedProfit: 1000000\n",
            "Episode: 8/200 RapTime: 0:01:13.755689 FixedProfit: 1157717\n",
            "Episode: 9/200 RapTime: 0:01:14.265900 FixedProfit: 1033116\n",
            "Episode: 10/200 RapTime: 0:01:14.349379 FixedProfit: 1000000\n",
            "Episode: 11/200 RapTime: 0:01:14.346003 FixedProfit: 982419\n",
            "Episode: 12/200 RapTime: 0:01:13.704620 FixedProfit: 992356\n",
            "Episode: 13/200 RapTime: 0:01:13.957593 FixedProfit: 1000000\n",
            "Episode: 14/200 RapTime: 0:01:13.353366 FixedProfit: 1162123\n",
            "Episode: 15/200 RapTime: 0:01:13.645551 FixedProfit: 1131517\n",
            "Episode: 16/200 RapTime: 0:01:14.151616 FixedProfit: 1231716\n",
            "Episode: 17/200 RapTime: 0:01:13.640839 FixedProfit: 1299995\n",
            "Episode: 18/200 RapTime: 0:01:13.277066 FixedProfit: 988509\n",
            "Episode: 19/200 RapTime: 0:01:13.404520 FixedProfit: 1183147\n",
            "Episode: 20/200 RapTime: 0:01:13.463900 FixedProfit: 1147077\n",
            "Episode: 21/200 RapTime: 0:01:13.336563 FixedProfit: 1037391\n",
            "Episode: 22/200 RapTime: 0:01:14.560472 FixedProfit: 1014940\n",
            "Episode: 23/200 RapTime: 0:01:13.838625 FixedProfit: 1075382\n",
            "Episode: 24/200 RapTime: 0:01:13.262449 FixedProfit: 1086003\n",
            "Episode: 25/200 RapTime: 0:01:13.953405 FixedProfit: 1090579\n",
            "Episode: 26/200 RapTime: 0:01:13.396583 FixedProfit: 1150311\n",
            "Episode: 27/200 RapTime: 0:01:13.687737 FixedProfit: 1139873\n",
            "Episode: 28/200 RapTime: 0:01:14.815186 FixedProfit: 1259828\n",
            "Episode: 29/200 RapTime: 0:01:13.942084 FixedProfit: 1070379\n",
            "Episode: 30/200 RapTime: 0:01:13.934533 FixedProfit: 1105169\n",
            "Episode: 31/200 RapTime: 0:01:14.158953 FixedProfit: 1063383\n",
            "Episode: 32/200 RapTime: 0:01:13.928177 FixedProfit: 1170518\n",
            "Episode: 33/200 RapTime: 0:01:14.243300 FixedProfit: 1145670\n",
            "Episode: 34/200 RapTime: 0:01:14.822097 FixedProfit: 1171244\n",
            "Episode: 35/200 RapTime: 0:01:13.301629 FixedProfit: 1009477\n",
            "Episode: 36/200 RapTime: 0:01:13.546470 FixedProfit: 1087142\n",
            "Episode: 37/200 RapTime: 0:01:13.400076 FixedProfit: 1245157\n",
            "Episode: 38/200 RapTime: 0:01:13.319351 FixedProfit: 1181156\n",
            "Episode: 39/200 RapTime: 0:01:13.121498 FixedProfit: 1010171\n",
            "Episode: 40/200 RapTime: 0:01:13.357494 FixedProfit: 992977\n",
            "Episode: 41/200 RapTime: 0:01:13.308257 FixedProfit: 1015702\n",
            "Episode: 42/200 RapTime: 0:01:13.291297 FixedProfit: 1023664\n",
            "Episode: 43/200 RapTime: 0:01:13.189003 FixedProfit: 1135156\n",
            "Episode: 44/200 RapTime: 0:01:13.019724 FixedProfit: 1010709\n",
            "Episode: 45/200 RapTime: 0:01:13.185742 FixedProfit: 1000000\n",
            "Episode: 46/200 RapTime: 0:01:13.048143 FixedProfit: 985326\n",
            "Episode: 47/200 RapTime: 0:01:13.001282 FixedProfit: 967652\n",
            "Episode: 48/200 RapTime: 0:01:12.669338 FixedProfit: 1014442\n",
            "Episode: 49/200 RapTime: 0:01:12.599814 FixedProfit: 1007316\n",
            "Episode: 50/200 RapTime: 0:01:12.813809 FixedProfit: 1000000\n",
            "Episode: 51/200 RapTime: 0:01:12.894225 FixedProfit: 985504\n",
            "Episode: 52/200 RapTime: 0:01:13.106546 FixedProfit: 1015930\n",
            "Episode: 53/200 RapTime: 0:01:13.325936 FixedProfit: 998049\n",
            "Episode: 54/200 RapTime: 0:01:13.546456 FixedProfit: 1004269\n",
            "Episode: 55/200 RapTime: 0:01:13.724344 FixedProfit: 1008564\n",
            "Episode: 56/200 RapTime: 0:01:13.744769 FixedProfit: 1000000\n",
            "Episode: 57/200 RapTime: 0:01:13.382504 FixedProfit: 1000347\n",
            "Episode: 58/200 RapTime: 0:01:13.120401 FixedProfit: 1010403\n",
            "Episode: 59/200 RapTime: 0:01:13.254906 FixedProfit: 1018600\n",
            "Episode: 60/200 RapTime: 0:01:13.001055 FixedProfit: 1010430\n",
            "Episode: 61/200 RapTime: 0:01:12.924081 FixedProfit: 1008360\n",
            "Episode: 62/200 RapTime: 0:01:13.189576 FixedProfit: 1010670\n",
            "Episode: 63/200 RapTime: 0:01:13.211079 FixedProfit: 983368\n",
            "Episode: 64/200 RapTime: 0:01:12.920917 FixedProfit: 1003909\n",
            "Episode: 65/200 RapTime: 0:01:12.838650 FixedProfit: 1077173\n",
            "Episode: 66/200 RapTime: 0:01:12.727943 FixedProfit: 1029700\n",
            "Episode: 67/200 RapTime: 0:01:12.502375 FixedProfit: 1084514\n",
            "Episode: 68/200 RapTime: 0:01:12.636344 FixedProfit: 1064921\n",
            "Episode: 69/200 RapTime: 0:01:12.642429 FixedProfit: 1010157\n",
            "Episode: 70/200 RapTime: 0:01:12.534542 FixedProfit: 1095226\n",
            "Episode: 71/200 RapTime: 0:01:12.798393 FixedProfit: 995861\n",
            "Episode: 72/200 RapTime: 0:01:12.519668 FixedProfit: 999547\n",
            "Episode: 73/200 RapTime: 0:01:12.256158 FixedProfit: 1133620\n",
            "Episode: 74/200 RapTime: 0:01:12.731637 FixedProfit: 1213155\n",
            "Episode: 75/200 RapTime: 0:01:12.494027 FixedProfit: 1170774\n",
            "Episode: 76/200 RapTime: 0:01:12.477201 FixedProfit: 1172464\n",
            "Episode: 77/200 RapTime: 0:01:12.927750 FixedProfit: 1158137\n",
            "Episode: 78/200 RapTime: 0:01:13.680196 FixedProfit: 993458\n",
            "Episode: 79/200 RapTime: 0:01:15.381091 FixedProfit: 990060\n",
            "Episode: 80/200 RapTime: 0:01:14.697370 FixedProfit: 1003915\n",
            "Episode: 81/200 RapTime: 0:01:14.535424 FixedProfit: 1002115\n",
            "Episode: 82/200 RapTime: 0:01:14.457564 FixedProfit: 1002246\n",
            "Episode: 83/200 RapTime: 0:01:14.839183 FixedProfit: 988813\n",
            "Episode: 84/200 RapTime: 0:01:14.307922 FixedProfit: 1162984\n",
            "Episode: 85/200 RapTime: 0:01:14.887909 FixedProfit: 1000000\n",
            "Episode: 86/200 RapTime: 0:01:14.840024 FixedProfit: 1164805\n",
            "Episode: 87/200 RapTime: 0:01:14.784156 FixedProfit: 1170518\n",
            "Episode: 88/200 RapTime: 0:01:15.312647 FixedProfit: 982411\n",
            "Episode: 89/200 RapTime: 0:01:15.100715 FixedProfit: 1029775\n",
            "Episode: 90/200 RapTime: 0:01:14.687819 FixedProfit: 1045803\n",
            "Episode: 91/200 RapTime: 0:01:14.862986 FixedProfit: 1133581\n",
            "Episode: 92/200 RapTime: 0:01:14.935336 FixedProfit: 1037861\n",
            "Episode: 93/200 RapTime: 0:01:14.910637 FixedProfit: 1171244\n",
            "Episode: 94/200 RapTime: 0:01:14.657984 FixedProfit: 1018226\n",
            "Episode: 95/200 RapTime: 0:01:14.741019 FixedProfit: 946858\n",
            "Episode: 96/200 RapTime: 0:01:14.884774 FixedProfit: 1015497\n",
            "Episode: 97/200 RapTime: 0:01:12.648253 FixedProfit: 1003376\n",
            "Episode: 98/200 RapTime: 0:01:12.296646 FixedProfit: 996705\n",
            "Episode: 99/200 RapTime: 0:01:12.498929 FixedProfit: 1001739\n",
            "Episode: 100/200 RapTime: 0:01:12.971083 FixedProfit: 1006272\n",
            "Episode: 101/200 RapTime: 0:01:12.868995 FixedProfit: 987546\n",
            "Episode: 102/200 RapTime: 0:01:12.642137 FixedProfit: 970427\n",
            "Episode: 103/200 RapTime: 0:01:12.943846 FixedProfit: 1000000\n",
            "Episode: 104/200 RapTime: 0:01:12.775552 FixedProfit: 1001267\n",
            "Episode: 105/200 RapTime: 0:01:12.568460 FixedProfit: 1003208\n",
            "Episode: 106/200 RapTime: 0:01:12.599793 FixedProfit: 975616\n",
            "Episode: 107/200 RapTime: 0:01:12.622437 FixedProfit: 1000830\n",
            "Episode: 108/200 RapTime: 0:01:12.788470 FixedProfit: 998262\n",
            "Episode: 109/200 RapTime: 0:01:12.598297 FixedProfit: 996248\n",
            "Episode: 110/200 RapTime: 0:01:12.907917 FixedProfit: 1000000\n",
            "Episode: 111/200 RapTime: 0:01:12.657085 FixedProfit: 984911\n",
            "Episode: 112/200 RapTime: 0:01:12.595256 FixedProfit: 1163402\n",
            "Episode: 113/200 RapTime: 0:01:12.354231 FixedProfit: 1000000\n",
            "Episode: 114/200 RapTime: 0:01:12.480864 FixedProfit: 1113792\n",
            "Episode: 115/200 RapTime: 0:01:12.519043 FixedProfit: 1213942\n",
            "Episode: 116/200 RapTime: 0:01:12.762600 FixedProfit: 1197509\n",
            "Episode: 117/200 RapTime: 0:01:13.423150 FixedProfit: 1066352\n",
            "Episode: 118/200 RapTime: 0:01:13.254055 FixedProfit: 1090778\n",
            "Episode: 119/200 RapTime: 0:01:13.244238 FixedProfit: 1173727\n",
            "Episode: 120/200 RapTime: 0:01:13.055408 FixedProfit: 1086822\n",
            "Episode: 121/200 RapTime: 0:01:12.816634 FixedProfit: 1153329\n",
            "Episode: 122/200 RapTime: 0:01:13.018676 FixedProfit: 1000000\n",
            "Episode: 123/200 RapTime: 0:01:12.939249 FixedProfit: 1014926\n",
            "Episode: 124/200 RapTime: 0:01:12.941766 FixedProfit: 1000000\n",
            "Episode: 125/200 RapTime: 0:01:13.136153 FixedProfit: 1000000\n",
            "Episode: 126/200 RapTime: 0:01:12.735274 FixedProfit: 1285014\n",
            "Episode: 127/200 RapTime: 0:01:13.223327 FixedProfit: 1127838\n",
            "Episode: 128/200 RapTime: 0:01:12.667453 FixedProfit: 1000000\n",
            "Episode: 129/200 RapTime: 0:01:12.329268 FixedProfit: 1063897\n",
            "Episode: 130/200 RapTime: 0:01:12.831586 FixedProfit: 1125183\n",
            "Episode: 131/200 RapTime: 0:01:12.663145 FixedProfit: 1219220\n",
            "Episode: 132/200 RapTime: 0:01:12.519373 FixedProfit: 1053976\n",
            "Episode: 133/200 RapTime: 0:01:12.781003 FixedProfit: 1041380\n",
            "Episode: 134/200 RapTime: 0:01:12.697886 FixedProfit: 1261567\n",
            "Episode: 135/200 RapTime: 0:01:12.632603 FixedProfit: 1157638\n",
            "Episode: 136/200 RapTime: 0:01:12.796988 FixedProfit: 1124617\n",
            "Episode: 137/200 RapTime: 0:01:12.818147 FixedProfit: 1146346\n",
            "Episode: 138/200 RapTime: 0:01:12.776849 FixedProfit: 1031327\n",
            "Episode: 139/200 RapTime: 0:01:12.941897 FixedProfit: 1021029\n",
            "Episode: 140/200 RapTime: 0:01:13.012841 FixedProfit: 1058912\n",
            "Episode: 141/200 RapTime: 0:01:13.353437 FixedProfit: 988330\n",
            "Episode: 142/200 RapTime: 0:01:13.341356 FixedProfit: 1000806\n",
            "Episode: 143/200 RapTime: 0:01:13.108248 FixedProfit: 1030354\n",
            "Episode: 144/200 RapTime: 0:01:13.174099 FixedProfit: 990133\n",
            "Episode: 145/200 RapTime: 0:01:13.063938 FixedProfit: 1006791\n",
            "Episode: 146/200 RapTime: 0:01:13.642930 FixedProfit: 996296\n",
            "Episode: 147/200 RapTime: 0:01:13.572829 FixedProfit: 1009200\n",
            "Episode: 148/200 RapTime: 0:01:13.638370 FixedProfit: 1010045\n",
            "Episode: 149/200 RapTime: 0:01:13.208070 FixedProfit: 969191\n",
            "Episode: 150/200 RapTime: 0:01:13.443939 FixedProfit: 1000000\n",
            "Episode: 151/200 RapTime: 0:01:13.212089 FixedProfit: 995896\n",
            "Episode: 152/200 RapTime: 0:01:13.350189 FixedProfit: 957280\n",
            "Episode: 153/200 RapTime: 0:01:13.234670 FixedProfit: 1019936\n",
            "Episode: 154/200 RapTime: 0:01:13.968530 FixedProfit: 998725\n",
            "Episode: 155/200 RapTime: 0:01:13.529356 FixedProfit: 1017028\n",
            "Episode: 156/200 RapTime: 0:01:13.616077 FixedProfit: 1006299\n",
            "Episode: 157/200 RapTime: 0:01:14.248960 FixedProfit: 1000000\n",
            "Episode: 158/200 RapTime: 0:01:13.723576 FixedProfit: 1005958\n",
            "Episode: 159/200 RapTime: 0:01:14.118077 FixedProfit: 1000299\n",
            "Episode: 160/200 RapTime: 0:01:13.574290 FixedProfit: 1261474\n",
            "Episode: 161/200 RapTime: 0:01:13.894612 FixedProfit: 981984\n",
            "Episode: 162/200 RapTime: 0:01:13.844635 FixedProfit: 1096958\n",
            "Episode: 163/200 RapTime: 0:01:13.578117 FixedProfit: 994661\n",
            "Episode: 164/200 RapTime: 0:01:14.044789 FixedProfit: 989903\n",
            "Episode: 165/200 RapTime: 0:01:14.381305 FixedProfit: 1152496\n",
            "Episode: 166/200 RapTime: 0:01:14.083994 FixedProfit: 1048885\n",
            "Episode: 167/200 RapTime: 0:01:13.767912 FixedProfit: 930711\n",
            "Episode: 168/200 RapTime: 0:01:13.807901 FixedProfit: 1216277\n",
            "Episode: 169/200 RapTime: 0:01:14.120896 FixedProfit: 1028763\n",
            "Episode: 170/200 RapTime: 0:01:14.115200 FixedProfit: 1061226\n",
            "Episode: 171/200 RapTime: 0:01:13.920991 FixedProfit: 1187004\n",
            "Episode: 172/200 RapTime: 0:01:13.957818 FixedProfit: 896579\n",
            "Episode: 173/200 RapTime: 0:01:14.276634 FixedProfit: 993590\n",
            "Episode: 174/200 RapTime: 0:01:13.953861 FixedProfit: 995340\n",
            "Episode: 175/200 RapTime: 0:01:14.035040 FixedProfit: 990884\n",
            "Episode: 176/200 RapTime: 0:01:13.582078 FixedProfit: 1001234\n",
            "Episode: 177/200 RapTime: 0:01:13.580391 FixedProfit: 1000000\n",
            "Episode: 178/200 RapTime: 0:01:13.843262 FixedProfit: 1005000\n",
            "Episode: 179/200 RapTime: 0:01:13.819940 FixedProfit: 1019168\n",
            "Episode: 180/200 RapTime: 0:01:13.527180 FixedProfit: 1016139\n",
            "Episode: 181/200 RapTime: 0:01:12.931712 FixedProfit: 1012307\n",
            "Episode: 182/200 RapTime: 0:01:13.461987 FixedProfit: 1001477\n",
            "Episode: 183/200 RapTime: 0:01:13.572746 FixedProfit: 999129\n",
            "Episode: 184/200 RapTime: 0:01:13.436047 FixedProfit: 1012517\n",
            "Episode: 185/200 RapTime: 0:01:13.441717 FixedProfit: 979220\n",
            "Episode: 186/200 RapTime: 0:01:13.912880 FixedProfit: 991622\n",
            "Episode: 187/200 RapTime: 0:01:13.405736 FixedProfit: 1041193\n",
            "Episode: 188/200 RapTime: 0:01:13.875124 FixedProfit: 1000000\n",
            "Episode: 189/200 RapTime: 0:01:14.062769 FixedProfit: 1011047\n",
            "Episode: 190/200 RapTime: 0:01:13.485926 FixedProfit: 996228\n",
            "Episode: 191/200 RapTime: 0:01:13.265388 FixedProfit: 983363\n",
            "Episode: 192/200 RapTime: 0:01:13.484072 FixedProfit: 1000419\n",
            "Episode: 193/200 RapTime: 0:01:13.947198 FixedProfit: 1000000\n",
            "Episode: 194/200 RapTime: 0:01:13.889721 FixedProfit: 1013884\n",
            "Episode: 195/200 RapTime: 0:01:13.739693 FixedProfit: 998139\n",
            "Episode: 196/200 RapTime: 0:01:13.535807 FixedProfit: 976501\n",
            "Episode: 197/200 RapTime: 0:01:13.848501 FixedProfit: 1000000\n",
            "Episode: 198/200 RapTime: 0:01:13.796396 FixedProfit: 1013740\n",
            "Episode: 199/200 RapTime: 0:01:13.898197 FixedProfit: 1008782\n",
            "Episode: 200/200 RapTime: 0:01:14.037871 FixedProfit: 1016718\n"
          ]
        }
      ]
    }
  ]
}