{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gorila_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMu+2LI5jroMCZNCuDsY+iq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/gorila_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "eadc5c10-bd68-4f69-f6e7-896fa13fcc4e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "mode = 'train'\n",
        "name = 'gorila'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U1RNmtkaZ2W"
      },
      "source": [
        "class ParameterServer:\n",
        "    def __init__(self):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        mastermodel = Sequential()\n",
        "        mastermodel.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_mid))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_action))\n",
        "        mastermodel.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((mastermodel.summary()))\n",
        "        self.mastermodel = mastermodel\n",
        "    \n",
        "    def load(self, name):\n",
        "        self.mastermodel.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.mastermodel.save_weights(name)\n",
        "\n",
        "    def placement(self, model):\n",
        "        for m, mm in zip(model.trainable_weights, self.mastermodel.trainable_weights):\n",
        "            m.assign(mm)\n",
        "\n",
        "    def integration(self, model):\n",
        "        for mm, m in zip(self.mastermodel.trainable_weights, model.trainable_weights):\n",
        "            mm.assign(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, masterbrain):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "        self.masterbrain = masterbrain\n",
        "\n",
        "    def load(self, name):\n",
        "        self.masterbrain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.masterbrain.save(name)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def train_on_batch(self, state, target_full):\n",
        "        self.model.train_on_batch(state, target_full)\n",
        "\n",
        "    def layering(self):\n",
        "        self.masterbrain.placement(self.model)\n",
        "\n",
        "    def integration(self):\n",
        "        self.masterbrain.integration(self.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1_BMH7hLQ8"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size, batch_size=32):\n",
        "\n",
        "        self.cntr = 0\n",
        "        self.size = 0\n",
        "        self.max_size = max_size\n",
        "        self.batch_size = batch_size\n",
        "        self.states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.next_states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.acts_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "        self.rewards_memory = np.zeros(self.max_size, dtype=np.float32)\n",
        "        self.done_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        self.states_memory[self.cntr] = state\n",
        "        self.next_states_memory[self.cntr] = next_state\n",
        "        self.acts_memory[self.cntr] = act\n",
        "        self.rewards_memory[self.cntr] = reward\n",
        "        self.done_memory[self.cntr] = done\n",
        "        self.cntr = (self.cntr+1) % self.max_size\n",
        "        self.size = min(self.size+1, self.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(self.size, self.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [self.states_memory[mb_index],self.next_states_memory[mb_index],\n",
        "                 self.acts_memory[mb_index],self.rewards_memory[mb_index],\n",
        "                 self.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrEa4wpGG1DF"
      },
      "source": [
        "class Actor:\n",
        "    def __init__(self, brain, memory, max_size, batch_size = 32):\n",
        "\n",
        "        self.brain   = brain\n",
        "        self.memory  = memory\n",
        "        self.epsilon = 1.0\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.brain.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        self.memory.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "    def layering(self):\n",
        "        self.brain.layering()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42NIN-PGBOc8"
      },
      "source": [
        "class Learner:\n",
        "    def __init__(self, brain, memory, batch_size = 32):\n",
        "\n",
        "        self.brain  = brain\n",
        "        self.memory = memory\n",
        "        self.gamma       = 0.95\n",
        "        self.epsilon     = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r           = 0.995\n",
        "        self.batch_size  = batch_size\n",
        "\n",
        "    def learn(self):\n",
        "        if self.memory.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.memory.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.brain.predict(next_states), axis=1)\n",
        "\n",
        "        target_full = self.brain.predict(states)\n",
        "\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.brain.train_on_batch(states, target_full)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "\n",
        "    def integration(self):\n",
        "        self.brain.integration()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, actor, learner, num, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env            = env\n",
        "        self.actor          = actor\n",
        "        self.learner        = learner\n",
        "        self.num            = str(num)\n",
        "        self.mdl_dir        = mdl_dir\n",
        "        self.scaler         = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode           = mode\n",
        "        self.name           = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.actor.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "        self.actor.layering()\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done  = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.actor.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.actor.store_transition(state, action, reward, next_state, done)\n",
        "                    self.learner.learn()\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                learner.integration()\n",
        "                actor.layering()\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.actor.load('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "        self.actor.save('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "f2f88c8e-0463-4eb1-b844-1c0658e092de"
      },
      "source": [
        "initial_money  = 1000000\n",
        "episodes_times = 50\n",
        "batch_size     = 32\n",
        "max_size       = 1000\n",
        "\n",
        "masterbrain    = ParameterServer()\n",
        "memory         = ReplayMemory(max_size, batch_size)\n",
        "\n",
        "thread_num = 4\n",
        "envs = []\n",
        "for i in range(thread_num):\n",
        "    env     = Environment(df, initial_money=initial_money, mode = mode)\n",
        "    brain   = Brain(masterbrain)\n",
        "    actor   = Actor(brain, memory, max_size, batch_size)\n",
        "    learner = Learner(brain, memory, batch_size)\n",
        "    main    = Main(env, actor, learner, i, mdl_dir, name, episodes_times, mode)\n",
        "    envs.append(main)\n",
        "\n",
        "datas = []\n",
        "with ThreadPoolExecutor(max_workers=thread_num) as executor:\n",
        "    for env in envs:\n",
        "        job = lambda: env.play_game()\n",
        "        datas.append(executor.submit(job))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/50 RapTime: 0:02:12.188997 FixedProfit: 1052254\n",
            "Episode: 1/50 RapTime: 0:02:15.821481 FixedProfit: 1137980\n",
            "Episode: 1/50 RapTime: 0:02:16.820632 FixedProfit: 1353409\n",
            "Episode: 1/50 RapTime: 0:02:19.789209 FixedProfit: 1385882\n",
            "Episode: 2/50 RapTime: 0:02:14.293255 FixedProfit: 1042109\n",
            "Episode: 2/50 RapTime: 0:02:16.866972 FixedProfit: 1233779\n",
            "Episode: 2/50 RapTime: 0:02:17.298831 FixedProfit: 1039210\n",
            "Episode: 2/50 RapTime: 0:02:15.831244 FixedProfit: 1151014\n",
            "Episode: 3/50 RapTime: 0:02:18.737072 FixedProfit: 924010\n",
            "Episode: 3/50 RapTime: 0:02:16.994464 FixedProfit: 1093907\n",
            "Episode: 3/50 RapTime: 0:02:18.157971 FixedProfit: 1025303\n",
            "Episode: 3/50 RapTime: 0:02:18.083787 FixedProfit: 1401118\n",
            "Episode: 4/50 RapTime: 0:02:16.198415 FixedProfit: 1111023\n",
            "Episode: 4/50 RapTime: 0:02:17.360640 FixedProfit: 985108\n",
            "Episode: 4/50 RapTime: 0:02:19.814708 FixedProfit: 1130825\n",
            "Episode: 4/50 RapTime: 0:02:20.320889 FixedProfit: 1276834\n",
            "Episode: 5/50 RapTime: 0:02:19.116402 FixedProfit: 1098065\n",
            "Episode: 5/50 RapTime: 0:02:22.190286 FixedProfit: 1144222\n",
            "Episode: 5/50 RapTime: 0:02:18.710204 FixedProfit: 1150301\n",
            "Episode: 5/50 RapTime: 0:02:19.104747 FixedProfit: 977927\n",
            "Episode: 6/50 RapTime: 0:02:19.026805 FixedProfit: 1217398\n",
            "Episode: 6/50 RapTime: 0:02:19.726929 FixedProfit: 959648\n",
            "Episode: 6/50 RapTime: 0:02:22.819970 FixedProfit: 905384\n",
            "Episode: 6/50 RapTime: 0:02:19.840871 FixedProfit: 1220516\n",
            "Episode: 7/50 RapTime: 0:02:21.490420 FixedProfit: 1000938\n",
            "Episode: 7/50 RapTime: 0:02:21.130338 FixedProfit: 1144196\n",
            "Episode: 7/50 RapTime: 0:02:19.998099 FixedProfit: 1120552\n",
            "Episode: 7/50 RapTime: 0:02:23.323983 FixedProfit: 960817\n",
            "Episode: 8/50 RapTime: 0:02:23.133210 FixedProfit: 1204343\n",
            "Episode: 8/50 RapTime: 0:02:21.055622 FixedProfit: 976789\n",
            "Episode: 8/50 RapTime: 0:02:22.388584 FixedProfit: 1095807\n",
            "Episode: 8/50 RapTime: 0:02:21.897109 FixedProfit: 1010735\n",
            "Episode: 9/50 RapTime: 0:02:23.365738 FixedProfit: 1259446\n",
            "Episode: 9/50 RapTime: 0:02:23.372410 FixedProfit: 1094222\n",
            "Episode: 9/50 RapTime: 0:02:21.812406 FixedProfit: 1045034\n",
            "Episode: 9/50 RapTime: 0:02:24.320137 FixedProfit: 1214338\n",
            "Episode: 10/50 RapTime: 0:02:22.128427 FixedProfit: 969257\n",
            "Episode: 10/50 RapTime: 0:02:23.533639 FixedProfit: 1134014\n",
            "Episode: 10/50 RapTime: 0:02:23.604385 FixedProfit: 1080775\n",
            "Episode: 10/50 RapTime: 0:02:24.280409 FixedProfit: 1110600\n",
            "Episode: 11/50 RapTime: 0:02:24.398388 FixedProfit: 1213555\n",
            "Episode: 11/50 RapTime: 0:02:24.188935 FixedProfit: 814952\n",
            "Episode: 11/50 RapTime: 0:02:24.581091 FixedProfit: 1176788\n",
            "Episode: 11/50 RapTime: 0:02:25.031680 FixedProfit: 1142144\n",
            "Episode: 12/50 RapTime: 0:02:26.461710 FixedProfit: 1083203\n",
            "Episode: 12/50 RapTime: 0:02:25.883352 FixedProfit: 1040965\n",
            "Episode: 12/50 RapTime: 0:02:25.559595 FixedProfit: 962370\n",
            "Episode: 12/50 RapTime: 0:02:26.738578 FixedProfit: 1149956\n",
            "Episode: 13/50 RapTime: 0:02:25.748947 FixedProfit: 1257782\n",
            "Episode: 13/50 RapTime: 0:02:25.301166 FixedProfit: 1255459\n",
            "Episode: 13/50 RapTime: 0:02:25.190522 FixedProfit: 1054699\n",
            "Episode: 13/50 RapTime: 0:02:29.462648 FixedProfit: 1168247\n",
            "Episode: 14/50 RapTime: 0:02:28.468226 FixedProfit: 1255768\n",
            "Episode: 14/50 RapTime: 0:02:25.000763 FixedProfit: 1011859\n",
            "Episode: 14/50 RapTime: 0:02:27.714045 FixedProfit: 933390\n",
            "Episode: 14/50 RapTime: 0:02:26.508409 FixedProfit: 1190776\n",
            "Episode: 15/50 RapTime: 0:02:27.333183 FixedProfit: 1153550\n",
            "Episode: 15/50 RapTime: 0:02:28.339548 FixedProfit: 1050571\n",
            "Episode: 15/50 RapTime: 0:02:30.623530 FixedProfit: 1032040\n",
            "Episode: 15/50 RapTime: 0:02:25.909172 FixedProfit: 1094595\n",
            "Episode: 16/50 RapTime: 0:02:29.919587 FixedProfit: 1036832\n",
            "Episode: 16/50 RapTime: 0:02:31.597474 FixedProfit: 939297\n",
            "Episode: 16/50 RapTime: 0:02:27.918502 FixedProfit: 1297680\n",
            "Episode: 16/50 RapTime: 0:02:28.783130 FixedProfit: 1145101\n",
            "Episode: 17/50 RapTime: 0:02:30.961610 FixedProfit: 1201888\n",
            "Episode: 17/50 RapTime: 0:02:29.918843 FixedProfit: 1302652\n",
            "Episode: 17/50 RapTime: 0:02:27.816804 FixedProfit: 1273530\n",
            "Episode: 17/50 RapTime: 0:02:31.463611 FixedProfit: 1117523\n",
            "Episode: 18/50 RapTime: 0:02:32.274082 FixedProfit: 905642\n",
            "Episode: 18/50 RapTime: 0:02:30.761200 FixedProfit: 1100080\n",
            "Episode: 18/50 RapTime: 0:02:32.104975 FixedProfit: 1023469\n",
            "Episode: 18/50 RapTime: 0:02:30.351808 FixedProfit: 1218806\n",
            "Episode: 19/50 RapTime: 0:02:33.722043 FixedProfit: 1137730\n",
            "Episode: 19/50 RapTime: 0:02:30.173168 FixedProfit: 1227267\n",
            "Episode: 19/50 RapTime: 0:02:32.345962 FixedProfit: 1079317\n",
            "Episode: 19/50 RapTime: 0:02:32.098590 FixedProfit: 958869\n",
            "Episode: 20/50 RapTime: 0:02:33.437420 FixedProfit: 1077101\n",
            "Episode: 20/50 RapTime: 0:02:32.403620 FixedProfit: 1095757\n",
            "Episode: 20/50 RapTime: 0:02:33.066989 FixedProfit: 1162595\n",
            "Episode: 20/50 RapTime: 0:02:34.022046 FixedProfit: 1237830\n",
            "Episode: 21/50 RapTime: 0:02:32.408253 FixedProfit: 960682\n",
            "Episode: 21/50 RapTime: 0:02:36.373683 FixedProfit: 1056302\n",
            "Episode: 21/50 RapTime: 0:02:33.426709 FixedProfit: 1143458\n",
            "Episode: 21/50 RapTime: 0:02:32.919967 FixedProfit: 1041851\n",
            "Episode: 22/50 RapTime: 0:02:33.896887 FixedProfit: 1128658\n",
            "Episode: 22/50 RapTime: 0:02:35.911984 FixedProfit: 1033078\n",
            "Episode: 22/50 RapTime: 0:02:35.481414 FixedProfit: 1050475\n",
            "Episode: 22/50 RapTime: 0:02:35.628381 FixedProfit: 951138\n",
            "Episode: 23/50 RapTime: 0:02:36.392827 FixedProfit: 1241673\n",
            "Episode: 23/50 RapTime: 0:02:35.555490 FixedProfit: 1035093\n",
            "Episode: 23/50 RapTime: 0:02:36.943307 FixedProfit: 1105677\n",
            "Episode: 23/50 RapTime: 0:02:35.169032 FixedProfit: 1294419\n",
            "Episode: 24/50 RapTime: 0:02:36.750478 FixedProfit: 1239072\n",
            "Episode: 24/50 RapTime: 0:02:36.866175 FixedProfit: 1141396\n",
            "Episode: 24/50 RapTime: 0:02:39.743807 FixedProfit: 1023454\n",
            "Episode: 24/50 RapTime: 0:02:35.970204 FixedProfit: 1027170\n",
            "Episode: 25/50 RapTime: 0:02:36.667695 FixedProfit: 1083290\n",
            "Episode: 25/50 RapTime: 0:02:41.570585 FixedProfit: 1026629\n",
            "Episode: 25/50 RapTime: 0:02:36.642951 FixedProfit: 1212484\n",
            "Episode: 25/50 RapTime: 0:02:37.195261 FixedProfit: 1245045\n",
            "Episode: 26/50 RapTime: 0:02:41.567923 FixedProfit: 1263199\n",
            "Episode: 26/50 RapTime: 0:02:40.328295 FixedProfit: 1011962\n",
            "Episode: 26/50 RapTime: 0:02:39.741016 FixedProfit: 1071152\n",
            "Episode: 26/50 RapTime: 0:02:38.129996 FixedProfit: 1373175\n",
            "Episode: 27/50 RapTime: 0:02:38.952023 FixedProfit: 1148372\n",
            "Episode: 27/50 RapTime: 0:02:42.466429 FixedProfit: 1244092\n",
            "Episode: 27/50 RapTime: 0:02:41.108783 FixedProfit: 1129242\n",
            "Episode: 27/50 RapTime: 0:02:39.813092 FixedProfit: 1207943\n",
            "Episode: 28/50 RapTime: 0:02:40.820231 FixedProfit: 1054368\n",
            "Episode: 28/50 RapTime: 0:02:39.491950 FixedProfit: 1124414\n",
            "Episode: 28/50 RapTime: 0:02:40.193704 FixedProfit: 1183870\n",
            "Episode: 28/50 RapTime: 0:02:44.268876 FixedProfit: 1068672\n",
            "Episode: 29/50 RapTime: 0:02:42.181643 FixedProfit: 1372198\n",
            "Episode: 29/50 RapTime: 0:02:39.404583 FixedProfit: 931082\n",
            "Episode: 29/50 RapTime: 0:02:45.858862 FixedProfit: 915519\n",
            "Episode: 29/50 RapTime: 0:02:42.002133 FixedProfit: 1235039\n",
            "Episode: 30/50 RapTime: 0:02:41.481168 FixedProfit: 937763\n",
            "Episode: 30/50 RapTime: 0:02:43.385117 FixedProfit: 988346\n",
            "Episode: 30/50 RapTime: 0:02:42.867477 FixedProfit: 1041727\n",
            "Episode: 30/50 RapTime: 0:02:45.387637 FixedProfit: 1032926\n",
            "Episode: 31/50 RapTime: 0:02:44.718000 FixedProfit: 1062542\n",
            "Episode: 31/50 RapTime: 0:02:42.530794 FixedProfit: 1165615\n",
            "Episode: 31/50 RapTime: 0:02:47.281605 FixedProfit: 1072021\n",
            "Episode: 31/50 RapTime: 0:02:46.471190 FixedProfit: 1136821\n",
            "Episode: 32/50 RapTime: 0:02:43.254915 FixedProfit: 1296785\n",
            "Episode: 32/50 RapTime: 0:02:44.094784 FixedProfit: 1116496\n",
            "Episode: 32/50 RapTime: 0:02:48.047163 FixedProfit: 1015648\n",
            "Episode: 32/50 RapTime: 0:02:46.457632 FixedProfit: 959320\n",
            "Episode: 33/50 RapTime: 0:02:48.332556 FixedProfit: 1089458\n",
            "Episode: 33/50 RapTime: 0:02:45.680023 FixedProfit: 1180677\n",
            "Episode: 33/50 RapTime: 0:02:46.327064 FixedProfit: 959195\n",
            "Episode: 33/50 RapTime: 0:02:50.329431 FixedProfit: 1041758\n",
            "Episode: 34/50 RapTime: 0:02:45.430039 FixedProfit: 1062245\n",
            "Episode: 34/50 RapTime: 0:02:50.040924 FixedProfit: 1201220\n",
            "Episode: 34/50 RapTime: 0:02:48.268814 FixedProfit: 1274426\n",
            "Episode: 34/50 RapTime: 0:02:48.965685 FixedProfit: 1167411\n",
            "Episode: 35/50 RapTime: 0:02:51.466170 FixedProfit: 1014916\n",
            "Episode: 35/50 RapTime: 0:02:49.646128 FixedProfit: 1072223\n",
            "Episode: 35/50 RapTime: 0:02:49.775151 FixedProfit: 855943\n",
            "Episode: 35/50 RapTime: 0:02:51.773303 FixedProfit: 1096902\n",
            "Episode: 36/50 RapTime: 0:02:50.949433 FixedProfit: 1119554\n",
            "Episode: 36/50 RapTime: 0:02:49.435975 FixedProfit: 952288\n",
            "Episode: 36/50 RapTime: 0:02:48.697223 FixedProfit: 993665\n",
            "Episode: 36/50 RapTime: 0:02:50.646427 FixedProfit: 1124070\n",
            "Episode: 37/50 RapTime: 0:02:51.269049 FixedProfit: 1291576\n",
            "Episode: 37/50 RapTime: 0:02:51.378301 FixedProfit: 1150555\n",
            "Episode: 37/50 RapTime: 0:02:51.671613 FixedProfit: 966295\n",
            "Episode: 37/50 RapTime: 0:02:53.889147 FixedProfit: 1152113\n",
            "Episode: 38/50 RapTime: 0:02:54.853242 FixedProfit: 1100210\n",
            "Episode: 38/50 RapTime: 0:02:51.363137 FixedProfit: 1335165\n",
            "Episode: 38/50 RapTime: 0:02:51.869523 FixedProfit: 1225381\n",
            "Episode: 38/50 RapTime: 0:02:53.362594 FixedProfit: 1112291\n",
            "Episode: 39/50 RapTime: 0:02:53.004182 FixedProfit: 1380898\n",
            "Episode: 39/50 RapTime: 0:02:53.380131 FixedProfit: 1409446\n",
            "Episode: 39/50 RapTime: 0:02:53.956372 FixedProfit: 969343\n",
            "Episode: 39/50 RapTime: 0:02:56.198411 FixedProfit: 1181267\n",
            "Episode: 40/50 RapTime: 0:02:53.118439 FixedProfit: 1013914\n",
            "Episode: 40/50 RapTime: 0:02:58.365478 FixedProfit: 816972\n",
            "Episode: 40/50 RapTime: 0:02:55.449580 FixedProfit: 1027388\n",
            "Episode: 40/50 RapTime: 0:02:55.033752 FixedProfit: 1318931\n",
            "Episode: 41/50 RapTime: 0:02:54.877354 FixedProfit: 1162914\n",
            "Episode: 41/50 RapTime: 0:02:58.108794 FixedProfit: 1005843\n",
            "Episode: 41/50 RapTime: 0:02:57.286277 FixedProfit: 1270634\n",
            "Episode: 41/50 RapTime: 0:02:57.008049 FixedProfit: 1231569\n",
            "Episode: 42/50 RapTime: 0:02:58.830241 FixedProfit: 920659\n",
            "Episode: 42/50 RapTime: 0:03:02.450203 FixedProfit: 1209006\n",
            "Episode: 42/50 RapTime: 0:02:55.966183 FixedProfit: 1050826\n",
            "Episode: 42/50 RapTime: 0:02:54.986399 FixedProfit: 1316452\n",
            "Episode: 43/50 RapTime: 0:02:56.208883 FixedProfit: 937659\n",
            "Episode: 43/50 RapTime: 0:02:59.277555 FixedProfit: 1155230\n",
            "Episode: 43/50 RapTime: 0:02:59.778865 FixedProfit: 1013464\n",
            "Episode: 43/50 RapTime: 0:03:03.178589 FixedProfit: 1182533\n",
            "Episode: 44/50 RapTime: 0:03:01.944760 FixedProfit: 1404450\n",
            "Episode: 44/50 RapTime: 0:02:59.237721 FixedProfit: 1060143\n",
            "Episode: 44/50 RapTime: 0:03:03.392719 FixedProfit: 1034359\n",
            "Episode: 44/50 RapTime: 0:02:58.359370 FixedProfit: 1023116\n",
            "Episode: 45/50 RapTime: 0:03:02.231309 FixedProfit: 1097614\n",
            "Episode: 45/50 RapTime: 0:03:00.047434 FixedProfit: 933031\n",
            "Episode: 45/50 RapTime: 0:03:02.277494 FixedProfit: 1146627\n",
            "Episode: 45/50 RapTime: 0:03:02.454109 FixedProfit: 1149128\n",
            "Episode: 46/50 RapTime: 0:03:06.335833 FixedProfit: 1028734\n",
            "Episode: 46/50 RapTime: 0:03:02.689106 FixedProfit: 1055223\n",
            "Episode: 46/50 RapTime: 0:03:00.918550 FixedProfit: 1153353\n",
            "Episode: 46/50 RapTime: 0:03:02.970147 FixedProfit: 921872\n",
            "Episode: 47/50 RapTime: 0:03:03.346403 FixedProfit: 963442\n",
            "Episode: 47/50 RapTime: 0:03:06.110699 FixedProfit: 1112284\n",
            "Episode: 47/50 RapTime: 0:03:03.946962 FixedProfit: 1167911\n",
            "Episode: 47/50 RapTime: 0:03:06.070217 FixedProfit: 884047\n",
            "Episode: 48/50 RapTime: 0:03:03.349243 FixedProfit: 1128290\n",
            "Episode: 48/50 RapTime: 0:03:08.721233 FixedProfit: 1043443\n",
            "Episode: 48/50 RapTime: 0:03:04.516300 FixedProfit: 1112388\n",
            "Episode: 48/50 RapTime: 0:03:06.439742 FixedProfit: 1156839\n",
            "Episode: 49/50 RapTime: 0:03:05.167857 FixedProfit: 1124645\n",
            "Episode: 49/50 RapTime: 0:03:05.552647 FixedProfit: 1333036\n",
            "Episode: 49/50 RapTime: 0:03:09.336882 FixedProfit: 988805\n",
            "Episode: 49/50 RapTime: 0:03:08.219808 FixedProfit: 1111758\n",
            "Episode: 50/50 RapTime: 0:03:07.970805 FixedProfit: 1253480\n",
            "Episode: 50/50 RapTime: 0:03:10.993930 FixedProfit: 970275\n",
            "Episode: 50/50 RapTime: 0:03:06.609441 FixedProfit: 1175387\n",
            "Episode: 50/50 RapTime: 0:03:06.316870 FixedProfit: 1112132\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}