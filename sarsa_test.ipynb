{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMFbeNElHFJBPQot/PrUBZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/sarsa_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "3a50c445-39c0-4bd5-9ca5-d8b6f55324b0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_test.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'sarsa_test.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self):\n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "        else:\n",
        "            if self.action_space[0] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1 \n",
        "            if self.action_space[2] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, next_act, done):\n",
        "        q = self.model.predict(state)\n",
        "        #next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*next_act\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state, act, reward, info, next_state, done, mode = 'train'):\n",
        "\n",
        "        next_act = self._next_act(state)\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.brain.train(state, act, reward, next_state, next_act, done)\n",
        "\n",
        "        return next_act\n",
        "\n",
        "    def _next_act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "        reward = 0.0\n",
        "        info = None\n",
        "        next_state = copy.copy(state)\n",
        "        next_act = 1\n",
        "        act = 1\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state, act, reward, info, next_state, done, mode)\n",
        "            state = next_state\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "            act = copy.copy(action)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "922aa15f-0c68-485d-8262-be90bcec8d7e"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'test'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_sarsa.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_sarsa.h5')\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:25.905474 FixedProfit: 1300075 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 2/100 RapTime: 0:00:25.462917 FixedProfit: 1040256 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 3/100 RapTime: 0:00:25.776892 FixedProfit: 978872 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 4/100 RapTime: 0:00:25.529822 FixedProfit: 1077868 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 5/100 RapTime: 0:00:25.806195 FixedProfit: 1040836 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 6/100 RapTime: 0:00:27.225016 FixedProfit: 1162482 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 7/100 RapTime: 0:00:27.791691 FixedProfit: 1128662 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 8/100 RapTime: 0:00:26.428140 FixedProfit: 1518906 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 9/100 RapTime: 0:00:25.479337 FixedProfit: 1429800 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 10/100 RapTime: 0:00:25.534038 FixedProfit: 1525677 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 11/100 RapTime: 0:00:25.593543 FixedProfit: 1502725 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 12/100 RapTime: 0:00:25.645813 FixedProfit: 1266816 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 13/100 RapTime: 0:00:25.534947 FixedProfit: 1372964 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 14/100 RapTime: 0:00:25.482007 FixedProfit: 1377816 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 15/100 RapTime: 0:00:25.392969 FixedProfit: 1057998 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 16/100 RapTime: 0:00:25.443003 FixedProfit: 1198341 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 17/100 RapTime: 0:00:25.507472 FixedProfit: 1068682 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 18/100 RapTime: 0:00:25.598311 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 19/100 RapTime: 0:00:25.356383 FixedProfit: 1229670 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 20/100 RapTime: 0:00:25.569519 FixedProfit: 1080053 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 21/100 RapTime: 0:00:25.560509 FixedProfit: 1024234 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 22/100 RapTime: 0:00:25.414173 FixedProfit: 1319868 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 23/100 RapTime: 0:00:25.750243 FixedProfit: 1086689 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 24/100 RapTime: 0:00:25.566874 FixedProfit: 1282897 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 25/100 RapTime: 0:00:25.326229 FixedProfit: 1249674 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 26/100 RapTime: 0:00:25.648591 FixedProfit: 1078954 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 27/100 RapTime: 0:00:25.431788 FixedProfit: 1044539 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 28/100 RapTime: 0:00:25.787964 FixedProfit: 1464077 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 29/100 RapTime: 0:00:25.689853 FixedProfit: 1070243 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 30/100 RapTime: 0:00:25.349162 FixedProfit: 1054349 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 31/100 RapTime: 0:00:25.463103 FixedProfit: 1106233 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 32/100 RapTime: 0:00:25.744101 FixedProfit: 1204867 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 33/100 RapTime: 0:00:25.788640 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 34/100 RapTime: 0:00:25.582320 FixedProfit: 1077790 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 35/100 RapTime: 0:00:25.605761 FixedProfit: 1138468 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 36/100 RapTime: 0:00:25.402613 FixedProfit: 1454577 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 37/100 RapTime: 0:00:25.436911 FixedProfit: 1123908 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 38/100 RapTime: 0:00:25.600945 FixedProfit: 1345309 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 39/100 RapTime: 0:00:25.574309 FixedProfit: 1053555 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 40/100 RapTime: 0:00:25.474471 FixedProfit: 1091261 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 41/100 RapTime: 0:00:25.467542 FixedProfit: 1465959 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 42/100 RapTime: 0:00:25.651079 FixedProfit: 1298739 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 43/100 RapTime: 0:00:25.618620 FixedProfit: 1409710 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 44/100 RapTime: 0:00:25.465108 FixedProfit: 1040649 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 45/100 RapTime: 0:00:25.348938 FixedProfit: 945338 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 46/100 RapTime: 0:00:25.513484 FixedProfit: 1521624 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 47/100 RapTime: 0:00:25.657928 FixedProfit: 1114866 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 48/100 RapTime: 0:00:25.606024 FixedProfit: 1399323 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 49/100 RapTime: 0:00:25.481706 FixedProfit: 1424522 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 50/100 RapTime: 0:00:25.586617 FixedProfit: 1249797 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 51/100 RapTime: 0:00:25.530228 FixedProfit: 1338079 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 52/100 RapTime: 0:00:25.632866 FixedProfit: 1309313 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 53/100 RapTime: 0:00:25.613086 FixedProfit: 958640 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 54/100 RapTime: 0:00:25.490656 FixedProfit: 1386829 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 55/100 RapTime: 0:00:25.703934 FixedProfit: 1410043 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 56/100 RapTime: 0:00:25.546677 FixedProfit: 1048619 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 57/100 RapTime: 0:00:25.426241 FixedProfit: 1075723 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 58/100 RapTime: 0:00:25.319419 FixedProfit: 1499608 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 59/100 RapTime: 0:00:25.420903 FixedProfit: 1327345 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 60/100 RapTime: 0:00:25.463255 FixedProfit: 1421776 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 61/100 RapTime: 0:00:25.562185 FixedProfit: 1193294 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 62/100 RapTime: 0:00:25.606591 FixedProfit: 1308443 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 63/100 RapTime: 0:00:25.379714 FixedProfit: 1206268 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 64/100 RapTime: 0:00:25.963560 FixedProfit: 1428333 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 65/100 RapTime: 0:00:25.469614 FixedProfit: 1611730 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 66/100 RapTime: 0:00:25.320391 FixedProfit: 1313536 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 67/100 RapTime: 0:00:25.667095 FixedProfit: 1444241 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 68/100 RapTime: 0:00:25.386097 FixedProfit: 1382796 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 69/100 RapTime: 0:00:25.464283 FixedProfit: 1157312 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 70/100 RapTime: 0:00:25.736943 FixedProfit: 1034429 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 71/100 RapTime: 0:00:25.588766 FixedProfit: 1478981 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 72/100 RapTime: 0:00:25.615495 FixedProfit: 1362553 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 73/100 RapTime: 0:00:25.382224 FixedProfit: 1027142 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 74/100 RapTime: 0:00:25.491869 FixedProfit: 1079875 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 75/100 RapTime: 0:00:25.525997 FixedProfit: 1012552 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 76/100 RapTime: 0:00:25.701213 FixedProfit: 1352873 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 77/100 RapTime: 0:00:25.528169 FixedProfit: 1460184 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 78/100 RapTime: 0:00:25.323105 FixedProfit: 1136745 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 79/100 RapTime: 0:00:25.365226 FixedProfit: 1803655 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 80/100 RapTime: 0:00:25.609852 FixedProfit: 1049385 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 81/100 RapTime: 0:00:25.587352 FixedProfit: 1229621 TradeTimes: 1 TradeWin: 0\n",
            "Episode: 82/100 RapTime: 0:00:25.486315 FixedProfit: 1013957 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 83/100 RapTime: 0:00:25.515752 FixedProfit: 1261330 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 84/100 RapTime: 0:00:25.556940 FixedProfit: 1422327 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 85/100 RapTime: 0:00:25.619869 FixedProfit: 1556451 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 86/100 RapTime: 0:00:25.731089 FixedProfit: 1000000 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 87/100 RapTime: 0:00:25.336373 FixedProfit: 1062409 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 88/100 RapTime: 0:00:25.297085 FixedProfit: 1463363 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 89/100 RapTime: 0:00:25.653730 FixedProfit: 1106143 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 90/100 RapTime: 0:00:25.653807 FixedProfit: 1085605 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 91/100 RapTime: 0:00:25.531179 FixedProfit: 1420480 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 92/100 RapTime: 0:00:25.552182 FixedProfit: 1173930 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 93/100 RapTime: 0:00:25.386206 FixedProfit: 1203414 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 94/100 RapTime: 0:00:25.544539 FixedProfit: 1514269 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 95/100 RapTime: 0:00:25.611228 FixedProfit: 1029232 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 96/100 RapTime: 0:00:25.528153 FixedProfit: 1448616 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 97/100 RapTime: 0:00:25.385064 FixedProfit: 1186066 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 98/100 RapTime: 0:00:25.255064 FixedProfit: 1374330 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 99/100 RapTime: 0:00:25.441917 FixedProfit: 1164471 TradeTimes: 0 TradeWin: 0\n",
            "Episode: 100/100 RapTime: 0:00:25.809202 FixedProfit: 1247217 TradeTimes: 1 TradeWin: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}