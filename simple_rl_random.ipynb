{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_rl_random.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWtfpzUgKxYHQsmQD+HRF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/simple_rl_random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "370ecac7-8cac-459d-9282-1888e1843151"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'data_csv_sp500.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=1000):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.stock_owned = None\n",
        "        self.current_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.current_step = 0\n",
        "        self.stock_owned = 0.0\n",
        "        self.current_price = self.df.loc[self.current_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        self.current_step += 1\n",
        "        self.current_price = self.df.loc[self.current_step, 'SP500']\n",
        " \n",
        "        # get current value before performing the action\n",
        "        prev_val = self._get_val()\n",
        "\n",
        "        # perform the trade\n",
        "        self._trade(action)\n",
        "\n",
        "        # get the new value after taking the action\n",
        "        cur_val = self._get_val()\n",
        "\n",
        "        # reward is the increase in porfolio value\n",
        "        reward = cur_val - prev_val\n",
        "\n",
        "        # done if we have run out of data\n",
        "        done = self.current_step == self.current_step - 1\n",
        "\n",
        "        # store the current value of the portfolio here\n",
        "        info = {'cur_val': cur_val}\n",
        "\n",
        "        # conform to the Gym API\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.stock_owned\n",
        "        state[1] = self.current_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_val(self):\n",
        "        return self.stock_owned * self.current_price + self.cash_in_hand\n",
        "\n",
        "\n",
        "    def _trade(self, action):\n",
        "        '''\n",
        "        0 = sell\n",
        "        1 = hold\n",
        "        2 = buy\n",
        "        売りたい株を売る\n",
        "        買いたい銘柄を買う\n",
        "        '''\n",
        "        if action == 0: # sell\n",
        "        # 注：問題を簡単にするために、売るときはその株のすべての株を売ることにします\n",
        "            self.cash_in_hand += self.current_price * self.stock_owned\n",
        "            self.stock_owned = 0\n",
        "        if action == 2: # buy\n",
        "        # 注：購入時には、買いたい銘柄をループさせて、現金がなくなるまで1株ずつ購入していきます。\n",
        "            can_buy = True\n",
        "            while can_buy:\n",
        "                if self.cash_in_hand > self.current_price:\n",
        "                    self.stock_owned += 1 # buy one share\n",
        "                    self.cash_in_hand -= self.current_price\n",
        "                else:\n",
        "                    can_buy = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_one_episode(env, train_episodes = 50):\n",
        "    average_net_worth = 0\n",
        "    for episode in range(train_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "\n",
        "        t0 = datetime.now()\n",
        "       \n",
        "        while not done:           \n",
        "\n",
        "            #乱数で1,2,3を出力\n",
        "            # action = agent.act(state)\n",
        "            action = np.random.randint(3, size=1)[0]\n",
        "            state, reward, done,info = env.step(action)\n",
        "\n",
        "            '''\n",
        "            next_state : [2420. 15.27 8.40000001] : [持っている株数 今の株価 手持ちのキャッシュ]\n",
        "            reward : 335.60999999999876\n",
        "            done : False\n",
        "            info: {'cur_val': 15667.53000000051}\n",
        "            '''\n",
        "            if env.current_step == env.end_step:\n",
        "                break\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f\"episode: {episode + 1}/{train_episodes}, episode end value: {info['cur_val']:.2f}, duration: {dt}\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "e6d002fa-5fc2-4580-bd89-ac2871800a39"
      },
      "source": [
        "env = Environment(df)\n",
        "play_one_episode(env, train_episodes = 10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 1/10, episode end value: 1912.98, duration: 0:00:00.061750\n",
            "episode: 2/10, episode end value: 25303.36, duration: 0:00:00.091314\n",
            "episode: 3/10, episode end value: 18786.04, duration: 0:00:00.078099\n",
            "episode: 4/10, episode end value: 19545.16, duration: 0:00:00.109647\n",
            "episode: 5/10, episode end value: 46137.36, duration: 0:00:00.115914\n",
            "episode: 6/10, episode end value: 85230.93, duration: 0:00:00.086801\n",
            "episode: 7/10, episode end value: 40469.03, duration: 0:00:00.110917\n",
            "episode: 8/10, episode end value: 8003.60, duration: 0:00:00.105462\n",
            "episode: 9/10, episode end value: 95164.75, duration: 0:00:00.151437\n",
            "episode: 10/10, episode end value: 87931.01, duration: 0:00:00.097773\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}