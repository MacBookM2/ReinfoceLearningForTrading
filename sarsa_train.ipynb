{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOWttcIP6ayVsctkrK2WYY6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/sarsa_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "f17f2a4b-d14e-4460-97d8-9a1aa74a9831"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'train'\n",
        "name = 'sarsa'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, next_act, done):\n",
        "        q = self.model.predict(state)  \n",
        "        target = np.copy(q)\n",
        "        if done:\n",
        "            target[:, action] = reward\n",
        "        else:\n",
        "            target[:, action] = reward + self.gamma*next_act\n",
        "        self.model.train_on_batch(state, target)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state, act, reward, info, next_state, done, mode = 'train'):\n",
        "\n",
        "        next_act = self._next_act(state)\n",
        "        if mode == 'train':\n",
        "            self.train(state, act, reward, next_state, next_act, done)\n",
        "\n",
        "        return next_act\n",
        "\n",
        "    def _next_act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "                self.scaler = pickle.load(f)\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "            reward = 0.0\n",
        "            info = None\n",
        "            next_state = copy.copy(state)\n",
        "            next_act = 1\n",
        "            act = 1\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state, act, reward, info, next_state, done, mode)\n",
        "                state = next_state\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "                act = copy.copy(action)\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save_scaler()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _save_scaler(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "a86d2c9d-5d1f-4247-cb61-95722aba5191"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:23.591026 FixedProfit: 1110915\n",
            "Episode: 2/100 RapTime: 0:00:22.954219 FixedProfit: 1125534\n",
            "Episode: 3/100 RapTime: 0:00:21.744621 FixedProfit: 1102302\n",
            "Episode: 4/100 RapTime: 0:00:21.977592 FixedProfit: 1016076\n",
            "Episode: 5/100 RapTime: 0:00:22.778496 FixedProfit: 1107737\n",
            "Episode: 6/100 RapTime: 0:00:21.614976 FixedProfit: 1202329\n",
            "Episode: 7/100 RapTime: 0:00:21.921079 FixedProfit: 946981\n",
            "Episode: 8/100 RapTime: 0:00:22.680960 FixedProfit: 1263165\n",
            "Episode: 9/100 RapTime: 0:00:21.616550 FixedProfit: 1220412\n",
            "Episode: 10/100 RapTime: 0:00:22.044823 FixedProfit: 1247509\n",
            "Episode: 11/100 RapTime: 0:00:23.004026 FixedProfit: 1257558\n",
            "Episode: 12/100 RapTime: 0:00:22.925990 FixedProfit: 1051503\n",
            "Episode: 13/100 RapTime: 0:00:21.845132 FixedProfit: 1130006\n",
            "Episode: 14/100 RapTime: 0:00:21.512024 FixedProfit: 1023279\n",
            "Episode: 15/100 RapTime: 0:00:22.805066 FixedProfit: 1220304\n",
            "Episode: 16/100 RapTime: 0:00:21.740573 FixedProfit: 1136237\n",
            "Episode: 17/100 RapTime: 0:00:21.322400 FixedProfit: 1153423\n",
            "Episode: 18/100 RapTime: 0:00:22.686020 FixedProfit: 1022677\n",
            "Episode: 19/100 RapTime: 0:00:21.959074 FixedProfit: 1145132\n",
            "Episode: 20/100 RapTime: 0:00:21.422526 FixedProfit: 1135649\n",
            "Episode: 21/100 RapTime: 0:00:22.855615 FixedProfit: 983908\n",
            "Episode: 22/100 RapTime: 0:00:23.479268 FixedProfit: 1113065\n",
            "Episode: 23/100 RapTime: 0:00:22.742779 FixedProfit: 1183552\n",
            "Episode: 24/100 RapTime: 0:00:24.152272 FixedProfit: 1213696\n",
            "Episode: 25/100 RapTime: 0:00:23.820432 FixedProfit: 1198341\n",
            "Episode: 26/100 RapTime: 0:00:23.262893 FixedProfit: 1138858\n",
            "Episode: 27/100 RapTime: 0:00:22.659638 FixedProfit: 1061585\n",
            "Episode: 28/100 RapTime: 0:00:23.479635 FixedProfit: 1040926\n",
            "Episode: 29/100 RapTime: 0:00:22.803737 FixedProfit: 1184075\n",
            "Episode: 30/100 RapTime: 0:00:22.617503 FixedProfit: 1143901\n",
            "Episode: 31/100 RapTime: 0:00:23.808836 FixedProfit: 1144939\n",
            "Episode: 32/100 RapTime: 0:00:22.007955 FixedProfit: 1082643\n",
            "Episode: 33/100 RapTime: 0:00:21.764381 FixedProfit: 1003981\n",
            "Episode: 34/100 RapTime: 0:00:23.418990 FixedProfit: 1060663\n",
            "Episode: 35/100 RapTime: 0:00:22.286876 FixedProfit: 1228042\n",
            "Episode: 36/100 RapTime: 0:00:22.611696 FixedProfit: 975910\n",
            "Episode: 37/100 RapTime: 0:00:23.048530 FixedProfit: 1407728\n",
            "Episode: 38/100 RapTime: 0:00:21.511727 FixedProfit: 1246858\n",
            "Episode: 39/100 RapTime: 0:00:21.673986 FixedProfit: 1031036\n",
            "Episode: 40/100 RapTime: 0:00:22.884500 FixedProfit: 1195687\n",
            "Episode: 41/100 RapTime: 0:00:22.562129 FixedProfit: 1170664\n",
            "Episode: 42/100 RapTime: 0:00:22.621524 FixedProfit: 1283957\n",
            "Episode: 43/100 RapTime: 0:00:22.187736 FixedProfit: 1080756\n",
            "Episode: 44/100 RapTime: 0:00:24.112219 FixedProfit: 1035835\n",
            "Episode: 45/100 RapTime: 0:00:23.240642 FixedProfit: 1230097\n",
            "Episode: 46/100 RapTime: 0:00:23.210686 FixedProfit: 1060538\n",
            "Episode: 47/100 RapTime: 0:00:23.726855 FixedProfit: 1035441\n",
            "Episode: 48/100 RapTime: 0:00:22.511612 FixedProfit: 1392970\n",
            "Episode: 49/100 RapTime: 0:00:22.998428 FixedProfit: 978704\n",
            "Episode: 50/100 RapTime: 0:00:23.126347 FixedProfit: 1162487\n",
            "Episode: 51/100 RapTime: 0:00:21.787597 FixedProfit: 1158694\n",
            "Episode: 52/100 RapTime: 0:00:21.642625 FixedProfit: 1088653\n",
            "Episode: 53/100 RapTime: 0:00:22.978542 FixedProfit: 1330085\n",
            "Episode: 54/100 RapTime: 0:00:22.390989 FixedProfit: 1108380\n",
            "Episode: 55/100 RapTime: 0:00:22.115991 FixedProfit: 1123391\n",
            "Episode: 56/100 RapTime: 0:00:21.230447 FixedProfit: 1061031\n",
            "Episode: 57/100 RapTime: 0:00:22.568705 FixedProfit: 926117\n",
            "Episode: 58/100 RapTime: 0:00:22.080043 FixedProfit: 1121907\n",
            "Episode: 59/100 RapTime: 0:00:21.369846 FixedProfit: 978938\n",
            "Episode: 60/100 RapTime: 0:00:22.070324 FixedProfit: 1159647\n",
            "Episode: 61/100 RapTime: 0:00:22.198318 FixedProfit: 997206\n",
            "Episode: 62/100 RapTime: 0:00:21.347885 FixedProfit: 1344745\n",
            "Episode: 63/100 RapTime: 0:00:22.212575 FixedProfit: 1132411\n",
            "Episode: 64/100 RapTime: 0:00:21.950599 FixedProfit: 1142995\n",
            "Episode: 65/100 RapTime: 0:00:21.173590 FixedProfit: 1219467\n",
            "Episode: 66/100 RapTime: 0:00:22.307721 FixedProfit: 1200364\n",
            "Episode: 67/100 RapTime: 0:00:22.326940 FixedProfit: 972487\n",
            "Episode: 68/100 RapTime: 0:00:21.329785 FixedProfit: 1106408\n",
            "Episode: 69/100 RapTime: 0:00:22.097510 FixedProfit: 1078704\n",
            "Episode: 70/100 RapTime: 0:00:22.523179 FixedProfit: 1181302\n",
            "Episode: 71/100 RapTime: 0:00:23.370560 FixedProfit: 836599\n",
            "Episode: 72/100 RapTime: 0:00:22.016845 FixedProfit: 1155064\n",
            "Episode: 73/100 RapTime: 0:00:21.846760 FixedProfit: 1197474\n",
            "Episode: 74/100 RapTime: 0:00:23.212400 FixedProfit: 950292\n",
            "Episode: 75/100 RapTime: 0:00:21.617226 FixedProfit: 1169548\n",
            "Episode: 76/100 RapTime: 0:00:22.161680 FixedProfit: 1173672\n",
            "Episode: 77/100 RapTime: 0:00:23.091691 FixedProfit: 1206857\n",
            "Episode: 78/100 RapTime: 0:00:21.844035 FixedProfit: 1139154\n",
            "Episode: 79/100 RapTime: 0:00:22.615403 FixedProfit: 1195791\n",
            "Episode: 80/100 RapTime: 0:00:24.351072 FixedProfit: 1070387\n",
            "Episode: 81/100 RapTime: 0:00:22.896843 FixedProfit: 1256561\n",
            "Episode: 82/100 RapTime: 0:00:22.106666 FixedProfit: 1213377\n",
            "Episode: 83/100 RapTime: 0:00:22.278456 FixedProfit: 1011279\n",
            "Episode: 84/100 RapTime: 0:00:22.586553 FixedProfit: 1076510\n",
            "Episode: 85/100 RapTime: 0:00:21.864359 FixedProfit: 1048677\n",
            "Episode: 86/100 RapTime: 0:00:21.540256 FixedProfit: 902586\n",
            "Episode: 87/100 RapTime: 0:00:22.543733 FixedProfit: 1258170\n",
            "Episode: 88/100 RapTime: 0:00:21.818440 FixedProfit: 1036709\n",
            "Episode: 89/100 RapTime: 0:00:21.305483 FixedProfit: 1029372\n",
            "Episode: 90/100 RapTime: 0:00:22.738983 FixedProfit: 990650\n",
            "Episode: 91/100 RapTime: 0:00:22.275778 FixedProfit: 1242387\n",
            "Episode: 92/100 RapTime: 0:00:22.008917 FixedProfit: 958680\n",
            "Episode: 93/100 RapTime: 0:00:23.855340 FixedProfit: 1147049\n",
            "Episode: 94/100 RapTime: 0:00:23.857458 FixedProfit: 1100812\n",
            "Episode: 95/100 RapTime: 0:00:22.149974 FixedProfit: 961163\n",
            "Episode: 96/100 RapTime: 0:00:22.827422 FixedProfit: 907349\n",
            "Episode: 97/100 RapTime: 0:00:21.322739 FixedProfit: 1127449\n",
            "Episode: 98/100 RapTime: 0:00:21.451646 FixedProfit: 1212273\n",
            "Episode: 99/100 RapTime: 0:00:22.996969 FixedProfit: 1206165\n",
            "Episode: 100/100 RapTime: 0:00:22.199948 FixedProfit: 878531\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}