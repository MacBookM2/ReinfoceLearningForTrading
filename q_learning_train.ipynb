{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMYluzjG74uC8vNsOg87XOG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "64eb441e-c368-4d9b-8991-dc62710fdc04"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_train.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'csv_data/qlearning_train.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        target = np.copy(q)\n",
        "        if done:\n",
        "            target[:, action] = reward\n",
        "        else:\n",
        "            target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, target)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = 'qlearning'\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "                self.scaler = pickle.load(f)\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.agent.train(state, action, reward, next_state, done)\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save_scaler()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _save_scaler(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(self.csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "8bce5b5e-2f62-4662-8d81-5bade42bd18c"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "mode = 'train'\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:41.721411 FixedProfit: 1135312\n",
            "Episode: 2/100 RapTime: 0:00:40.981686 FixedProfit: 1152026\n",
            "Episode: 3/100 RapTime: 0:00:41.755224 FixedProfit: 1152899\n",
            "Episode: 4/100 RapTime: 0:00:40.764130 FixedProfit: 1275777\n",
            "Episode: 5/100 RapTime: 0:00:42.466332 FixedProfit: 961312\n",
            "Episode: 6/100 RapTime: 0:00:41.285665 FixedProfit: 1150339\n",
            "Episode: 7/100 RapTime: 0:00:42.338901 FixedProfit: 1067278\n",
            "Episode: 8/100 RapTime: 0:00:40.715024 FixedProfit: 1161303\n",
            "Episode: 9/100 RapTime: 0:00:41.954306 FixedProfit: 980412\n",
            "Episode: 10/100 RapTime: 0:00:41.753464 FixedProfit: 1190882\n",
            "Episode: 11/100 RapTime: 0:00:40.664372 FixedProfit: 982966\n",
            "Episode: 12/100 RapTime: 0:00:42.432151 FixedProfit: 1077683\n",
            "Episode: 13/100 RapTime: 0:00:42.815717 FixedProfit: 1177837\n",
            "Episode: 14/100 RapTime: 0:00:43.397909 FixedProfit: 1128596\n",
            "Episode: 15/100 RapTime: 0:00:42.001937 FixedProfit: 1155379\n",
            "Episode: 16/100 RapTime: 0:00:42.117722 FixedProfit: 1047074\n",
            "Episode: 17/100 RapTime: 0:00:41.746213 FixedProfit: 1356749\n",
            "Episode: 18/100 RapTime: 0:00:40.918680 FixedProfit: 1107316\n",
            "Episode: 19/100 RapTime: 0:00:41.838289 FixedProfit: 1143133\n",
            "Episode: 20/100 RapTime: 0:00:41.469236 FixedProfit: 1231580\n",
            "Episode: 21/100 RapTime: 0:00:42.476555 FixedProfit: 1021023\n",
            "Episode: 22/100 RapTime: 0:00:40.769597 FixedProfit: 933878\n",
            "Episode: 23/100 RapTime: 0:00:42.082907 FixedProfit: 1087699\n",
            "Episode: 24/100 RapTime: 0:00:41.289637 FixedProfit: 1168854\n",
            "Episode: 25/100 RapTime: 0:00:40.871518 FixedProfit: 1023321\n",
            "Episode: 26/100 RapTime: 0:00:42.159061 FixedProfit: 892969\n",
            "Episode: 27/100 RapTime: 0:00:40.834294 FixedProfit: 1200216\n",
            "Episode: 28/100 RapTime: 0:00:42.590162 FixedProfit: 942989\n",
            "Episode: 29/100 RapTime: 0:00:40.787545 FixedProfit: 1080452\n",
            "Episode: 30/100 RapTime: 0:00:42.206854 FixedProfit: 931726\n",
            "Episode: 31/100 RapTime: 0:00:40.777368 FixedProfit: 922855\n",
            "Episode: 32/100 RapTime: 0:00:41.342511 FixedProfit: 1184655\n",
            "Episode: 33/100 RapTime: 0:00:41.864925 FixedProfit: 1080637\n",
            "Episode: 34/100 RapTime: 0:00:40.447283 FixedProfit: 1067786\n",
            "Episode: 35/100 RapTime: 0:00:42.494268 FixedProfit: 1026578\n",
            "Episode: 36/100 RapTime: 0:00:41.239802 FixedProfit: 1091142\n",
            "Episode: 37/100 RapTime: 0:00:41.885576 FixedProfit: 1062122\n",
            "Episode: 38/100 RapTime: 0:00:40.826297 FixedProfit: 1086043\n",
            "Episode: 39/100 RapTime: 0:00:41.733107 FixedProfit: 1006790\n",
            "Episode: 40/100 RapTime: 0:00:41.489273 FixedProfit: 1315251\n",
            "Episode: 41/100 RapTime: 0:00:40.741577 FixedProfit: 1227425\n",
            "Episode: 42/100 RapTime: 0:00:41.999123 FixedProfit: 1132251\n",
            "Episode: 43/100 RapTime: 0:00:40.882632 FixedProfit: 1110002\n",
            "Episode: 44/100 RapTime: 0:00:42.413061 FixedProfit: 1129129\n",
            "Episode: 45/100 RapTime: 0:00:41.154245 FixedProfit: 1174037\n",
            "Episode: 46/100 RapTime: 0:00:42.792329 FixedProfit: 1033660\n",
            "Episode: 47/100 RapTime: 0:00:42.574801 FixedProfit: 1021823\n",
            "Episode: 48/100 RapTime: 0:00:41.114259 FixedProfit: 1272174\n",
            "Episode: 49/100 RapTime: 0:00:41.982229 FixedProfit: 1133064\n",
            "Episode: 50/100 RapTime: 0:00:40.561594 FixedProfit: 1080001\n",
            "Episode: 51/100 RapTime: 0:00:43.072860 FixedProfit: 1120800\n",
            "Episode: 52/100 RapTime: 0:00:41.403227 FixedProfit: 1060538\n",
            "Episode: 53/100 RapTime: 0:00:42.333156 FixedProfit: 974613\n",
            "Episode: 54/100 RapTime: 0:00:41.073160 FixedProfit: 870109\n",
            "Episode: 55/100 RapTime: 0:00:41.544037 FixedProfit: 1047726\n",
            "Episode: 56/100 RapTime: 0:00:41.981693 FixedProfit: 1062571\n",
            "Episode: 57/100 RapTime: 0:00:40.489592 FixedProfit: 1203391\n",
            "Episode: 58/100 RapTime: 0:00:42.255722 FixedProfit: 1037285\n",
            "Episode: 59/100 RapTime: 0:00:41.709572 FixedProfit: 929288\n",
            "Episode: 60/100 RapTime: 0:00:42.521936 FixedProfit: 1067841\n",
            "Episode: 61/100 RapTime: 0:00:40.926471 FixedProfit: 1355831\n",
            "Episode: 62/100 RapTime: 0:00:41.893383 FixedProfit: 1173905\n",
            "Episode: 63/100 RapTime: 0:00:42.002080 FixedProfit: 1067476\n",
            "Episode: 64/100 RapTime: 0:00:41.129693 FixedProfit: 916867\n",
            "Episode: 65/100 RapTime: 0:00:42.336821 FixedProfit: 944712\n",
            "Episode: 66/100 RapTime: 0:00:41.952949 FixedProfit: 1052964\n",
            "Episode: 67/100 RapTime: 0:00:42.793343 FixedProfit: 1235554\n",
            "Episode: 68/100 RapTime: 0:00:41.060737 FixedProfit: 1019600\n",
            "Episode: 69/100 RapTime: 0:00:42.679167 FixedProfit: 1084878\n",
            "Episode: 70/100 RapTime: 0:00:41.519144 FixedProfit: 1204705\n",
            "Episode: 71/100 RapTime: 0:00:41.079575 FixedProfit: 987246\n",
            "Episode: 72/100 RapTime: 0:00:41.994694 FixedProfit: 1172983\n",
            "Episode: 73/100 RapTime: 0:00:41.804994 FixedProfit: 960275\n",
            "Episode: 74/100 RapTime: 0:00:41.440312 FixedProfit: 1026181\n",
            "Episode: 75/100 RapTime: 0:00:42.188961 FixedProfit: 1094036\n",
            "Episode: 76/100 RapTime: 0:00:42.034841 FixedProfit: 1301987\n",
            "Episode: 77/100 RapTime: 0:00:41.391421 FixedProfit: 1171038\n",
            "Episode: 78/100 RapTime: 0:00:41.791320 FixedProfit: 1118234\n",
            "Episode: 79/100 RapTime: 0:00:42.259342 FixedProfit: 1160679\n",
            "Episode: 80/100 RapTime: 0:00:41.046211 FixedProfit: 1292726\n",
            "Episode: 81/100 RapTime: 0:00:41.901050 FixedProfit: 1028339\n",
            "Episode: 82/100 RapTime: 0:00:42.362371 FixedProfit: 939554\n",
            "Episode: 83/100 RapTime: 0:00:42.150539 FixedProfit: 1172040\n",
            "Episode: 84/100 RapTime: 0:00:41.203518 FixedProfit: 1211976\n",
            "Episode: 85/100 RapTime: 0:00:41.720671 FixedProfit: 1225896\n",
            "Episode: 86/100 RapTime: 0:00:41.993006 FixedProfit: 1180079\n",
            "Episode: 87/100 RapTime: 0:00:40.816942 FixedProfit: 1387018\n",
            "Episode: 88/100 RapTime: 0:00:42.295562 FixedProfit: 1313130\n",
            "Episode: 89/100 RapTime: 0:00:41.945316 FixedProfit: 1207532\n",
            "Episode: 90/100 RapTime: 0:00:41.558362 FixedProfit: 1119246\n",
            "Episode: 91/100 RapTime: 0:00:42.359159 FixedProfit: 1164360\n",
            "Episode: 92/100 RapTime: 0:00:42.421289 FixedProfit: 1314382\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}