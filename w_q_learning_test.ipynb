{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w_q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNFnAiySk+USpovY7gmRYW+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/w_q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "eccc728a-e9ba-4552-f1dd-57a22dee2dee"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'test'\n",
        "name = 'w_qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "    \n",
        "        model_2 = Sequential()\n",
        "        model_2.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_mid))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_action))\n",
        "        model_2.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model_2.summary()))\n",
        "        self.model_2 = model_2\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done, s_flag):\n",
        "\n",
        "        next_act_values = self.model.predict(next_state,s_flag)\n",
        "        next_action =np.argmax(next_act_values[0])\n",
        "\n",
        "        if s_flag == 11:\n",
        "            q = self.model.predict(state)  \n",
        "            next_q = self.model_2.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model.train_on_batch(state, target)\n",
        "        else:\n",
        "            q = self.model_2.predict(state)  \n",
        "            next_q = self.model.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model_2.train_on_batch(state, target)\n",
        "\n",
        "\n",
        "    def predict(self, state, s_flag = 12):\n",
        "        values = None\n",
        "        q1 = self.model.predict(state)\n",
        "        q2 = self.model_2.predict(state)\n",
        "        if s_flag == 12:\n",
        "            values = np.array([q1[0,a] + q2[0,a] for a in range(2)])\n",
        "        elif s_flag == 11:\n",
        "            values = np.array([q1[0,a] + q1[0,a] for a in range(2)])\n",
        "        else:\n",
        "            values = np.array([q2[0,a] + q2[0,a] for a in range(2)])\n",
        "        return values\n",
        "\n",
        "    def load(self, name, name2):\n",
        "        self.model.load_weights(name)\n",
        "        self.model_2.load_weights(name2)\n",
        "\n",
        "    def save(self, name, name2):\n",
        "        self.model.save_weights(name)\n",
        "        self.model_2.save_weights(name2)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state,s_flag=12):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state,s_flag)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                s_flag = 12\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    rand = np.random.random()\n",
        "                    if rand <= 0.5:\n",
        "                        s_flag = 11\n",
        "                    else:\n",
        "                        s_flag = 22\n",
        "                    agent.train(state, action, reward, next_state, done, s_flag)\n",
        "                    \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "669e2e14-cb92-404f-eed7-d53b9e6d67e2"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:01:00.035139 FixedProfit: 1542126 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 2/100 RapTime: 0:00:57.937536 FixedProfit: 1523713 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 3/100 RapTime: 0:00:58.936857 FixedProfit: 1541597 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 4/100 RapTime: 0:00:58.016008 FixedProfit: 1533787 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 5/100 RapTime: 0:00:57.449795 FixedProfit: 1527707 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 6/100 RapTime: 0:00:58.728710 FixedProfit: 1561393 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 7/100 RapTime: 0:00:58.083192 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 8/100 RapTime: 0:00:59.128053 FixedProfit: 1548808 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 9/100 RapTime: 0:00:58.033126 FixedProfit: 1544772 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 10/100 RapTime: 0:00:57.761290 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 11/100 RapTime: 0:00:58.122897 FixedProfit: 1544197 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 12/100 RapTime: 0:00:59.063113 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 13/100 RapTime: 0:00:58.156366 FixedProfit: 1537850 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 14/100 RapTime: 0:00:57.539472 FixedProfit: 1560644 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 15/100 RapTime: 0:00:57.844495 FixedProfit: 1532027 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 16/100 RapTime: 0:00:58.156263 FixedProfit: 1516663 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 17/100 RapTime: 0:00:59.661511 FixedProfit: 1632701 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 18/100 RapTime: 0:00:58.053150 FixedProfit: 1598274 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 19/100 RapTime: 0:00:57.569454 FixedProfit: 1529187 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 20/100 RapTime: 0:00:58.102915 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 21/100 RapTime: 0:00:58.511104 FixedProfit: 1533997 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 22/100 RapTime: 0:00:58.607471 FixedProfit: 1532840 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 23/100 RapTime: 0:00:58.114155 FixedProfit: 1509077 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 24/100 RapTime: 0:00:57.937614 FixedProfit: 1511096 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 25/100 RapTime: 0:00:56.958466 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 26/100 RapTime: 0:00:58.673423 FixedProfit: 1541454 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 27/100 RapTime: 0:00:58.086245 FixedProfit: 1533231 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 28/100 RapTime: 0:00:56.554564 FixedProfit: 1572070 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 29/100 RapTime: 0:00:57.229416 FixedProfit: 1579621 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 30/100 RapTime: 0:00:56.695014 FixedProfit: 1591106 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 31/100 RapTime: 0:00:56.713247 FixedProfit: 1533205 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 32/100 RapTime: 0:00:56.484800 FixedProfit: 1533750 TradeTimes: 7 TradeWin: 7\n",
            "Episode: 33/100 RapTime: 0:00:55.424057 FixedProfit: 1510739 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 34/100 RapTime: 0:00:56.893392 FixedProfit: 1528169 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 35/100 RapTime: 0:00:56.735428 FixedProfit: 1542967 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 36/100 RapTime: 0:00:56.333514 FixedProfit: 1536623 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:00:57.950087 FixedProfit: 1562626 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 38/100 RapTime: 0:00:56.505857 FixedProfit: 1531024 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 39/100 RapTime: 0:00:56.938658 FixedProfit: 1567965 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 40/100 RapTime: 0:00:57.511643 FixedProfit: 1556134 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 41/100 RapTime: 0:00:57.144017 FixedProfit: 1571599 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 42/100 RapTime: 0:00:57.894577 FixedProfit: 1535148 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 43/100 RapTime: 0:00:57.838202 FixedProfit: 1529882 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 44/100 RapTime: 0:00:58.199009 FixedProfit: 1498714 TradeTimes: 6 TradeWin: 6\n",
            "Episode: 45/100 RapTime: 0:00:57.773805 FixedProfit: 1559124 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 46/100 RapTime: 0:00:55.618750 FixedProfit: 1526369 TradeTimes: 8 TradeWin: 6\n",
            "Episode: 47/100 RapTime: 0:00:56.950921 FixedProfit: 1549579 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 48/100 RapTime: 0:00:57.382526 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 49/100 RapTime: 0:00:59.452085 FixedProfit: 1566581 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 50/100 RapTime: 0:01:00.081644 FixedProfit: 1554472 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 51/100 RapTime: 0:00:59.073055 FixedProfit: 1506320 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 52/100 RapTime: 0:00:59.710397 FixedProfit: 1544867 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 53/100 RapTime: 0:00:56.766070 FixedProfit: 1570123 TradeTimes: 7 TradeWin: 7\n",
            "Episode: 54/100 RapTime: 0:00:57.382334 FixedProfit: 1537786 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 55/100 RapTime: 0:00:57.222521 FixedProfit: 1546914 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 56/100 RapTime: 0:00:56.169965 FixedProfit: 1545593 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 57/100 RapTime: 0:00:57.558592 FixedProfit: 1500246 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 58/100 RapTime: 0:00:56.682381 FixedProfit: 1518555 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 59/100 RapTime: 0:00:55.957785 FixedProfit: 1629504 TradeTimes: 7 TradeWin: 5\n",
            "Episode: 60/100 RapTime: 0:00:56.414008 FixedProfit: 1505795 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 61/100 RapTime: 0:00:55.889429 FixedProfit: 1555311 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 62/100 RapTime: 0:00:55.907676 FixedProfit: 1649795 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 63/100 RapTime: 0:00:57.630878 FixedProfit: 1549003 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 64/100 RapTime: 0:00:55.886095 FixedProfit: 1548504 TradeTimes: 7 TradeWin: 7\n",
            "Episode: 65/100 RapTime: 0:00:56.889544 FixedProfit: 1571843 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 66/100 RapTime: 0:00:56.977472 FixedProfit: 1536350 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 67/100 RapTime: 0:00:56.105992 FixedProfit: 1528952 TradeTimes: 7 TradeWin: 5\n",
            "Episode: 68/100 RapTime: 0:00:57.135310 FixedProfit: 1505920 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 69/100 RapTime: 0:00:56.486435 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 70/100 RapTime: 0:00:56.390516 FixedProfit: 1593465 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 71/100 RapTime: 0:00:56.571118 FixedProfit: 1571979 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 72/100 RapTime: 0:00:56.592123 FixedProfit: 1561363 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 73/100 RapTime: 0:00:57.175116 FixedProfit: 1564225 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 74/100 RapTime: 0:00:55.898655 FixedProfit: 1534822 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 75/100 RapTime: 0:00:56.784503 FixedProfit: 1540532 TradeTimes: 8 TradeWin: 6\n",
            "Episode: 76/100 RapTime: 0:00:57.023655 FixedProfit: 1538766 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 77/100 RapTime: 0:00:56.029507 FixedProfit: 1543161 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 78/100 RapTime: 0:00:55.776675 FixedProfit: 1569486 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 79/100 RapTime: 0:00:56.594445 FixedProfit: 1497189 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 80/100 RapTime: 0:00:58.017506 FixedProfit: 1540852 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 81/100 RapTime: 0:00:56.821388 FixedProfit: 1529934 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 82/100 RapTime: 0:00:55.713913 FixedProfit: 1548367 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 83/100 RapTime: 0:00:56.277216 FixedProfit: 1574156 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 84/100 RapTime: 0:00:57.837303 FixedProfit: 1516457 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 85/100 RapTime: 0:00:57.418818 FixedProfit: 1567469 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 86/100 RapTime: 0:00:56.863950 FixedProfit: 1518478 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 87/100 RapTime: 0:00:57.307008 FixedProfit: 1593316 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 88/100 RapTime: 0:00:56.685602 FixedProfit: 1635342 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 89/100 RapTime: 0:00:57.052489 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 90/100 RapTime: 0:00:57.191619 FixedProfit: 1546537 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 91/100 RapTime: 0:00:56.569635 FixedProfit: 1552086 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 92/100 RapTime: 0:00:57.210540 FixedProfit: 1570644 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 93/100 RapTime: 0:00:56.756319 FixedProfit: 1557484 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 94/100 RapTime: 0:00:56.531015 FixedProfit: 1529007 TradeTimes: 7 TradeWin: 7\n",
            "Episode: 95/100 RapTime: 0:00:56.062626 FixedProfit: 1752135 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 96/100 RapTime: 0:00:57.714490 FixedProfit: 1504765 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 97/100 RapTime: 0:00:58.401271 FixedProfit: 1536430 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 98/100 RapTime: 0:00:56.706299 FixedProfit: 1558796 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 99/100 RapTime: 0:00:56.806164 FixedProfit: 1527206 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 100/100 RapTime: 0:00:56.813211 FixedProfit: 1527599 TradeTimes: 4 TradeWin: 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}