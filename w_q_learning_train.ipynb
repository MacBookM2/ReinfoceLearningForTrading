{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w_q_learning_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOEmYEGros8SBplZSft0hsj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/w_q_learning_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "aa15cfd0-7496-4381-efe7-0a08046b9d51"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'train'\n",
        "name = 'w_qlearning'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "    \n",
        "        model_2 = Sequential()\n",
        "        model_2.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_mid))\n",
        "        model_2.add(ReLU()) \n",
        "        model_2.add(Dense(n_action))\n",
        "        model_2.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model_2.summary()))\n",
        "        self.model_2 = model_2\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done, s_flag):\n",
        "\n",
        "        next_act_values = self.model.predict(next_state,s_flag)\n",
        "        next_action =np.argmax(next_act_values[0])\n",
        "\n",
        "        if s_flag == 11:\n",
        "            q = self.model.predict(state)  \n",
        "            next_q = self.model_2.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model.train_on_batch(state, target)\n",
        "        else:\n",
        "            q = self.model_2.predict(state)  \n",
        "            next_q = self.model.predict(next_state)\n",
        "            target = np.copy(q)\n",
        "\n",
        "            if done:\n",
        "                target[:, action] = reward\n",
        "            else:\n",
        "                target[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "            self.model_2.train_on_batch(state, target)\n",
        "\n",
        "\n",
        "    def predict(self, state, s_flag = 12):\n",
        "        values = None\n",
        "        q1 = self.model.predict(state)\n",
        "        q2 = self.model_2.predict(state)\n",
        "        if s_flag == 12:\n",
        "            values = np.array([q1[0,a] + q2[0,a] for a in range(2)])\n",
        "        elif s_flag == 11:\n",
        "            values = np.array([q1[0,a] + q1[0,a] for a in range(2)])\n",
        "        else:\n",
        "            values = np.array([q2[0,a] + q2[0,a] for a in range(2)])\n",
        "        return values\n",
        "\n",
        "    def load(self, name, name2):\n",
        "        self.model.load_weights(name)\n",
        "        self.model_2.load_weights(name2)\n",
        "\n",
        "    def save(self, name, name2):\n",
        "        self.model.save_weights(name)\n",
        "        self.model_2.save_weights(name2)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state,s_flag=12):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state,s_flag)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                s_flag = 12\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    rand = np.random.random()\n",
        "                    if rand <= 0.5:\n",
        "                        s_flag = 11\n",
        "                    else:\n",
        "                        s_flag = 22\n",
        "                    agent.train(state, action, reward, next_state, done, s_flag)\n",
        "                    \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name), '{}/{}_2.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "b0e09cc8-0afd-43eb-da17-43b413cf4127"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:01:02.960384 FixedProfit: 1203055\n",
            "Episode: 2/100 RapTime: 0:01:00.983187 FixedProfit: 1013324\n",
            "Episode: 3/100 RapTime: 0:01:01.684943 FixedProfit: 1202678\n",
            "Episode: 4/100 RapTime: 0:01:00.447126 FixedProfit: 1142093\n",
            "Episode: 5/100 RapTime: 0:00:59.390828 FixedProfit: 963123\n",
            "Episode: 6/100 RapTime: 0:00:59.938549 FixedProfit: 1113696\n",
            "Episode: 7/100 RapTime: 0:01:00.583910 FixedProfit: 1169590\n",
            "Episode: 8/100 RapTime: 0:01:01.017889 FixedProfit: 1145155\n",
            "Episode: 9/100 RapTime: 0:00:59.679115 FixedProfit: 974656\n",
            "Episode: 10/100 RapTime: 0:00:59.538800 FixedProfit: 1067129\n",
            "Episode: 11/100 RapTime: 0:00:59.525177 FixedProfit: 993178\n",
            "Episode: 12/100 RapTime: 0:01:00.282370 FixedProfit: 1214715\n",
            "Episode: 13/100 RapTime: 0:00:59.784421 FixedProfit: 1316141\n",
            "Episode: 14/100 RapTime: 0:01:00.445201 FixedProfit: 914890\n",
            "Episode: 15/100 RapTime: 0:00:59.414321 FixedProfit: 1186329\n",
            "Episode: 16/100 RapTime: 0:00:59.229695 FixedProfit: 1080590\n",
            "Episode: 17/100 RapTime: 0:00:59.690092 FixedProfit: 1077314\n",
            "Episode: 18/100 RapTime: 0:00:59.408231 FixedProfit: 1027579\n",
            "Episode: 19/100 RapTime: 0:01:00.064990 FixedProfit: 979126\n",
            "Episode: 20/100 RapTime: 0:00:59.057328 FixedProfit: 1059318\n",
            "Episode: 21/100 RapTime: 0:00:59.020054 FixedProfit: 1097232\n",
            "Episode: 22/100 RapTime: 0:00:59.691106 FixedProfit: 1082201\n",
            "Episode: 23/100 RapTime: 0:00:59.263198 FixedProfit: 1053832\n",
            "Episode: 24/100 RapTime: 0:01:00.093404 FixedProfit: 1068172\n",
            "Episode: 25/100 RapTime: 0:00:58.832845 FixedProfit: 1081551\n",
            "Episode: 26/100 RapTime: 0:00:59.226036 FixedProfit: 1007397\n",
            "Episode: 27/100 RapTime: 0:00:59.511021 FixedProfit: 897757\n",
            "Episode: 28/100 RapTime: 0:00:59.418223 FixedProfit: 1251055\n",
            "Episode: 29/100 RapTime: 0:00:59.136761 FixedProfit: 1015775\n",
            "Episode: 30/100 RapTime: 0:00:59.560861 FixedProfit: 1137956\n",
            "Episode: 31/100 RapTime: 0:00:58.867309 FixedProfit: 1192210\n",
            "Episode: 32/100 RapTime: 0:00:59.542135 FixedProfit: 1013136\n",
            "Episode: 33/100 RapTime: 0:00:59.776878 FixedProfit: 1070579\n",
            "Episode: 34/100 RapTime: 0:00:59.650143 FixedProfit: 1056108\n",
            "Episode: 35/100 RapTime: 0:01:01.053666 FixedProfit: 1101980\n",
            "Episode: 36/100 RapTime: 0:00:58.964670 FixedProfit: 1215294\n",
            "Episode: 37/100 RapTime: 0:00:59.109469 FixedProfit: 1006828\n",
            "Episode: 38/100 RapTime: 0:00:59.682121 FixedProfit: 964583\n",
            "Episode: 39/100 RapTime: 0:00:59.203037 FixedProfit: 899014\n",
            "Episode: 40/100 RapTime: 0:00:59.369146 FixedProfit: 1252811\n",
            "Episode: 41/100 RapTime: 0:00:59.558568 FixedProfit: 1288443\n",
            "Episode: 42/100 RapTime: 0:00:59.486932 FixedProfit: 1139190\n",
            "Episode: 43/100 RapTime: 0:00:59.957320 FixedProfit: 1015642\n",
            "Episode: 44/100 RapTime: 0:00:59.377914 FixedProfit: 1061947\n",
            "Episode: 45/100 RapTime: 0:01:00.476742 FixedProfit: 1005092\n",
            "Episode: 46/100 RapTime: 0:01:00.131049 FixedProfit: 1461994\n",
            "Episode: 47/100 RapTime: 0:00:59.322724 FixedProfit: 1061150\n",
            "Episode: 48/100 RapTime: 0:00:59.667961 FixedProfit: 1014355\n",
            "Episode: 49/100 RapTime: 0:00:59.550565 FixedProfit: 1170160\n",
            "Episode: 50/100 RapTime: 0:00:59.747000 FixedProfit: 893205\n",
            "Episode: 51/100 RapTime: 0:00:59.650653 FixedProfit: 1313991\n",
            "Episode: 52/100 RapTime: 0:00:59.752808 FixedProfit: 904424\n",
            "Episode: 53/100 RapTime: 0:00:59.863185 FixedProfit: 1231796\n",
            "Episode: 54/100 RapTime: 0:00:59.553893 FixedProfit: 1093569\n",
            "Episode: 55/100 RapTime: 0:00:59.652396 FixedProfit: 1188841\n",
            "Episode: 56/100 RapTime: 0:00:59.773883 FixedProfit: 1317215\n",
            "Episode: 57/100 RapTime: 0:00:59.766057 FixedProfit: 1195338\n",
            "Episode: 58/100 RapTime: 0:01:01.601101 FixedProfit: 1210539\n",
            "Episode: 59/100 RapTime: 0:00:59.992984 FixedProfit: 1015966\n",
            "Episode: 60/100 RapTime: 0:00:59.840799 FixedProfit: 1045598\n",
            "Episode: 61/100 RapTime: 0:00:59.698921 FixedProfit: 1114246\n",
            "Episode: 62/100 RapTime: 0:00:59.677542 FixedProfit: 1008504\n",
            "Episode: 63/100 RapTime: 0:00:59.647383 FixedProfit: 1125178\n",
            "Episode: 64/100 RapTime: 0:00:59.824189 FixedProfit: 1276303\n",
            "Episode: 65/100 RapTime: 0:00:59.860275 FixedProfit: 1102323\n",
            "Episode: 66/100 RapTime: 0:00:59.705903 FixedProfit: 1088746\n",
            "Episode: 67/100 RapTime: 0:01:02.435477 FixedProfit: 1249569\n",
            "Episode: 68/100 RapTime: 0:01:00.877425 FixedProfit: 1283900\n",
            "Episode: 69/100 RapTime: 0:01:00.854519 FixedProfit: 1104084\n",
            "Episode: 70/100 RapTime: 0:01:00.404819 FixedProfit: 1244646\n",
            "Episode: 71/100 RapTime: 0:00:59.605539 FixedProfit: 961146\n",
            "Episode: 72/100 RapTime: 0:00:59.543892 FixedProfit: 971674\n",
            "Episode: 73/100 RapTime: 0:01:01.846058 FixedProfit: 1081822\n",
            "Episode: 74/100 RapTime: 0:01:01.668295 FixedProfit: 1387670\n",
            "Episode: 75/100 RapTime: 0:01:00.246397 FixedProfit: 1074637\n",
            "Episode: 76/100 RapTime: 0:01:00.425187 FixedProfit: 1061345\n",
            "Episode: 77/100 RapTime: 0:01:00.130124 FixedProfit: 933138\n",
            "Episode: 78/100 RapTime: 0:01:00.262858 FixedProfit: 1042613\n",
            "Episode: 79/100 RapTime: 0:01:00.717227 FixedProfit: 1039296\n",
            "Episode: 80/100 RapTime: 0:00:59.853178 FixedProfit: 998399\n",
            "Episode: 81/100 RapTime: 0:01:00.284313 FixedProfit: 1045879\n",
            "Episode: 82/100 RapTime: 0:01:00.358117 FixedProfit: 1040132\n",
            "Episode: 83/100 RapTime: 0:01:01.132061 FixedProfit: 997468\n",
            "Episode: 84/100 RapTime: 0:01:02.611727 FixedProfit: 968457\n",
            "Episode: 85/100 RapTime: 0:01:01.431082 FixedProfit: 1227705\n",
            "Episode: 86/100 RapTime: 0:01:00.658491 FixedProfit: 950987\n",
            "Episode: 87/100 RapTime: 0:01:00.738248 FixedProfit: 966369\n",
            "Episode: 88/100 RapTime: 0:01:00.555556 FixedProfit: 1030995\n",
            "Episode: 89/100 RapTime: 0:01:00.781031 FixedProfit: 1577145\n",
            "Episode: 90/100 RapTime: 0:01:01.596130 FixedProfit: 960365\n",
            "Episode: 91/100 RapTime: 0:01:00.388529 FixedProfit: 1152999\n",
            "Episode: 92/100 RapTime: 0:01:00.763648 FixedProfit: 1041686\n",
            "Episode: 93/100 RapTime: 0:01:00.197408 FixedProfit: 939707\n",
            "Episode: 94/100 RapTime: 0:01:00.416269 FixedProfit: 889149\n",
            "Episode: 95/100 RapTime: 0:01:02.111095 FixedProfit: 1198970\n",
            "Episode: 96/100 RapTime: 0:01:00.297239 FixedProfit: 1135585\n",
            "Episode: 97/100 RapTime: 0:01:00.140469 FixedProfit: 1213066\n",
            "Episode: 98/100 RapTime: 0:01:00.175879 FixedProfit: 1301068\n",
            "Episode: 99/100 RapTime: 0:01:00.342906 FixedProfit: 1122121\n",
            "Episode: 100/100 RapTime: 0:01:00.224071 FixedProfit: 1079355\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}