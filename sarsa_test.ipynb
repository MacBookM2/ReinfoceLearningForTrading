{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMOjPNNvKW7KYEGyL/Z78mB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/sarsa_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "6cc3803c-f4d8-4a8b-a9d7-ce9367fe9d35"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "mode = 'test'\n",
        "name = 'sarsa'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU())\n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, next_act, done):\n",
        "        q = self.model.predict(state)  \n",
        "        target = np.copy(q)\n",
        "        if done:\n",
        "            target[:, action] = reward\n",
        "        else:\n",
        "            target[:, action] = reward + self.gamma*next_act\n",
        "        self.model.train_on_batch(state, target)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state, act, reward, info, next_state, done, mode = 'train'):\n",
        "\n",
        "        next_act = self._next_act(state)\n",
        "        if mode == 'train':\n",
        "            self.train(state, act, reward, next_state, next_act, done)\n",
        "\n",
        "        return next_act\n",
        "\n",
        "    def _next_act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.mdl_dir = mdl_dir\n",
        "        self.scaler = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode = mode\n",
        "        self.name = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "                self.scaler = pickle.load(f)\n",
        "            self.agent.epsilon = 0.01\n",
        "            self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "        else:\n",
        "            self.df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done = False\n",
        "            start_time = datetime.now()\n",
        "            reward = 0.0\n",
        "            info = None\n",
        "            next_state = copy.copy(state)\n",
        "            next_act = 1\n",
        "            act = 1\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state, act, reward, info, next_state, done, mode)\n",
        "                state = next_state\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "                act = copy.copy(action)\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "            else:\n",
        "                record = pd.Series(info['cur_revenue'], index=self.df_rec.columns)\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, self.episodes_times, play_time, info['cur_revenue']))\n",
        "\n",
        "            state = next_state\n",
        "            self.df_rec = self.df_rec.append(record, ignore_index=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save_scaler()\n",
        "        self._save_csv()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _save_scaler(self):\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "\n",
        "    def _save_csv(self):\n",
        "        self.df_rec.to_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "41761ba5-6f0c-454c-db4d-0c77b5bad1a1"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "\n",
        "agent = Agent()\n",
        "env = Environment(df, initial_money, mode)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:26.349392 FixedProfit: 1540249 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 2/100 RapTime: 0:00:26.633897 FixedProfit: 1549127 TradeTimes: 16 TradeWin: 12\n",
            "Episode: 3/100 RapTime: 0:00:26.803928 FixedProfit: 1431381 TradeTimes: 30 TradeWin: 18\n",
            "Episode: 4/100 RapTime: 0:00:26.121774 FixedProfit: 1452317 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 5/100 RapTime: 0:00:27.404620 FixedProfit: 1564026 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 6/100 RapTime: 0:00:27.372615 FixedProfit: 1547641 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 7/100 RapTime: 0:00:26.950955 FixedProfit: 1437151 TradeTimes: 27 TradeWin: 15\n",
            "Episode: 8/100 RapTime: 0:00:26.652538 FixedProfit: 1515827 TradeTimes: 71 TradeWin: 42\n",
            "Episode: 9/100 RapTime: 0:00:27.109992 FixedProfit: 1567871 TradeTimes: 9 TradeWin: 5\n",
            "Episode: 10/100 RapTime: 0:00:26.214535 FixedProfit: 1840533 TradeTimes: 29 TradeWin: 18\n",
            "Episode: 11/100 RapTime: 0:00:27.351344 FixedProfit: 1484727 TradeTimes: 58 TradeWin: 32\n",
            "Episode: 12/100 RapTime: 0:00:26.693305 FixedProfit: 1586703 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 13/100 RapTime: 0:00:26.511754 FixedProfit: 1575009 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 14/100 RapTime: 0:00:27.182191 FixedProfit: 1489275 TradeTimes: 55 TradeWin: 31\n",
            "Episode: 15/100 RapTime: 0:00:26.061905 FixedProfit: 1571627 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 16/100 RapTime: 0:00:27.638130 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 17/100 RapTime: 0:00:27.523765 FixedProfit: 1513855 TradeTimes: 80 TradeWin: 42\n",
            "Episode: 18/100 RapTime: 0:00:26.898693 FixedProfit: 1534190 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 19/100 RapTime: 0:00:26.384685 FixedProfit: 1538919 TradeTimes: 10 TradeWin: 8\n",
            "Episode: 20/100 RapTime: 0:00:27.475068 FixedProfit: 2110261 TradeTimes: 52 TradeWin: 34\n",
            "Episode: 21/100 RapTime: 0:00:26.275309 FixedProfit: 1814266 TradeTimes: 22 TradeWin: 14\n",
            "Episode: 22/100 RapTime: 0:00:27.486710 FixedProfit: 1803804 TradeTimes: 27 TradeWin: 16\n",
            "Episode: 23/100 RapTime: 0:00:27.146527 FixedProfit: 1555094 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 24/100 RapTime: 0:00:26.373987 FixedProfit: 1498982 TradeTimes: 58 TradeWin: 31\n",
            "Episode: 25/100 RapTime: 0:00:27.399585 FixedProfit: 1655270 TradeTimes: 79 TradeWin: 50\n",
            "Episode: 26/100 RapTime: 0:00:26.020287 FixedProfit: 1804035 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 27/100 RapTime: 0:00:27.224765 FixedProfit: 1304317 TradeTimes: 60 TradeWin: 40\n",
            "Episode: 28/100 RapTime: 0:00:26.483911 FixedProfit: 1576202 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 29/100 RapTime: 0:00:26.928547 FixedProfit: 1410575 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 30/100 RapTime: 0:00:27.380648 FixedProfit: 1523050 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 31/100 RapTime: 0:00:28.429562 FixedProfit: 1541404 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 32/100 RapTime: 0:00:26.844110 FixedProfit: 1546156 TradeTimes: 9 TradeWin: 4\n",
            "Episode: 33/100 RapTime: 0:00:28.008724 FixedProfit: 1405682 TradeTimes: 11 TradeWin: 4\n",
            "Episode: 34/100 RapTime: 0:00:27.156940 FixedProfit: 1551971 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 35/100 RapTime: 0:00:26.850997 FixedProfit: 1548045 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 36/100 RapTime: 0:00:27.892608 FixedProfit: 1512438 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 37/100 RapTime: 0:00:26.660755 FixedProfit: 1494360 TradeTimes: 27 TradeWin: 15\n",
            "Episode: 38/100 RapTime: 0:00:28.175422 FixedProfit: 1567012 TradeTimes: 11 TradeWin: 8\n",
            "Episode: 39/100 RapTime: 0:00:26.735424 FixedProfit: 1583823 TradeTimes: 11 TradeWin: 9\n",
            "Episode: 40/100 RapTime: 0:00:26.839557 FixedProfit: 1571992 TradeTimes: 15 TradeWin: 10\n",
            "Episode: 41/100 RapTime: 0:00:27.760595 FixedProfit: 1417451 TradeTimes: 64 TradeWin: 35\n",
            "Episode: 42/100 RapTime: 0:00:27.633331 FixedProfit: 1551292 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 43/100 RapTime: 0:00:26.659052 FixedProfit: 1813005 TradeTimes: 57 TradeWin: 39\n",
            "Episode: 44/100 RapTime: 0:00:27.755999 FixedProfit: 1857210 TradeTimes: 22 TradeWin: 14\n",
            "Episode: 45/100 RapTime: 0:00:26.653732 FixedProfit: 1466434 TradeTimes: 40 TradeWin: 21\n",
            "Episode: 46/100 RapTime: 0:00:27.159472 FixedProfit: 1471021 TradeTimes: 24 TradeWin: 15\n",
            "Episode: 47/100 RapTime: 0:00:27.642299 FixedProfit: 1531471 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 48/100 RapTime: 0:00:26.305054 FixedProfit: 1821768 TradeTimes: 49 TradeWin: 33\n",
            "Episode: 49/100 RapTime: 0:00:28.087319 FixedProfit: 1562458 TradeTimes: 56 TradeWin: 34\n",
            "Episode: 50/100 RapTime: 0:00:26.494457 FixedProfit: 1515988 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 51/100 RapTime: 0:00:27.561574 FixedProfit: 1530244 TradeTimes: 11 TradeWin: 9\n",
            "Episode: 52/100 RapTime: 0:00:27.349564 FixedProfit: 1540336 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 53/100 RapTime: 0:00:26.615186 FixedProfit: 1451748 TradeTimes: 78 TradeWin: 49\n",
            "Episode: 54/100 RapTime: 0:00:27.696083 FixedProfit: 1539101 TradeTimes: 19 TradeWin: 14\n",
            "Episode: 55/100 RapTime: 0:00:27.941991 FixedProfit: 1504688 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 56/100 RapTime: 0:00:26.572379 FixedProfit: 1435397 TradeTimes: 32 TradeWin: 20\n",
            "Episode: 57/100 RapTime: 0:00:27.300398 FixedProfit: 1507445 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 58/100 RapTime: 0:00:27.359396 FixedProfit: 1552401 TradeTimes: 7 TradeWin: 5\n",
            "Episode: 59/100 RapTime: 0:00:26.645507 FixedProfit: 1538857 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 60/100 RapTime: 0:00:27.654131 FixedProfit: 1356343 TradeTimes: 40 TradeWin: 26\n",
            "Episode: 61/100 RapTime: 0:00:26.429299 FixedProfit: 1859572 TradeTimes: 12 TradeWin: 8\n",
            "Episode: 62/100 RapTime: 0:00:27.761639 FixedProfit: 1541807 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 63/100 RapTime: 0:00:27.148978 FixedProfit: 1694087 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 64/100 RapTime: 0:00:26.840504 FixedProfit: 1537299 TradeTimes: 18 TradeWin: 11\n",
            "Episode: 65/100 RapTime: 0:00:27.824369 FixedProfit: 1566783 TradeTimes: 7 TradeWin: 4\n",
            "Episode: 66/100 RapTime: 0:00:27.958534 FixedProfit: 1492549 TradeTimes: 17 TradeWin: 10\n",
            "Episode: 67/100 RapTime: 0:00:26.667694 FixedProfit: 1572306 TradeTimes: 22 TradeWin: 12\n",
            "Episode: 68/100 RapTime: 0:00:27.447505 FixedProfit: 1538806 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 69/100 RapTime: 0:00:27.320014 FixedProfit: 1541272 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 70/100 RapTime: 0:00:26.720165 FixedProfit: 1553010 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 71/100 RapTime: 0:00:27.862050 FixedProfit: 1638660 TradeTimes: 26 TradeWin: 15\n",
            "Episode: 72/100 RapTime: 0:00:26.711877 FixedProfit: 1574982 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 73/100 RapTime: 0:00:27.897205 FixedProfit: 1582660 TradeTimes: 40 TradeWin: 24\n",
            "Episode: 74/100 RapTime: 0:00:27.248136 FixedProfit: 1407560 TradeTimes: 50 TradeWin: 34\n",
            "Episode: 75/100 RapTime: 0:00:26.946448 FixedProfit: 1541511 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 76/100 RapTime: 0:00:27.679898 FixedProfit: 1457599 TradeTimes: 35 TradeWin: 20\n",
            "Episode: 77/100 RapTime: 0:00:26.435093 FixedProfit: 1520129 TradeTimes: 19 TradeWin: 13\n",
            "Episode: 78/100 RapTime: 0:00:27.931828 FixedProfit: 1549963 TradeTimes: 10 TradeWin: 4\n",
            "Episode: 79/100 RapTime: 0:00:27.721387 FixedProfit: 1444757 TradeTimes: 67 TradeWin: 39\n",
            "Episode: 80/100 RapTime: 0:00:27.235217 FixedProfit: 1578325 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 81/100 RapTime: 0:00:26.695729 FixedProfit: 1519251 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 82/100 RapTime: 0:00:27.899429 FixedProfit: 1347485 TradeTimes: 26 TradeWin: 21\n",
            "Episode: 83/100 RapTime: 0:00:26.521323 FixedProfit: 1507368 TradeTimes: 16 TradeWin: 12\n",
            "Episode: 84/100 RapTime: 0:00:27.953522 FixedProfit: 1442973 TradeTimes: 49 TradeWin: 29\n",
            "Episode: 85/100 RapTime: 0:00:27.071345 FixedProfit: 1637867 TradeTimes: 28 TradeWin: 14\n",
            "Episode: 86/100 RapTime: 0:00:27.046060 FixedProfit: 1798548 TradeTimes: 46 TradeWin: 31\n",
            "Episode: 87/100 RapTime: 0:00:27.786659 FixedProfit: 1549889 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 88/100 RapTime: 0:00:26.576114 FixedProfit: 1498752 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 89/100 RapTime: 0:00:28.230386 FixedProfit: 1803163 TradeTimes: 32 TradeWin: 21\n",
            "Episode: 90/100 RapTime: 0:00:27.971495 FixedProfit: 1537497 TradeTimes: 8 TradeWin: 6\n",
            "Episode: 91/100 RapTime: 0:00:26.614044 FixedProfit: 1417640 TradeTimes: 89 TradeWin: 55\n",
            "Episode: 92/100 RapTime: 0:00:27.322747 FixedProfit: 1548039 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 93/100 RapTime: 0:00:27.698720 FixedProfit: 1465374 TradeTimes: 66 TradeWin: 35\n",
            "Episode: 94/100 RapTime: 0:00:26.516381 FixedProfit: 1622515 TradeTimes: 41 TradeWin: 26\n",
            "Episode: 95/100 RapTime: 0:00:28.426598 FixedProfit: 1859454 TradeTimes: 10 TradeWin: 5\n",
            "Episode: 96/100 RapTime: 0:00:26.712840 FixedProfit: 1530357 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 97/100 RapTime: 0:00:27.427317 FixedProfit: 1674145 TradeTimes: 7 TradeWin: 6\n",
            "Episode: 98/100 RapTime: 0:00:27.402147 FixedProfit: 1543971 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 99/100 RapTime: 0:00:26.581402 FixedProfit: 1821903 TradeTimes: 54 TradeWin: 37\n",
            "Episode: 100/100 RapTime: 0:00:28.530548 FixedProfit: 1549016 TradeTimes: 5 TradeWin: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}