{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOthzxToZmmYo5DLfxvaVcO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/sarsa_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "fc264a83-4718-4252-d002-1d0a11f59b3d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_train.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'sarsa_train.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        prev_revenue = self._get_revenue()\n",
        "\n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self):\n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "        else:\n",
        "            if self.action_space[0] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1 \n",
        "            if self.action_space[2] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, next_act, done):\n",
        "        q = self.model.predict(state)\n",
        "        #next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*next_act\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state, act, reward, info, next_state, done, mode = 'train'):\n",
        "\n",
        "        next_act = self._next_act(state)\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.brain.train(state, act, reward, next_state, next_act, done)\n",
        "\n",
        "        return next_act\n",
        "\n",
        "    def _next_act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "        reward = 0.0\n",
        "        info = None\n",
        "        next_state = copy.copy(state)\n",
        "        next_act = 1\n",
        "        act = 1\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state, act, reward, info, next_state, done, mode)\n",
        "            state = next_state\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "            act = copy.copy(action)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "b674a718-e867-4270-d595-348d2df405c2"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'train'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_sarsa.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_sarsa.h5')\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:21.758643 FixedProfit: 1009159\n",
            "Episode: 2/100 RapTime: 0:00:21.743126 FixedProfit: 1163278\n",
            "Episode: 3/100 RapTime: 0:00:21.177841 FixedProfit: 1375870\n",
            "Episode: 4/100 RapTime: 0:00:21.161135 FixedProfit: 1065527\n",
            "Episode: 5/100 RapTime: 0:00:21.277177 FixedProfit: 1177415\n",
            "Episode: 6/100 RapTime: 0:00:21.253974 FixedProfit: 1103499\n",
            "Episode: 7/100 RapTime: 0:00:21.419158 FixedProfit: 1166780\n",
            "Episode: 8/100 RapTime: 0:00:21.283598 FixedProfit: 1225454\n",
            "Episode: 9/100 RapTime: 0:00:21.350784 FixedProfit: 1039907\n",
            "Episode: 10/100 RapTime: 0:00:21.387941 FixedProfit: 1029734\n",
            "Episode: 11/100 RapTime: 0:00:21.170743 FixedProfit: 1120432\n",
            "Episode: 12/100 RapTime: 0:00:21.235840 FixedProfit: 1057378\n",
            "Episode: 13/100 RapTime: 0:00:21.332904 FixedProfit: 971922\n",
            "Episode: 14/100 RapTime: 0:00:21.172918 FixedProfit: 962246\n",
            "Episode: 15/100 RapTime: 0:00:21.445450 FixedProfit: 1012804\n",
            "Episode: 16/100 RapTime: 0:00:21.251504 FixedProfit: 1043576\n",
            "Episode: 17/100 RapTime: 0:00:21.389678 FixedProfit: 1323860\n",
            "Episode: 18/100 RapTime: 0:00:21.192987 FixedProfit: 1088523\n",
            "Episode: 19/100 RapTime: 0:00:21.501971 FixedProfit: 1030072\n",
            "Episode: 20/100 RapTime: 0:00:21.340899 FixedProfit: 1135155\n",
            "Episode: 21/100 RapTime: 0:00:21.438536 FixedProfit: 1104475\n",
            "Episode: 22/100 RapTime: 0:00:21.267626 FixedProfit: 1157887\n",
            "Episode: 23/100 RapTime: 0:00:21.494329 FixedProfit: 1128583\n",
            "Episode: 24/100 RapTime: 0:00:21.263853 FixedProfit: 917151\n",
            "Episode: 25/100 RapTime: 0:00:21.249725 FixedProfit: 1229401\n",
            "Episode: 26/100 RapTime: 0:00:21.221249 FixedProfit: 1193733\n",
            "Episode: 27/100 RapTime: 0:00:21.384441 FixedProfit: 907045\n",
            "Episode: 28/100 RapTime: 0:00:21.332296 FixedProfit: 1021076\n",
            "Episode: 29/100 RapTime: 0:00:21.340333 FixedProfit: 1220630\n",
            "Episode: 30/100 RapTime: 0:00:21.225997 FixedProfit: 1082904\n",
            "Episode: 31/100 RapTime: 0:00:21.363579 FixedProfit: 1109065\n",
            "Episode: 32/100 RapTime: 0:00:21.373746 FixedProfit: 1063699\n",
            "Episode: 33/100 RapTime: 0:00:21.241599 FixedProfit: 951400\n",
            "Episode: 34/100 RapTime: 0:00:21.178351 FixedProfit: 946094\n",
            "Episode: 35/100 RapTime: 0:00:21.412675 FixedProfit: 1156906\n",
            "Episode: 36/100 RapTime: 0:00:21.384152 FixedProfit: 1248558\n",
            "Episode: 37/100 RapTime: 0:00:21.291962 FixedProfit: 1223138\n",
            "Episode: 38/100 RapTime: 0:00:21.338276 FixedProfit: 1019243\n",
            "Episode: 39/100 RapTime: 0:00:21.093301 FixedProfit: 1528436\n",
            "Episode: 40/100 RapTime: 0:00:21.434645 FixedProfit: 996565\n",
            "Episode: 41/100 RapTime: 0:00:21.248011 FixedProfit: 1017733\n",
            "Episode: 42/100 RapTime: 0:00:21.253623 FixedProfit: 1010316\n",
            "Episode: 43/100 RapTime: 0:00:21.246198 FixedProfit: 1110499\n",
            "Episode: 44/100 RapTime: 0:00:21.440565 FixedProfit: 1269502\n",
            "Episode: 45/100 RapTime: 0:00:21.187097 FixedProfit: 1214723\n",
            "Episode: 46/100 RapTime: 0:00:21.316534 FixedProfit: 1092987\n",
            "Episode: 47/100 RapTime: 0:00:21.477816 FixedProfit: 1003740\n",
            "Episode: 48/100 RapTime: 0:00:21.484017 FixedProfit: 1039375\n",
            "Episode: 49/100 RapTime: 0:00:21.189230 FixedProfit: 1254468\n",
            "Episode: 50/100 RapTime: 0:00:21.252524 FixedProfit: 1125091\n",
            "Episode: 51/100 RapTime: 0:00:21.274462 FixedProfit: 1142704\n",
            "Episode: 52/100 RapTime: 0:00:21.425441 FixedProfit: 1073115\n",
            "Episode: 53/100 RapTime: 0:00:21.177617 FixedProfit: 1278401\n",
            "Episode: 54/100 RapTime: 0:00:21.119628 FixedProfit: 916181\n",
            "Episode: 55/100 RapTime: 0:00:21.430892 FixedProfit: 950320\n",
            "Episode: 56/100 RapTime: 0:00:21.128582 FixedProfit: 1049289\n",
            "Episode: 57/100 RapTime: 0:00:21.442438 FixedProfit: 939810\n",
            "Episode: 58/100 RapTime: 0:00:21.263559 FixedProfit: 912618\n",
            "Episode: 59/100 RapTime: 0:00:21.298835 FixedProfit: 1090241\n",
            "Episode: 60/100 RapTime: 0:00:21.200183 FixedProfit: 1321638\n",
            "Episode: 61/100 RapTime: 0:00:21.380687 FixedProfit: 972939\n",
            "Episode: 62/100 RapTime: 0:00:21.208924 FixedProfit: 1226702\n",
            "Episode: 63/100 RapTime: 0:00:21.205913 FixedProfit: 1134430\n",
            "Episode: 64/100 RapTime: 0:00:21.192700 FixedProfit: 1296016\n",
            "Episode: 65/100 RapTime: 0:00:21.824376 FixedProfit: 1087648\n",
            "Episode: 66/100 RapTime: 0:00:22.129574 FixedProfit: 1063186\n",
            "Episode: 67/100 RapTime: 0:00:22.136131 FixedProfit: 1274682\n",
            "Episode: 68/100 RapTime: 0:00:22.199141 FixedProfit: 1279505\n",
            "Episode: 69/100 RapTime: 0:00:22.506553 FixedProfit: 974271\n",
            "Episode: 70/100 RapTime: 0:00:22.342523 FixedProfit: 1093430\n",
            "Episode: 71/100 RapTime: 0:00:21.740926 FixedProfit: 951173\n",
            "Episode: 72/100 RapTime: 0:00:22.406646 FixedProfit: 1196870\n",
            "Episode: 73/100 RapTime: 0:00:23.767178 FixedProfit: 1119663\n",
            "Episode: 74/100 RapTime: 0:00:24.632533 FixedProfit: 1202814\n",
            "Episode: 75/100 RapTime: 0:00:23.603281 FixedProfit: 1046979\n",
            "Episode: 76/100 RapTime: 0:00:23.806083 FixedProfit: 1039641\n",
            "Episode: 77/100 RapTime: 0:00:23.593754 FixedProfit: 901864\n",
            "Episode: 78/100 RapTime: 0:00:22.788196 FixedProfit: 1205460\n",
            "Episode: 79/100 RapTime: 0:00:21.287123 FixedProfit: 1039576\n",
            "Episode: 80/100 RapTime: 0:00:21.914393 FixedProfit: 1228152\n",
            "Episode: 81/100 RapTime: 0:00:22.594619 FixedProfit: 1133032\n",
            "Episode: 82/100 RapTime: 0:00:24.553579 FixedProfit: 1212280\n",
            "Episode: 83/100 RapTime: 0:00:24.072600 FixedProfit: 1278817\n",
            "Episode: 84/100 RapTime: 0:00:22.327415 FixedProfit: 1289346\n",
            "Episode: 85/100 RapTime: 0:00:21.864396 FixedProfit: 1100356\n",
            "Episode: 86/100 RapTime: 0:00:21.817468 FixedProfit: 1143984\n",
            "Episode: 87/100 RapTime: 0:00:21.602716 FixedProfit: 1265914\n",
            "Episode: 88/100 RapTime: 0:00:21.470356 FixedProfit: 1067067\n",
            "Episode: 89/100 RapTime: 0:00:21.544056 FixedProfit: 1159256\n",
            "Episode: 90/100 RapTime: 0:00:22.002813 FixedProfit: 1150770\n",
            "Episode: 91/100 RapTime: 0:00:21.721789 FixedProfit: 1183894\n",
            "Episode: 92/100 RapTime: 0:00:21.427615 FixedProfit: 1048309\n",
            "Episode: 93/100 RapTime: 0:00:21.608577 FixedProfit: 1052806\n",
            "Episode: 94/100 RapTime: 0:00:21.779532 FixedProfit: 972749\n",
            "Episode: 95/100 RapTime: 0:00:21.662070 FixedProfit: 1115675\n",
            "Episode: 96/100 RapTime: 0:00:21.315669 FixedProfit: 1027978\n",
            "Episode: 97/100 RapTime: 0:00:21.316974 FixedProfit: 892851\n",
            "Episode: 98/100 RapTime: 0:00:21.323600 FixedProfit: 1084014\n",
            "Episode: 99/100 RapTime: 0:00:21.707978 FixedProfit: 1168131\n",
            "Episode: 100/100 RapTime: 0:00:21.465944 FixedProfit: 1013970\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}