{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drqn_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNPRLD4OUrTwlj29lsCC6gn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/drqn_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "73446def-778f-4cb4-8b7e-79f0c3ae4d23"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU, LSTM, Activation, Input, MaxPool1D, Conv1D\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "mode = 'train'\n",
        "name = 'drqn'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evsq8JqfWNoj"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "\n",
        "        self.cntr = 0\n",
        "        self.size = 0\n",
        "        self.max_size = max_size\n",
        "        self.batch_size = batch_size\n",
        "        self.states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.next_states_memory = np.zeros([self.max_size, 3], dtype=np.float32)\n",
        "        self.acts_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "        self.rewards_memory = np.zeros(self.max_size, dtype=np.float32)\n",
        "        self.done_memory = np.zeros(self.max_size, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        self.states_memory[self.cntr] = state\n",
        "        self.next_states_memory[self.cntr] = next_state\n",
        "        self.acts_memory[self.cntr] = act\n",
        "        self.rewards_memory[self.cntr] = reward\n",
        "        self.done_memory[self.cntr] = done\n",
        "        self.cntr = (self.cntr+1) % self.max_size\n",
        "        self.size = min(self.size+1, self.max_size)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        dice = np.arange(10, self.size)\n",
        "        mb_index = np.random.choice(dice, self.batch_size, replace=False)\n",
        "        mb_index_min = mb_index - 10\n",
        "\n",
        "        states_3d = np.empty((0, 10, 3))\n",
        "        next_states_3d = np.empty((0, 10, 3))\n",
        "        for a,b in zip(mb_index, mb_index_min):\n",
        "            states_tmp = self.states_memory[b:a]\n",
        "            next_states_tmp = self.next_states_memory[b:a]\n",
        "\n",
        "            states_tmp  = np.reshape(states_tmp, (1, 10, 3))\n",
        "            next_states_tmp  = np.reshape(next_states_tmp, (1, 10, 3))\n",
        "\n",
        "            states_3d = np.append(states_3d, states_tmp,axis=0)\n",
        "            next_states_3d = np.append(next_states_3d, next_states_tmp,axis=0)\n",
        "\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [states_3d ,next_states_3d, self.acts_memory[mb_index], self.rewards_memory[mb_index], self.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "        return dict1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self):\n",
        "\n",
        "        conv_filter = 12\n",
        "        units = 16\n",
        "        look_back = 10\n",
        "        opt = Adam(learning_rate=0.001)\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=conv_filter, kernel_size=1, padding=\"same\", activation=\"tanh\",batch_input_shape=(None, look_back, 3)))\n",
        "        model.add(MaxPool1D(pool_size=1, padding='same'))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(LSTM(units))\n",
        "        model.add(Dense(3, kernel_initializer='random_uniform'))\n",
        "        model.compile(loss = \"mean_absolute_error\", optimizer=opt)\n",
        "        model.summary()\n",
        "        self.model = model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent(Brain, ReplayMemory):\n",
        "    def __init__(self, max_size=500, batch_size=32):\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "        self.batch_size = batch_size\n",
        "        self.local_state = np.empty((0,3), float)\n",
        "        Brain.__init__(self)\n",
        "        ReplayMemory.__init__(self, max_size, batch_size)\n",
        "\n",
        "    def reset(self):\n",
        "        self.local_state = np.empty((0,3), float)\n",
        "\n",
        "    def update_replay_memory(self, state, action, reward, next_state, done):\n",
        "        self.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "    def act(self, state):\n",
        "        if len(self.local_state) >= 10:\n",
        "            self.local_state = self.local_state[1:]\n",
        "            self.local_state = np.append(self.local_state, np.array(state), axis=0)\n",
        "            tmp_state = copy.deepcopy(self.local_state)\n",
        "            tmp_state  = np.reshape(tmp_state, (1, 10, 3))\n",
        "\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                return np.random.choice(3)\n",
        "            act_values = self.model.predict(tmp_state)\n",
        "            return np.argmax(act_values[0])\n",
        "        else:\n",
        "            self.local_state = np.append(self.local_state, np.array(state), axis=0)\n",
        "            return np.random.choice(3)\n",
        "\n",
        "    def replay(self):\n",
        "        if self.size < (self.batch_size + 11):\n",
        "            return\n",
        "\n",
        "        m_batch = self.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.model.predict(next_states), axis=1)\n",
        "        d = self.model.predict(next_states)\n",
        "        c = np.amax(self.model.predict(next_states), axis=1)\n",
        "        target_full = self.model.predict(states)\n",
        "\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.model.train_on_batch(states, target_full)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, agent, mdl_dir, name, episodes_times = 200, mode = 'test'):\n",
        "        self.env            = env\n",
        "        self.agent          = agent\n",
        "        self.mdl_dir        = mdl_dir\n",
        "        self.scaler         = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode           = mode\n",
        "        self.name           = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.agent.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done  = False\n",
        "            start_time = datetime.now()\n",
        "            self.agent.reset()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.agent.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.agent.update_replay_memory(state, action, reward, next_state, done)\n",
        "                    self.agent.replay()                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if self.mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.agent.load('{}/{}.h5'.format(self.mdl_dir, self.name))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        with open('{}/{}.pkl'.format(self.mdl_dir, self.name), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "        self.agent.save('{}/{}.h5'.format(self.mdl_dir, self.name))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "1fa5da47-fb7c-443f-fc8e-ec84414cd027"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 200\n",
        "batch_size = 32\n",
        "max_size = 500\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "agent = Agent(max_size, batch_size)\n",
        "main = Main(env, agent, mdl_dir, name, episodes_times, mode)\n",
        "main.play_game()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 10, 12)            48        \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 10, 12)            0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10, 12)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 16)                1856      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 1,955\n",
            "Trainable params: 1,955\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Episode: 1/200 RapTime: 0:01:37.181980 FixedProfit: 1159170\n",
            "Episode: 2/200 RapTime: 0:01:31.456100 FixedProfit: 1061815\n",
            "Episode: 3/200 RapTime: 0:01:30.941900 FixedProfit: 1029752\n",
            "Episode: 4/200 RapTime: 0:01:31.285713 FixedProfit: 1066745\n",
            "Episode: 5/200 RapTime: 0:01:31.482540 FixedProfit: 1053869\n",
            "Episode: 6/200 RapTime: 0:01:31.140674 FixedProfit: 977116\n",
            "Episode: 7/200 RapTime: 0:01:31.159519 FixedProfit: 988175\n",
            "Episode: 8/200 RapTime: 0:01:31.291278 FixedProfit: 1107246\n",
            "Episode: 9/200 RapTime: 0:01:30.872215 FixedProfit: 917737\n",
            "Episode: 10/200 RapTime: 0:01:31.504782 FixedProfit: 975292\n",
            "Episode: 11/200 RapTime: 0:01:31.574632 FixedProfit: 965642\n",
            "Episode: 12/200 RapTime: 0:01:31.933850 FixedProfit: 989414\n",
            "Episode: 13/200 RapTime: 0:01:32.293716 FixedProfit: 1017071\n",
            "Episode: 14/200 RapTime: 0:01:32.095687 FixedProfit: 1201396\n",
            "Episode: 15/200 RapTime: 0:01:33.393045 FixedProfit: 1193527\n",
            "Episode: 16/200 RapTime: 0:01:33.091668 FixedProfit: 1218643\n",
            "Episode: 17/200 RapTime: 0:01:32.380800 FixedProfit: 1214691\n",
            "Episode: 18/200 RapTime: 0:01:33.221848 FixedProfit: 1202255\n",
            "Episode: 19/200 RapTime: 0:01:32.800963 FixedProfit: 1242579\n",
            "Episode: 20/200 RapTime: 0:01:33.090129 FixedProfit: 1210620\n",
            "Episode: 21/200 RapTime: 0:01:33.420303 FixedProfit: 1165890\n",
            "Episode: 22/200 RapTime: 0:01:33.557277 FixedProfit: 1201429\n",
            "Episode: 23/200 RapTime: 0:01:32.952034 FixedProfit: 1219892\n",
            "Episode: 24/200 RapTime: 0:01:33.397047 FixedProfit: 1221189\n",
            "Episode: 25/200 RapTime: 0:01:33.113471 FixedProfit: 1184555\n",
            "Episode: 26/200 RapTime: 0:01:32.816657 FixedProfit: 1185096\n",
            "Episode: 27/200 RapTime: 0:01:32.353669 FixedProfit: 1212823\n",
            "Episode: 28/200 RapTime: 0:01:32.679352 FixedProfit: 1194641\n",
            "Episode: 29/200 RapTime: 0:01:32.424677 FixedProfit: 1205849\n",
            "Episode: 30/200 RapTime: 0:01:32.456680 FixedProfit: 1183927\n",
            "Episode: 31/200 RapTime: 0:01:32.502288 FixedProfit: 1191184\n",
            "Episode: 32/200 RapTime: 0:01:32.944596 FixedProfit: 1219866\n",
            "Episode: 33/200 RapTime: 0:01:32.215881 FixedProfit: 1205451\n",
            "Episode: 34/200 RapTime: 0:01:32.993552 FixedProfit: 1180463\n",
            "Episode: 35/200 RapTime: 0:01:33.844725 FixedProfit: 1187362\n",
            "Episode: 36/200 RapTime: 0:01:32.860797 FixedProfit: 1211374\n",
            "Episode: 37/200 RapTime: 0:01:33.195098 FixedProfit: 1192980\n",
            "Episode: 38/200 RapTime: 0:01:33.435278 FixedProfit: 1191744\n",
            "Episode: 39/200 RapTime: 0:01:32.786635 FixedProfit: 1172187\n",
            "Episode: 40/200 RapTime: 0:01:32.775134 FixedProfit: 1187209\n",
            "Episode: 41/200 RapTime: 0:01:32.927930 FixedProfit: 1195955\n",
            "Episode: 42/200 RapTime: 0:01:33.225164 FixedProfit: 1208752\n",
            "Episode: 43/200 RapTime: 0:01:32.720779 FixedProfit: 1201047\n",
            "Episode: 44/200 RapTime: 0:01:32.524375 FixedProfit: 1170018\n",
            "Episode: 45/200 RapTime: 0:01:32.511737 FixedProfit: 1229756\n",
            "Episode: 46/200 RapTime: 0:01:32.107301 FixedProfit: 1213233\n",
            "Episode: 47/200 RapTime: 0:01:31.610075 FixedProfit: 1212350\n",
            "Episode: 48/200 RapTime: 0:01:31.733033 FixedProfit: 1168622\n",
            "Episode: 49/200 RapTime: 0:01:31.529201 FixedProfit: 1184920\n",
            "Episode: 50/200 RapTime: 0:01:31.571181 FixedProfit: 1206930\n",
            "Episode: 51/200 RapTime: 0:01:31.475713 FixedProfit: 1183379\n",
            "Episode: 52/200 RapTime: 0:01:31.625912 FixedProfit: 1232832\n",
            "Episode: 53/200 RapTime: 0:01:31.308165 FixedProfit: 1232643\n",
            "Episode: 54/200 RapTime: 0:01:31.602483 FixedProfit: 1200748\n",
            "Episode: 55/200 RapTime: 0:01:31.404034 FixedProfit: 1178816\n",
            "Episode: 56/200 RapTime: 0:01:31.431462 FixedProfit: 1229834\n",
            "Episode: 57/200 RapTime: 0:01:32.202522 FixedProfit: 1196800\n",
            "Episode: 58/200 RapTime: 0:01:31.426440 FixedProfit: 1172300\n",
            "Episode: 59/200 RapTime: 0:01:31.404080 FixedProfit: 1164194\n",
            "Episode: 60/200 RapTime: 0:01:31.637706 FixedProfit: 1204005\n",
            "Episode: 61/200 RapTime: 0:01:31.114539 FixedProfit: 1210925\n",
            "Episode: 62/200 RapTime: 0:01:31.380007 FixedProfit: 1192775\n",
            "Episode: 63/200 RapTime: 0:01:32.009880 FixedProfit: 1186880\n",
            "Episode: 64/200 RapTime: 0:01:31.624102 FixedProfit: 1197226\n",
            "Episode: 65/200 RapTime: 0:01:31.840126 FixedProfit: 1202842\n",
            "Episode: 66/200 RapTime: 0:01:31.482800 FixedProfit: 1190548\n",
            "Episode: 67/200 RapTime: 0:01:31.451618 FixedProfit: 1225342\n",
            "Episode: 68/200 RapTime: 0:01:31.606399 FixedProfit: 1168344\n",
            "Episode: 69/200 RapTime: 0:01:31.408993 FixedProfit: 1240064\n",
            "Episode: 70/200 RapTime: 0:01:31.530371 FixedProfit: 1204141\n",
            "Episode: 71/200 RapTime: 0:01:31.714733 FixedProfit: 1204141\n",
            "Episode: 72/200 RapTime: 0:01:31.509955 FixedProfit: 1157133\n",
            "Episode: 73/200 RapTime: 0:01:30.909158 FixedProfit: 1183826\n",
            "Episode: 74/200 RapTime: 0:01:31.678573 FixedProfit: 1173007\n",
            "Episode: 75/200 RapTime: 0:01:31.193972 FixedProfit: 1224532\n",
            "Episode: 76/200 RapTime: 0:01:31.449854 FixedProfit: 1186387\n",
            "Episode: 77/200 RapTime: 0:01:31.415411 FixedProfit: 1218373\n",
            "Episode: 78/200 RapTime: 0:01:31.289711 FixedProfit: 1186789\n",
            "Episode: 79/200 RapTime: 0:01:32.290006 FixedProfit: 1177230\n",
            "Episode: 80/200 RapTime: 0:01:35.398757 FixedProfit: 1213825\n",
            "Episode: 81/200 RapTime: 0:01:34.912441 FixedProfit: 1201916\n",
            "Episode: 82/200 RapTime: 0:01:33.753199 FixedProfit: 1200988\n",
            "Episode: 83/200 RapTime: 0:01:33.078933 FixedProfit: 1164926\n",
            "Episode: 84/200 RapTime: 0:01:32.964488 FixedProfit: 1203846\n",
            "Episode: 85/200 RapTime: 0:01:32.924685 FixedProfit: 1159958\n",
            "Episode: 86/200 RapTime: 0:01:33.147413 FixedProfit: 1248748\n",
            "Episode: 87/200 RapTime: 0:01:33.045800 FixedProfit: 1180296\n",
            "Episode: 88/200 RapTime: 0:01:32.860983 FixedProfit: 1181456\n",
            "Episode: 89/200 RapTime: 0:01:33.305462 FixedProfit: 1183692\n",
            "Episode: 90/200 RapTime: 0:01:33.316906 FixedProfit: 1136452\n",
            "Episode: 91/200 RapTime: 0:01:33.624198 FixedProfit: 1167131\n",
            "Episode: 92/200 RapTime: 0:01:33.695739 FixedProfit: 1281403\n",
            "Episode: 93/200 RapTime: 0:01:33.188479 FixedProfit: 1164726\n",
            "Episode: 94/200 RapTime: 0:01:33.177007 FixedProfit: 1177009\n",
            "Episode: 95/200 RapTime: 0:01:33.310892 FixedProfit: 1239647\n",
            "Episode: 96/200 RapTime: 0:01:33.611344 FixedProfit: 1166591\n",
            "Episode: 97/200 RapTime: 0:01:33.334025 FixedProfit: 1206625\n",
            "Episode: 98/200 RapTime: 0:01:32.783283 FixedProfit: 1230392\n",
            "Episode: 99/200 RapTime: 0:01:33.107545 FixedProfit: 1164621\n",
            "Episode: 100/200 RapTime: 0:01:33.119994 FixedProfit: 1186961\n",
            "Episode: 101/200 RapTime: 0:01:33.382571 FixedProfit: 1191931\n",
            "Episode: 102/200 RapTime: 0:01:33.317743 FixedProfit: 1210178\n",
            "Episode: 103/200 RapTime: 0:01:33.146288 FixedProfit: 1223728\n",
            "Episode: 104/200 RapTime: 0:01:32.855179 FixedProfit: 1187994\n",
            "Episode: 105/200 RapTime: 0:01:32.652924 FixedProfit: 1193660\n",
            "Episode: 106/200 RapTime: 0:01:33.563163 FixedProfit: 1189331\n",
            "Episode: 107/200 RapTime: 0:01:33.186646 FixedProfit: 1160162\n",
            "Episode: 108/200 RapTime: 0:01:33.708995 FixedProfit: 1194102\n",
            "Episode: 109/200 RapTime: 0:01:33.555720 FixedProfit: 1201666\n",
            "Episode: 110/200 RapTime: 0:01:33.469343 FixedProfit: 1170784\n",
            "Episode: 111/200 RapTime: 0:01:33.053204 FixedProfit: 1220482\n",
            "Episode: 112/200 RapTime: 0:01:33.330781 FixedProfit: 1199236\n",
            "Episode: 113/200 RapTime: 0:01:32.751535 FixedProfit: 1210233\n",
            "Episode: 114/200 RapTime: 0:01:33.258933 FixedProfit: 1183542\n",
            "Episode: 115/200 RapTime: 0:01:33.301215 FixedProfit: 1192926\n",
            "Episode: 116/200 RapTime: 0:01:33.489025 FixedProfit: 1178044\n",
            "Episode: 117/200 RapTime: 0:01:33.347099 FixedProfit: 1210631\n",
            "Episode: 118/200 RapTime: 0:01:33.081934 FixedProfit: 1187473\n",
            "Episode: 119/200 RapTime: 0:01:33.540281 FixedProfit: 1206529\n",
            "Episode: 120/200 RapTime: 0:01:33.865426 FixedProfit: 1207595\n",
            "Episode: 121/200 RapTime: 0:01:33.155964 FixedProfit: 1206858\n",
            "Episode: 122/200 RapTime: 0:01:33.706870 FixedProfit: 1158209\n",
            "Episode: 123/200 RapTime: 0:01:33.981989 FixedProfit: 1161624\n",
            "Episode: 124/200 RapTime: 0:01:33.667224 FixedProfit: 1167400\n",
            "Episode: 125/200 RapTime: 0:01:33.851489 FixedProfit: 1192240\n",
            "Episode: 126/200 RapTime: 0:01:33.862683 FixedProfit: 1216213\n",
            "Episode: 127/200 RapTime: 0:01:33.398160 FixedProfit: 1167177\n",
            "Episode: 128/200 RapTime: 0:01:32.850839 FixedProfit: 1185942\n",
            "Episode: 129/200 RapTime: 0:01:33.475092 FixedProfit: 1210305\n",
            "Episode: 130/200 RapTime: 0:01:32.837750 FixedProfit: 1183266\n",
            "Episode: 131/200 RapTime: 0:01:32.830886 FixedProfit: 1247260\n",
            "Episode: 132/200 RapTime: 0:01:32.780033 FixedProfit: 1144918\n",
            "Episode: 133/200 RapTime: 0:01:32.918735 FixedProfit: 1206968\n",
            "Episode: 134/200 RapTime: 0:01:33.135339 FixedProfit: 1170213\n",
            "Episode: 135/200 RapTime: 0:01:33.280306 FixedProfit: 1183545\n",
            "Episode: 136/200 RapTime: 0:01:33.102099 FixedProfit: 1200480\n",
            "Episode: 137/200 RapTime: 0:01:33.388378 FixedProfit: 1225782\n",
            "Episode: 138/200 RapTime: 0:01:33.347709 FixedProfit: 1238009\n",
            "Episode: 139/200 RapTime: 0:01:33.924601 FixedProfit: 1166805\n",
            "Episode: 140/200 RapTime: 0:01:35.361568 FixedProfit: 1194682\n",
            "Episode: 141/200 RapTime: 0:01:32.705650 FixedProfit: 1158084\n",
            "Episode: 142/200 RapTime: 0:01:32.973280 FixedProfit: 1213568\n",
            "Episode: 143/200 RapTime: 0:01:33.029129 FixedProfit: 1190857\n",
            "Episode: 144/200 RapTime: 0:01:33.702545 FixedProfit: 1189905\n",
            "Episode: 145/200 RapTime: 0:01:33.920190 FixedProfit: 1187663\n",
            "Episode: 146/200 RapTime: 0:01:32.896431 FixedProfit: 1142638\n",
            "Episode: 147/200 RapTime: 0:01:33.483421 FixedProfit: 1182904\n",
            "Episode: 148/200 RapTime: 0:01:33.737400 FixedProfit: 1208757\n",
            "Episode: 149/200 RapTime: 0:01:32.648054 FixedProfit: 1213942\n",
            "Episode: 150/200 RapTime: 0:01:32.904104 FixedProfit: 1226887\n",
            "Episode: 151/200 RapTime: 0:01:33.930285 FixedProfit: 1173720\n",
            "Episode: 152/200 RapTime: 0:01:35.310467 FixedProfit: 1186550\n",
            "Episode: 153/200 RapTime: 0:01:33.367371 FixedProfit: 1192936\n",
            "Episode: 154/200 RapTime: 0:01:33.591585 FixedProfit: 1215981\n",
            "Episode: 155/200 RapTime: 0:01:33.618474 FixedProfit: 1191750\n",
            "Episode: 156/200 RapTime: 0:01:33.948111 FixedProfit: 1200895\n",
            "Episode: 157/200 RapTime: 0:01:33.815989 FixedProfit: 1170222\n",
            "Episode: 158/200 RapTime: 0:01:32.934700 FixedProfit: 1194312\n",
            "Episode: 159/200 RapTime: 0:01:33.770243 FixedProfit: 1260131\n",
            "Episode: 160/200 RapTime: 0:01:32.976228 FixedProfit: 1212819\n",
            "Episode: 161/200 RapTime: 0:01:34.063308 FixedProfit: 1197842\n",
            "Episode: 162/200 RapTime: 0:01:35.382773 FixedProfit: 1192018\n",
            "Episode: 163/200 RapTime: 0:01:32.455309 FixedProfit: 1204721\n",
            "Episode: 164/200 RapTime: 0:01:33.102351 FixedProfit: 1173153\n",
            "Episode: 165/200 RapTime: 0:01:32.790516 FixedProfit: 1228560\n",
            "Episode: 166/200 RapTime: 0:01:32.798269 FixedProfit: 1184318\n",
            "Episode: 167/200 RapTime: 0:01:33.021983 FixedProfit: 1229512\n",
            "Episode: 168/200 RapTime: 0:01:33.065720 FixedProfit: 1250399\n",
            "Episode: 169/200 RapTime: 0:01:33.365299 FixedProfit: 1216914\n",
            "Episode: 170/200 RapTime: 0:01:33.971215 FixedProfit: 1178414\n",
            "Episode: 171/200 RapTime: 0:01:33.054831 FixedProfit: 1139561\n",
            "Episode: 172/200 RapTime: 0:01:33.252306 FixedProfit: 1191571\n",
            "Episode: 173/200 RapTime: 0:01:34.032807 FixedProfit: 1207861\n",
            "Episode: 174/200 RapTime: 0:01:33.506471 FixedProfit: 1206169\n",
            "Episode: 175/200 RapTime: 0:01:33.826933 FixedProfit: 1256554\n",
            "Episode: 176/200 RapTime: 0:01:34.037438 FixedProfit: 1202642\n",
            "Episode: 177/200 RapTime: 0:01:33.072624 FixedProfit: 1187456\n",
            "Episode: 178/200 RapTime: 0:01:33.959809 FixedProfit: 1226282\n",
            "Episode: 179/200 RapTime: 0:01:36.892355 FixedProfit: 1195678\n",
            "Episode: 180/200 RapTime: 0:01:36.748236 FixedProfit: 1211502\n",
            "Episode: 181/200 RapTime: 0:01:34.676955 FixedProfit: 1236967\n",
            "Episode: 182/200 RapTime: 0:01:34.587470 FixedProfit: 1186783\n",
            "Episode: 183/200 RapTime: 0:01:34.017607 FixedProfit: 1214986\n",
            "Episode: 184/200 RapTime: 0:01:34.411098 FixedProfit: 1189671\n",
            "Episode: 185/200 RapTime: 0:01:34.071873 FixedProfit: 1205586\n",
            "Episode: 186/200 RapTime: 0:01:34.489674 FixedProfit: 1191805\n",
            "Episode: 187/200 RapTime: 0:01:36.121824 FixedProfit: 1210985\n",
            "Episode: 188/200 RapTime: 0:01:35.567522 FixedProfit: 1239283\n",
            "Episode: 189/200 RapTime: 0:01:35.587682 FixedProfit: 1184444\n",
            "Episode: 190/200 RapTime: 0:01:34.825722 FixedProfit: 1198088\n",
            "Episode: 191/200 RapTime: 0:01:34.116593 FixedProfit: 1205205\n",
            "Episode: 192/200 RapTime: 0:01:34.156974 FixedProfit: 1166085\n",
            "Episode: 193/200 RapTime: 0:01:33.825294 FixedProfit: 1222323\n",
            "Episode: 194/200 RapTime: 0:01:33.903500 FixedProfit: 1177178\n",
            "Episode: 195/200 RapTime: 0:01:34.178012 FixedProfit: 1212976\n",
            "Episode: 196/200 RapTime: 0:01:33.720140 FixedProfit: 1202979\n",
            "Episode: 197/200 RapTime: 0:01:33.485768 FixedProfit: 1240169\n",
            "Episode: 198/200 RapTime: 0:01:34.484607 FixedProfit: 1239170\n",
            "Episode: 199/200 RapTime: 0:01:34.136322 FixedProfit: 1184440\n",
            "Episode: 200/200 RapTime: 0:01:33.942554 FixedProfit: 1188652\n"
          ]
        }
      ]
    }
  ]
}