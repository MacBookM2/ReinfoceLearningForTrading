{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO9ZEICCpfhMPHgXGyUd2dx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/q_learning_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "3ee334be-c3dd-4363-b631-ac698b5abf4a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_test.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'qlearning_test.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        q = self.model.predict(state)  \n",
        "        next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*np.max(next_q, axis=1)\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        self.brain.train(state, action, reward, next_state, done)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "\n",
        "            if mode == 'train':\n",
        "                agent.train(state, action, reward, next_state, done)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        state = next_state\n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "6eb1beef-d314-44b3-c93e-6ff83bd84d67"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'test'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_ql.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_ql.h5')\n",
        "    with open(f'{models_folder}/scaler_ql.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:35.741188 FixedProfit: 1030889 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 2/100 RapTime: 0:00:34.986842 FixedProfit: 1001537 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 3/100 RapTime: 0:00:34.631833 FixedProfit: 1001027 TradeTimes: 5 TradeWin: 1\n",
            "Episode: 4/100 RapTime: 0:00:34.693243 FixedProfit: 1020600 TradeTimes: 6 TradeWin: 5\n",
            "Episode: 5/100 RapTime: 0:00:34.912947 FixedProfit: 1019015 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 6/100 RapTime: 0:00:35.010779 FixedProfit: 1009133 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 7/100 RapTime: 0:00:34.676838 FixedProfit: 1005014 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 8/100 RapTime: 0:00:35.158031 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 9/100 RapTime: 0:00:34.244942 FixedProfit: 996859 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 10/100 RapTime: 0:00:34.841316 FixedProfit: 997056 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 11/100 RapTime: 0:00:34.532506 FixedProfit: 1001768 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 12/100 RapTime: 0:00:34.648131 FixedProfit: 1070187 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 13/100 RapTime: 0:00:34.091091 FixedProfit: 959006 TradeTimes: 6 TradeWin: 2\n",
            "Episode: 14/100 RapTime: 0:00:34.130820 FixedProfit: 979100 TradeTimes: 6 TradeWin: 2\n",
            "Episode: 15/100 RapTime: 0:00:34.267625 FixedProfit: 996072 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 16/100 RapTime: 0:00:34.712155 FixedProfit: 991554 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 17/100 RapTime: 0:00:34.695179 FixedProfit: 1004327 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 18/100 RapTime: 0:00:34.041808 FixedProfit: 980203 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 19/100 RapTime: 0:00:34.583302 FixedProfit: 1026566 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 20/100 RapTime: 0:00:33.920545 FixedProfit: 997151 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 21/100 RapTime: 0:00:34.292384 FixedProfit: 971898 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 22/100 RapTime: 0:00:34.200607 FixedProfit: 999252 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 23/100 RapTime: 0:00:34.230982 FixedProfit: 1008999 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 24/100 RapTime: 0:00:33.960837 FixedProfit: 984269 TradeTimes: 8 TradeWin: 3\n",
            "Episode: 25/100 RapTime: 0:00:34.024134 FixedProfit: 1043312 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 26/100 RapTime: 0:00:34.318342 FixedProfit: 997962 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 27/100 RapTime: 0:00:34.083208 FixedProfit: 997700 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 28/100 RapTime: 0:00:34.221272 FixedProfit: 1007135 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 29/100 RapTime: 0:00:34.137657 FixedProfit: 1021969 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 30/100 RapTime: 0:00:33.986730 FixedProfit: 1006383 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 31/100 RapTime: 0:00:34.288126 FixedProfit: 1001809 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 32/100 RapTime: 0:00:34.171045 FixedProfit: 1002906 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 33/100 RapTime: 0:00:34.473660 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 34/100 RapTime: 0:00:33.815027 FixedProfit: 985357 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 35/100 RapTime: 0:00:34.031361 FixedProfit: 1012094 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 36/100 RapTime: 0:00:34.471574 FixedProfit: 940941 TradeTimes: 5 TradeWin: 1\n",
            "Episode: 37/100 RapTime: 0:00:34.498235 FixedProfit: 1023664 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 38/100 RapTime: 0:00:34.102345 FixedProfit: 991478 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 39/100 RapTime: 0:00:33.520529 FixedProfit: 983339 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 40/100 RapTime: 0:00:34.194152 FixedProfit: 990587 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 41/100 RapTime: 0:00:33.339516 FixedProfit: 1006729 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 42/100 RapTime: 0:00:34.020710 FixedProfit: 1040490 TradeTimes: 6 TradeWin: 6\n",
            "Episode: 43/100 RapTime: 0:00:33.578576 FixedProfit: 1005512 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 44/100 RapTime: 0:00:34.087600 FixedProfit: 997147 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 45/100 RapTime: 0:00:34.196443 FixedProfit: 938854 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 46/100 RapTime: 0:00:33.409478 FixedProfit: 1027292 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 47/100 RapTime: 0:00:33.900746 FixedProfit: 854340 TradeTimes: 7 TradeWin: 1\n",
            "Episode: 48/100 RapTime: 0:00:33.456967 FixedProfit: 1014459 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 49/100 RapTime: 0:00:33.980133 FixedProfit: 1007664 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 50/100 RapTime: 0:00:33.423002 FixedProfit: 1011019 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 51/100 RapTime: 0:00:34.138478 FixedProfit: 988785 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 52/100 RapTime: 0:00:33.163812 FixedProfit: 1016762 TradeTimes: 7 TradeWin: 5\n",
            "Episode: 53/100 RapTime: 0:00:34.242459 FixedProfit: 996827 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 54/100 RapTime: 0:00:33.454033 FixedProfit: 1020872 TradeTimes: 6 TradeWin: 4\n",
            "Episode: 55/100 RapTime: 0:00:34.332873 FixedProfit: 1004230 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 56/100 RapTime: 0:00:34.178679 FixedProfit: 990330 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 57/100 RapTime: 0:00:33.585945 FixedProfit: 998697 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 58/100 RapTime: 0:00:34.145171 FixedProfit: 997145 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 59/100 RapTime: 0:00:33.843213 FixedProfit: 992843 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 60/100 RapTime: 0:00:34.189052 FixedProfit: 1013421 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 61/100 RapTime: 0:00:34.161836 FixedProfit: 1000847 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 62/100 RapTime: 0:00:33.997454 FixedProfit: 1002705 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 63/100 RapTime: 0:00:34.213942 FixedProfit: 998107 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 64/100 RapTime: 0:00:34.333369 FixedProfit: 999631 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 65/100 RapTime: 0:00:33.886467 FixedProfit: 1017979 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 66/100 RapTime: 0:00:34.114192 FixedProfit: 994745 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 67/100 RapTime: 0:00:33.816960 FixedProfit: 1001741 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 68/100 RapTime: 0:00:33.986538 FixedProfit: 1010840 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 69/100 RapTime: 0:00:33.720135 FixedProfit: 1021607 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 70/100 RapTime: 0:00:33.932330 FixedProfit: 1012842 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 71/100 RapTime: 0:00:33.766518 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 72/100 RapTime: 0:00:34.112040 FixedProfit: 1005767 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 73/100 RapTime: 0:00:33.423722 FixedProfit: 1033871 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 74/100 RapTime: 0:00:33.998604 FixedProfit: 980330 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 75/100 RapTime: 0:00:34.172124 FixedProfit: 1002867 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 76/100 RapTime: 0:00:33.363197 FixedProfit: 998146 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 77/100 RapTime: 0:00:34.079888 FixedProfit: 1007937 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 78/100 RapTime: 0:00:33.567141 FixedProfit: 986434 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 79/100 RapTime: 0:00:34.219672 FixedProfit: 969209 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 80/100 RapTime: 0:00:33.560699 FixedProfit: 1013933 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 81/100 RapTime: 0:00:34.094519 FixedProfit: 1010044 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 82/100 RapTime: 0:00:34.200254 FixedProfit: 1046193 TradeTimes: 5 TradeWin: 3\n",
            "Episode: 83/100 RapTime: 0:00:33.440126 FixedProfit: 1009233 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 84/100 RapTime: 0:00:34.279339 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 85/100 RapTime: 0:00:33.658291 FixedProfit: 1006861 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 86/100 RapTime: 0:00:34.258919 FixedProfit: 1000943 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 87/100 RapTime: 0:00:33.686118 FixedProfit: 992008 TradeTimes: 3 TradeWin: 0\n",
            "Episode: 88/100 RapTime: 0:00:33.932619 FixedProfit: 1014563 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 89/100 RapTime: 0:00:33.057076 FixedProfit: 994223 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 90/100 RapTime: 0:00:33.866253 FixedProfit: 928348 TradeTimes: 7 TradeWin: 2\n",
            "Episode: 91/100 RapTime: 0:00:33.538902 FixedProfit: 1013278 TradeTimes: 6 TradeWin: 3\n",
            "Episode: 92/100 RapTime: 0:00:34.227385 FixedProfit: 997707 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 93/100 RapTime: 0:00:33.339412 FixedProfit: 1039595 TradeTimes: 9 TradeWin: 6\n",
            "Episode: 94/100 RapTime: 0:00:34.016224 FixedProfit: 1006423 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 95/100 RapTime: 0:00:33.855407 FixedProfit: 996890 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 96/100 RapTime: 0:00:33.767794 FixedProfit: 1001131 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 97/100 RapTime: 0:00:33.651912 FixedProfit: 1013294 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 98/100 RapTime: 0:00:33.658705 FixedProfit: 1001045 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 99/100 RapTime: 0:00:34.645053 FixedProfit: 971137 TradeTimes: 5 TradeWin: 2\n",
            "Episode: 100/100 RapTime: 0:00:34.537370 FixedProfit: 1023832 TradeTimes: 7 TradeWin: 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}