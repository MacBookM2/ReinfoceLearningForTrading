{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOr7f1p3Z6dGC5aGwfOf1I/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/sarsa_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "680b0539-9739-4570-9a40-5cc94c9eca20"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'sp500_test.csv'\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + 'sarsa_test.csv'\n",
        "\n",
        "models_folder = '/content/drive/My Drive/' + exp_dir + 'rl_models'\n",
        "rewards_folder = '/content/drive/My Drive/' + exp_dir + 'rl_rewards'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-UoFozKs9l"
      },
      "source": [
        "def make_scaler(env):\n",
        "    states = []\n",
        "    for _ in range(env.df_total_steps):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.initial_money = initial_money\n",
        "        self.mode = mode\n",
        "        self.trade_time = None\n",
        "        self.trade_win = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time = 0\n",
        "        self.trade_win = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step = self.df_total_steps\n",
        "        self.now_step = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, n_hidden_layers=1, hidden_dim=32):\n",
        "\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        n_mid = 3\n",
        "        n_state = 3\n",
        "        n_action = 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, state, action, reward, next_state, next_act, done):\n",
        "        q = self.model.predict(state)\n",
        "        #next_q = self.model.predict(next_state)\n",
        "        t = np.copy(q)\n",
        "        if done:\n",
        "            t[:, action] = reward\n",
        "        else:\n",
        "            t[:, action] = reward + self.gamma*next_act\n",
        "        self.model.train_on_batch(state, t)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxR4grMVRLCR"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, brain, state_size=3, action_size=3):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.brain = brain\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r = 0.995\n",
        "\n",
        "    def act(self, state, act, reward, info, next_state, done, mode = 'train'):\n",
        "\n",
        "        next_act = self._next_act(state)\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.brain.train(state, act, reward, next_state, next_act, done)\n",
        "\n",
        "        return next_act\n",
        "\n",
        "    def _next_act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.brain.predict(state)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "def play_game(env, agent , episodes_times = 1000, mode = 'test', batch_size = 32):\n",
        "    if mode == 'test':\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit','TradeTimes','TradeWin'])\n",
        "    else:\n",
        "        df_rec = pd.DataFrame(index=[], columns=['FixedProfit'])\n",
        "\n",
        "    for episode in range(episodes_times):\n",
        "        state = env.reset()\n",
        "        state = scaler.transform([state])\n",
        "        done = False\n",
        "        start_time = datetime.now()\n",
        "        reward = 0.0\n",
        "        info = None\n",
        "        next_state = copy.copy(state)\n",
        "        next_act = 1\n",
        "        act = 1\n",
        "       \n",
        "        while not done:\n",
        "            action = agent.act(state, act, reward, info, next_state, done, mode)\n",
        "            state = next_state\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            next_state = scaler.transform([next_state])\n",
        "            act = copy.copy(action)\n",
        "            \n",
        "        play_time = datetime.now() - start_time\n",
        "        if mode == 'test':\n",
        "            record = pd.Series([info['cur_revenue'],info['trade_time'],info['trade_win']], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f} TradeTimes: {info['trade_time']} TradeWin: {info['trade_win']}\")\n",
        "        else:\n",
        "            record = pd.Series(info['cur_revenue'], index=df_rec.columns)\n",
        "            print(f\"Episode: {episode + 1}/{episodes_times} RapTime: {play_time} FixedProfit: {info['cur_revenue']:.0f}\")\n",
        "    \n",
        "        df_rec = df_rec.append(record, ignore_index=True)\n",
        "    return df_rec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "5d8101b7-e492-4061-bfbe-d10f50c31246"
      },
      "source": [
        "initial_money=1000000\n",
        "episodes_times = 100\n",
        "batch_size = 32\n",
        "mode = 'test'\n",
        "brain = Brain()\n",
        "agent = Agent(brain=brain)\n",
        "\n",
        "if mode == 'test':\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    agent.epsilon = 0.01\n",
        "    agent.load(f'{models_folder}/dqn_sarsa.h5')\n",
        "\n",
        "env = Environment(df, initial_money=initial_money, mode = mode)\n",
        "scaler = make_scaler(env)\n",
        "df_rec = play_game(env, agent , episodes_times = episodes_times, mode = mode, batch_size = batch_size)\n",
        "\n",
        "if mode == 'train':\n",
        "    agent.save(f'{models_folder}/dqn_sarsa.h5')\n",
        "    with open(f'{models_folder}/scaler_sarsa.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "df_rec.to_csv(csv_path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/100 RapTime: 0:00:29.928380 FixedProfit: 999634 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 2/100 RapTime: 0:00:28.861822 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 3/100 RapTime: 0:00:29.071987 FixedProfit: 1004618 TradeTimes: 4 TradeWin: 2\n",
            "Episode: 4/100 RapTime: 0:00:28.536984 FixedProfit: 1165957 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 5/100 RapTime: 0:00:29.911340 FixedProfit: 1094071 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 6/100 RapTime: 0:00:28.586061 FixedProfit: 1024129 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 7/100 RapTime: 0:00:29.906248 FixedProfit: 1206634 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 8/100 RapTime: 0:00:28.594175 FixedProfit: 1443457 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 9/100 RapTime: 0:00:29.467937 FixedProfit: 1158563 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 10/100 RapTime: 0:00:29.957975 FixedProfit: 1155702 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 11/100 RapTime: 0:00:29.489427 FixedProfit: 1163281 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 12/100 RapTime: 0:00:28.762367 FixedProfit: 1109448 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 13/100 RapTime: 0:00:29.538622 FixedProfit: 1052201 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 14/100 RapTime: 0:00:28.480277 FixedProfit: 1075493 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 15/100 RapTime: 0:00:29.600823 FixedProfit: 1331785 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 16/100 RapTime: 0:00:28.796433 FixedProfit: 1123329 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 17/100 RapTime: 0:00:29.408241 FixedProfit: 1387993 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 18/100 RapTime: 0:00:29.126883 FixedProfit: 1424129 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 19/100 RapTime: 0:00:28.877122 FixedProfit: 1502996 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 20/100 RapTime: 0:00:29.615934 FixedProfit: 927847 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 21/100 RapTime: 0:00:28.414861 FixedProfit: 1094084 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 22/100 RapTime: 0:00:29.929629 FixedProfit: 1086374 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 23/100 RapTime: 0:00:29.867878 FixedProfit: 1323684 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 24/100 RapTime: 0:00:28.619042 FixedProfit: 1311760 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 25/100 RapTime: 0:00:29.024477 FixedProfit: 1123898 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 26/100 RapTime: 0:00:28.670192 FixedProfit: 1270741 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 27/100 RapTime: 0:00:29.037660 FixedProfit: 1014823 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 28/100 RapTime: 0:00:29.024623 FixedProfit: 1237992 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 29/100 RapTime: 0:00:28.440573 FixedProfit: 1214146 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 30/100 RapTime: 0:00:29.334881 FixedProfit: 1232012 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 31/100 RapTime: 0:00:28.395637 FixedProfit: 1132549 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 32/100 RapTime: 0:00:29.708445 FixedProfit: 1253400 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 33/100 RapTime: 0:00:29.525075 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 34/100 RapTime: 0:00:28.968996 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 35/100 RapTime: 0:00:30.062075 FixedProfit: 1319777 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 36/100 RapTime: 0:00:30.030726 FixedProfit: 1032229 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 37/100 RapTime: 0:00:29.873002 FixedProfit: 1270546 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 38/100 RapTime: 0:00:30.566087 FixedProfit: 956068 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 39/100 RapTime: 0:00:29.458928 FixedProfit: 1100655 TradeTimes: 4 TradeWin: 1\n",
            "Episode: 40/100 RapTime: 0:00:30.374853 FixedProfit: 1508161 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 41/100 RapTime: 0:00:29.507017 FixedProfit: 1288834 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 42/100 RapTime: 0:00:30.838906 FixedProfit: 1277426 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 43/100 RapTime: 0:00:29.556580 FixedProfit: 1352575 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 44/100 RapTime: 0:00:30.530513 FixedProfit: 912771 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 45/100 RapTime: 0:00:30.339555 FixedProfit: 1122076 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 46/100 RapTime: 0:00:29.893011 FixedProfit: 1030888 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 47/100 RapTime: 0:00:30.011338 FixedProfit: 1526454 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 48/100 RapTime: 0:00:30.238273 FixedProfit: 1256895 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 49/100 RapTime: 0:00:30.111188 FixedProfit: 895400 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 50/100 RapTime: 0:00:30.410061 FixedProfit: 1086992 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 51/100 RapTime: 0:00:28.769320 FixedProfit: 1382445 TradeTimes: 4 TradeWin: 4\n",
            "Episode: 52/100 RapTime: 0:00:29.612267 FixedProfit: 976282 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 53/100 RapTime: 0:00:28.455477 FixedProfit: 1161684 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 54/100 RapTime: 0:00:29.379792 FixedProfit: 1111359 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 55/100 RapTime: 0:00:29.499372 FixedProfit: 1452049 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 56/100 RapTime: 0:00:28.638179 FixedProfit: 1047321 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 57/100 RapTime: 0:00:28.764575 FixedProfit: 1109588 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 58/100 RapTime: 0:00:29.448112 FixedProfit: 1116742 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 59/100 RapTime: 0:00:28.852595 FixedProfit: 1234444 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 60/100 RapTime: 0:00:30.753314 FixedProfit: 1003794 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 61/100 RapTime: 0:00:29.411641 FixedProfit: 1184331 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 62/100 RapTime: 0:00:30.749931 FixedProfit: 1132629 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 63/100 RapTime: 0:00:29.855426 FixedProfit: 1212191 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 64/100 RapTime: 0:00:30.691907 FixedProfit: 1154221 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 65/100 RapTime: 0:00:31.646644 FixedProfit: 936062 TradeTimes: 2 TradeWin: 1\n",
            "Episode: 66/100 RapTime: 0:00:30.057889 FixedProfit: 1151617 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 67/100 RapTime: 0:00:30.288048 FixedProfit: 1311207 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 68/100 RapTime: 0:00:30.751043 FixedProfit: 1486082 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 69/100 RapTime: 0:00:31.323295 FixedProfit: 1200801 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 70/100 RapTime: 0:00:31.724618 FixedProfit: 1309448 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 71/100 RapTime: 0:00:31.034366 FixedProfit: 1443376 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 72/100 RapTime: 0:00:30.594029 FixedProfit: 1272401 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 73/100 RapTime: 0:00:29.949009 FixedProfit: 997754 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 74/100 RapTime: 0:00:30.673136 FixedProfit: 1436525 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 75/100 RapTime: 0:00:29.610215 FixedProfit: 1000881 TradeTimes: 5 TradeWin: 4\n",
            "Episode: 76/100 RapTime: 0:00:30.669942 FixedProfit: 900534 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 77/100 RapTime: 0:00:30.744848 FixedProfit: 1142660 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 78/100 RapTime: 0:00:29.730631 FixedProfit: 1198992 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 79/100 RapTime: 0:00:31.098421 FixedProfit: 1320213 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 80/100 RapTime: 0:00:30.061002 FixedProfit: 1288892 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 81/100 RapTime: 0:00:30.412216 FixedProfit: 1525624 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 82/100 RapTime: 0:00:30.041617 FixedProfit: 1289391 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 83/100 RapTime: 0:00:30.036960 FixedProfit: 1169130 TradeTimes: 3 TradeWin: 2\n",
            "Episode: 84/100 RapTime: 0:00:31.039755 FixedProfit: 1077224 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 85/100 RapTime: 0:00:30.106106 FixedProfit: 1000000 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 86/100 RapTime: 0:00:30.946447 FixedProfit: 980338 TradeTimes: 2 TradeWin: 0\n",
            "Episode: 87/100 RapTime: 0:00:30.514918 FixedProfit: 1231594 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 88/100 RapTime: 0:00:29.694873 FixedProfit: 1118500 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 89/100 RapTime: 0:00:30.867392 FixedProfit: 1020834 TradeTimes: 3 TradeWin: 1\n",
            "Episode: 90/100 RapTime: 0:00:29.953120 FixedProfit: 1090610 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 91/100 RapTime: 0:00:30.425067 FixedProfit: 1362471 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 92/100 RapTime: 0:00:29.935591 FixedProfit: 1571582 TradeTimes: 5 TradeWin: 5\n",
            "Episode: 93/100 RapTime: 0:00:30.031694 FixedProfit: 1185278 TradeTimes: 4 TradeWin: 3\n",
            "Episode: 94/100 RapTime: 0:00:30.225837 FixedProfit: 1263323 TradeTimes: 1 TradeWin: 1\n",
            "Episode: 95/100 RapTime: 0:00:30.045661 FixedProfit: 1054749 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 96/100 RapTime: 0:00:30.570071 FixedProfit: 1310345 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 97/100 RapTime: 0:00:29.405017 FixedProfit: 1269986 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 98/100 RapTime: 0:00:30.930596 FixedProfit: 1254802 TradeTimes: 2 TradeWin: 2\n",
            "Episode: 99/100 RapTime: 0:00:31.206039 FixedProfit: 1162440 TradeTimes: 3 TradeWin: 3\n",
            "Episode: 100/100 RapTime: 0:00:30.244556 FixedProfit: 1184043 TradeTimes: 3 TradeWin: 3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}