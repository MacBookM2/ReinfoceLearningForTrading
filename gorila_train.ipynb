{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gorila_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNZQSAmGy1rzDu+/HvavYrg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugiyama404/ReinfoceLearningForTrading/blob/main/gorila_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIXg6mTzk0K",
        "outputId": "e9ec0ef3-7579-4503-c583-4df3d2e32c33"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "import copy\n",
        "\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, ReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = RMSprop()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "mode = 'train'\n",
        "name = 'gorila'\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'Colab Notebooks/dataset/reinforcement_learning/'\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + f'sp500_{mode}.csv'\n",
        "\n",
        "exp_dir = 'Colab Notebooks/workspace/export/'\n",
        "mdl_dir = '/content/drive/My Drive/' + exp_dir + 'models'\n",
        "csv_path = '/content/drive/My Drive/' + exp_dir + f'csv_data/{name}_{mode}.csv'\n",
        "\n",
        "df = pd.read_csv(nov_path)\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1DKfV6zauY"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, df, initial_money=100000, mode = 'test'):\n",
        "\n",
        "        self.df = df.dropna().reset_index()\n",
        "\n",
        "        self.df_total_steps  = len(self.df)-1\n",
        "        self.initial_money   = initial_money\n",
        "        self.mode            = mode\n",
        "        self.trade_time      = None\n",
        "        self.trade_win       = None\n",
        "        self.brfore_buy_cash = None\n",
        "        self.action_space    = np.array([0, 1, 2]) # buy,hold,sell\n",
        "        self.hold_a_position = None\n",
        "        self.now_price       = None\n",
        "        self.cash_in_hand    = None\n",
        "\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "\n",
        "        self.trade_time      = 0\n",
        "        self.trade_win       = 0\n",
        "        self.brfore_buy_cash = 0\n",
        "        self.end_step        = self.df_total_steps\n",
        "        self.now_step        = 0\n",
        "        self.hold_a_position = 0.0\n",
        "        self.now_price       = self.df.loc[self.now_step, 'SP500']\n",
        "        self.cash_in_hand    = self.initial_money\n",
        "\n",
        "        return self._get_now_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_revenue = self._get_revenue()\n",
        "        self.now_step += 1\n",
        "        self.now_price = self.df.loc[self.now_step, 'SP500']\n",
        " \n",
        "        done = (self.end_step == self.now_step)\n",
        "\n",
        "        self._trade(action,done)\n",
        "        cur_revenue = self._get_revenue()\n",
        " \n",
        "        reward = cur_revenue - prev_revenue\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            info = { 'cur_revenue' : cur_revenue , 'trade_time' : self.trade_time, 'trade_win' : self.trade_win }\n",
        "        else:\n",
        "            info = { 'cur_revenue' : cur_revenue }\n",
        "\n",
        "        return self._get_now_state(), reward, done, info\n",
        "\n",
        "    def _get_now_state(self):\n",
        "        state = np.empty(3)\n",
        "        state[0] = self.hold_a_position\n",
        "        state[1] = self.now_price\n",
        "        state[2] = self.cash_in_hand\n",
        "        return state\n",
        "\n",
        "    def _get_revenue(self): \n",
        "        return self.hold_a_position * self.now_price + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action,lastorder = False):\n",
        "        if lastorder:\n",
        "            self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "            self.hold_a_position = 0\n",
        "            if self.mode == 'test':\n",
        "                self.trade_time += 1\n",
        "                if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                    self.trade_win += 1\n",
        "        else:\n",
        "            if self.action_space[0] == action: # buy\n",
        "                if self.hold_a_position == 0:\n",
        "                    buy_flag = True\n",
        "                    if self.mode == 'test':\n",
        "                        self.brfore_buy_cash = copy.copy(self.cash_in_hand)\n",
        "                    while buy_flag:\n",
        "                        if self.cash_in_hand > self.now_price:\n",
        "                            self.hold_a_position += 1\n",
        "                            self.cash_in_hand -= self.now_price\n",
        "                        else:\n",
        "                            buy_flag = False\n",
        "            if self.action_space[2] == action: # sell\n",
        "                if self.hold_a_position != 0:\n",
        "                    self.cash_in_hand += self.now_price * self.hold_a_position\n",
        "                    self.hold_a_position = 0\n",
        "                    if self.mode == 'test':\n",
        "                        self.trade_time += 1\n",
        "                        if self.cash_in_hand > self.brfore_buy_cash:\n",
        "                            self.trade_win += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U1RNmtkaZ2W"
      },
      "source": [
        "class ParameterServer:\n",
        "    def __init__(self):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        mastermodel = Sequential()\n",
        "        mastermodel.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_mid))\n",
        "        mastermodel.add(ReLU()) \n",
        "        mastermodel.add(Dense(n_action))\n",
        "        mastermodel.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((mastermodel.summary()))\n",
        "        self.mastermodel = mastermodel\n",
        "    \n",
        "    def load(self, name):\n",
        "        self.mastermodel.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.mastermodel.save_weights(name)\n",
        "\n",
        "    def placement(self, model):\n",
        "        for m, mm in zip(model.trainable_weights, self.mastermodel.trainable_weights):\n",
        "            m.assign(mm)\n",
        "\n",
        "    def integration(self, model):\n",
        "        for mm, m in zip(self.mastermodel.trainable_weights, model.trainable_weights):\n",
        "            mm.assign(m)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGeWOM-ZWNYK"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, masterbrain):\n",
        "\n",
        "        n_mid, n_state, n_action = 3, 3, 3\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_mid))\n",
        "        model.add(ReLU()) \n",
        "        model.add(Dense(n_action))\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "        print((model.summary()))\n",
        "        self.model = model\n",
        "        self.masterbrain = masterbrain\n",
        "\n",
        "    def load(self, name):\n",
        "        self.masterbrain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.masterbrain.save(name)\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model.predict(state)\n",
        "\n",
        "    def train_on_batch(self, state, target_full):\n",
        "        self.model.train_on_batch(state, target_full)\n",
        "\n",
        "    def layering(self):\n",
        "        self.masterbrain.placement(self.model)\n",
        "\n",
        "    def integration(self):\n",
        "        self.masterbrain.integration(self.model)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1_BMH7hLQ8"
      },
      "source": [
        "class ReplayMemory:\n",
        "    def __init__(self, max_size, batch_size=32):\n",
        "\n",
        "        self.cntr = 0\n",
        "        self.size = 0\n",
        "        self.max_size3 = max_size\n",
        "        self.batch_size = batch_size\n",
        "        self.states_memory = np.zeros([self.max_size3, 3], dtype=np.float32)\n",
        "        self.next_states_memory = np.zeros([self.max_size3, 3], dtype=np.float32)\n",
        "        self.acts_memory = np.zeros(self.max_size3, dtype=np.uint8)\n",
        "        self.rewards_memory = np.zeros(self.max_size3, dtype=np.float32)\n",
        "        self.done_memory = np.zeros(self.max_size3, dtype=np.uint8)\n",
        "\n",
        "    def store_transition(self, state, act, reward, next_state, done):\n",
        "        self.states_memory[self.cntr] = state\n",
        "        self.next_states_memory[self.cntr] = next_state\n",
        "        self.acts_memory[self.cntr] = act\n",
        "        self.rewards_memory[self.cntr] = reward\n",
        "        self.done_memory[self.cntr] = done\n",
        "        self.cntr = (self.cntr+1) % self.max_size3\n",
        "        self.size = min(self.size+1, self.max_size3)\n",
        "\n",
        "    def random_sampling(self):\n",
        "        mb_index = np.random.choice(self.size, self.batch_size, replace=False)\n",
        "        key = ['state','next_state','act','reward','done']\n",
        "        value = [self.states_memory[mb_index],self.next_states_memory[mb_index],\n",
        "                 self.acts_memory[mb_index],self.rewards_memory[mb_index],\n",
        "                 self.done_memory[mb_index]]\n",
        "        dict1=dict(zip(key,value))\n",
        "\n",
        "        return dict1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrEa4wpGG1DF"
      },
      "source": [
        "class Actor:\n",
        "    def __init__(self, brain, memory, max_size, batch_size = 32):\n",
        "\n",
        "        self.brain   = brain\n",
        "        self.memory  = memory\n",
        "        self.epsilon = 1.0\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(3)\n",
        "        act_values = self.brain.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def load(self, name):\n",
        "        self.brain.load(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.brain.save(name)\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        self.memory.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "    def layering(self):\n",
        "        self.brain.layering()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42NIN-PGBOc8"
      },
      "source": [
        "class Learner:\n",
        "    def __init__(self, brain, memory, batch_size = 32):\n",
        "\n",
        "        self.brain  = brain\n",
        "        self.memory = memory\n",
        "\n",
        "        self.gamma       = 0.95\n",
        "        self.epsilon     = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.r           = 0.995\n",
        "        self.batch_size  = batch_size\n",
        "\n",
        "    def learn(self):\n",
        "        if self.memory.size < self.batch_size:\n",
        "            return\n",
        "\n",
        "        m_batch = self.memory.random_sampling()\n",
        "        states, next_states, actions, rewards, done = m_batch['state'], m_batch['next_state'], m_batch['act'], m_batch['reward'], m_batch['done']\n",
        "        target = rewards + (1 - done) * self.gamma * np.amax(self.brain.predict(next_states), axis=1)\n",
        "\n",
        "        target_full = self.brain.predict(states)\n",
        "\n",
        "        target_full[np.arange(self.batch_size), actions] = target\n",
        "        self.brain.train_on_batch(states, target_full)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.r\n",
        "\n",
        "    def integration(self):\n",
        "        self.brain.integration()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5S8YtLz3U4"
      },
      "source": [
        "class Main:\n",
        "    def __init__(self, env, actor, learner, num, mdl_dir, name, episodes_times = 1000, mode = 'test'):\n",
        "        self.env            = env\n",
        "        self.actor          = actor\n",
        "        self.learner        = learner\n",
        "        self.num            = str(num)\n",
        "        self.mdl_dir        = mdl_dir\n",
        "        self.scaler         = self._standard_scaler(self.env)\n",
        "        self.episodes_times = episodes_times\n",
        "        self.mode           = mode\n",
        "        self.name           = name\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            self._load()\n",
        "            self.actor.epsilon = 0.01\n",
        "\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit,TradeTimes,TradeWin'\n",
        "                print(row, file=f)\n",
        "        else:\n",
        "            with open(csv_path, 'w') as f:\n",
        "                row = 'FixedProfit'\n",
        "                print(row, file=f)\n",
        "\n",
        "    def play_game(self):\n",
        "        self.actor.layering()\n",
        "\n",
        "        for episode in range(self.episodes_times):\n",
        "            state = self.env.reset()\n",
        "            state = self.scaler.transform([state])\n",
        "            done  = False\n",
        "            start_time = datetime.now()\n",
        "        \n",
        "            while not done:\n",
        "                action = self.actor.act(state)\n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = self.scaler.transform([next_state])\n",
        "\n",
        "                if self.mode == 'train':\n",
        "                    self.actor.store_transition(state, action, reward, next_state, done)\n",
        "                    self.learner.learn()\n",
        "                \n",
        "            play_time = datetime.now() - start_time\n",
        "            if mode == 'test':\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f} TradeTimes: {} TradeWin: {}\".format(episode + 1, episodes_times, play_time, info['cur_revenue'], info['trade_time'], info['trade_win']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue']) + ',' + str(info['trade_time']) + ',' + str(info['trade_win'])\n",
        "                    print(row, file=f)\n",
        "            else:\n",
        "                learner.integration()\n",
        "                actor.layering()\n",
        "                print(\"Episode: {}/{} RapTime: {} FixedProfit: {:.0f}\".format(episode + 1, episodes_times, play_time, info['cur_revenue']))\n",
        "                with open(csv_path, 'a') as f:\n",
        "                    row = str(info['cur_revenue'])\n",
        "                    print(row, file=f)\n",
        "    \n",
        "            state = next_state\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self._save()\n",
        "\n",
        "    def _standard_scaler(self, env):\n",
        "        states = []\n",
        "        for _ in range(env.df_total_steps):\n",
        "            action = np.random.choice(env.action_space)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            states.append(state)\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(states)\n",
        "        return scaler\n",
        "\n",
        "    def _load(self):\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'rb') as f:\n",
        "            self.scaler = pickle.load(f)\n",
        "        self.actor.load('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))\n",
        "\n",
        "\n",
        "    def _save(self):\n",
        "        with open('{}/{}_{}.pkl'.format(self.mdl_dir, self.name, self.num), 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "        self.actor.save('{}/{}.h5'.format(self.mdl_dir, self.name, self.num))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFNVDDQz9X9",
        "outputId": "f226d22d-7758-4cf4-9077-8e7a5d0b1f17"
      },
      "source": [
        "initial_money  = 1000000\n",
        "episodes_times = 50\n",
        "batch_size     = 32\n",
        "max_size       = 500\n",
        "\n",
        "masterbrain    = ParameterServer()\n",
        "\n",
        "thread_num = 4\n",
        "envs = []\n",
        "for i in range(thread_num):\n",
        "    env     = Environment(df, initial_money=initial_money, mode = mode)\n",
        "    brain   = Brain(masterbrain)\n",
        "    memory  = ReplayMemory(max_size, batch_size)\n",
        "    actor   = Actor(brain, memory, max_size, batch_size)\n",
        "    learner = Learner(brain, memory, batch_size)\n",
        "    main    = Main(env, actor, learner, i, mdl_dir, name, episodes_times, mode)\n",
        "    envs.append(main)\n",
        "\n",
        "datas = []\n",
        "with ThreadPoolExecutor(max_workers=thread_num) as executor:\n",
        "    for env in envs:\n",
        "        job = lambda: env.play_game()\n",
        "        datas.append(executor.submit(job))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode: 1/50 RapTime: 0:03:04.610237 FixedProfit: 1110862\n",
            "Episode: 1/50 RapTime: 0:03:06.341864 FixedProfit: 1245949\n",
            "Episode: 1/50 RapTime: 0:03:08.682811 FixedProfit: 1277344\n",
            "Episode: 1/50 RapTime: 0:03:09.713337 FixedProfit: 998222\n",
            "Episode: 2/50 RapTime: 0:03:12.706660 FixedProfit: 987857\n",
            "Episode: 2/50 RapTime: 0:03:13.651299 FixedProfit: 1011501\n",
            "Episode: 2/50 RapTime: 0:03:14.013664 FixedProfit: 1092384\n",
            "Episode: 2/50 RapTime: 0:03:17.449602 FixedProfit: 1070635\n",
            "Episode: 3/50 RapTime: 0:03:11.167278 FixedProfit: 991319\n",
            "Episode: 3/50 RapTime: 0:03:17.692722 FixedProfit: 1010765\n",
            "Episode: 3/50 RapTime: 0:03:14.418754 FixedProfit: 1081922\n",
            "Episode: 3/50 RapTime: 0:03:16.448794 FixedProfit: 1199108\n",
            "Episode: 4/50 RapTime: 0:03:15.730286 FixedProfit: 1209490\n",
            "Episode: 4/50 RapTime: 0:03:15.794933 FixedProfit: 1121171\n",
            "Episode: 4/50 RapTime: 0:03:17.330297 FixedProfit: 1155252\n",
            "Episode: 4/50 RapTime: 0:03:17.243499 FixedProfit: 876747\n",
            "Episode: 5/50 RapTime: 0:03:17.890037 FixedProfit: 982220\n",
            "Episode: 5/50 RapTime: 0:03:18.665634 FixedProfit: 945432\n",
            "Episode: 5/50 RapTime: 0:03:18.716213 FixedProfit: 1015710\n",
            "Episode: 5/50 RapTime: 0:03:20.180095 FixedProfit: 982599\n",
            "Episode: 6/50 RapTime: 0:03:17.868859 FixedProfit: 1031683\n",
            "Episode: 6/50 RapTime: 0:03:18.144685 FixedProfit: 930706\n",
            "Episode: 6/50 RapTime: 0:03:18.625652 FixedProfit: 1080528\n",
            "Episode: 6/50 RapTime: 0:03:20.953282 FixedProfit: 1126743\n",
            "Episode: 7/50 RapTime: 0:03:18.381015 FixedProfit: 1288746\n",
            "Episode: 7/50 RapTime: 0:03:21.514690 FixedProfit: 1052655\n",
            "Episode: 7/50 RapTime: 0:03:17.424413 FixedProfit: 1337358\n",
            "Episode: 7/50 RapTime: 0:03:20.299994 FixedProfit: 890712\n",
            "Episode: 8/50 RapTime: 0:03:16.134655 FixedProfit: 1231677\n",
            "Episode: 8/50 RapTime: 0:03:20.234361 FixedProfit: 1022177\n",
            "Episode: 8/50 RapTime: 0:03:21.788899 FixedProfit: 1181859\n",
            "Episode: 8/50 RapTime: 0:03:26.036598 FixedProfit: 1190706\n",
            "Episode: 9/50 RapTime: 0:03:24.351115 FixedProfit: 885012\n",
            "Episode: 9/50 RapTime: 0:03:25.616954 FixedProfit: 1288028\n",
            "Episode: 9/50 RapTime: 0:03:21.195040 FixedProfit: 1037221\n",
            "Episode: 9/50 RapTime: 0:03:24.675409 FixedProfit: 904361\n",
            "Episode: 10/50 RapTime: 0:03:26.076511 FixedProfit: 1280002\n",
            "Episode: 10/50 RapTime: 0:03:27.114527 FixedProfit: 1139213\n",
            "Episode: 10/50 RapTime: 0:03:26.886564 FixedProfit: 1082685\n",
            "Episode: 10/50 RapTime: 0:03:24.336260 FixedProfit: 1200736\n",
            "Episode: 11/50 RapTime: 0:03:30.096140 FixedProfit: 924536\n",
            "Episode: 11/50 RapTime: 0:03:28.069612 FixedProfit: 1295805\n",
            "Episode: 11/50 RapTime: 0:03:28.162789 FixedProfit: 1259045\n",
            "Episode: 11/50 RapTime: 0:03:28.829041 FixedProfit: 1138253\n",
            "Episode: 12/50 RapTime: 0:03:31.024070 FixedProfit: 1203803\n",
            "Episode: 12/50 RapTime: 0:03:29.162958 FixedProfit: 1165072\n",
            "Episode: 12/50 RapTime: 0:03:30.331436 FixedProfit: 1188058\n",
            "Episode: 12/50 RapTime: 0:03:30.940139 FixedProfit: 1121490\n",
            "Episode: 13/50 RapTime: 0:03:32.906362 FixedProfit: 896142\n",
            "Episode: 13/50 RapTime: 0:03:34.636273 FixedProfit: 1141903\n",
            "Episode: 13/50 RapTime: 0:03:34.997794 FixedProfit: 1109525\n",
            "Episode: 13/50 RapTime: 0:03:36.291289 FixedProfit: 1194107\n",
            "Episode: 14/50 RapTime: 0:03:31.536568 FixedProfit: 959114\n",
            "Episode: 14/50 RapTime: 0:03:34.795058 FixedProfit: 1358766\n",
            "Episode: 14/50 RapTime: 0:03:32.623077 FixedProfit: 1232038\n",
            "Episode: 14/50 RapTime: 0:03:29.300094 FixedProfit: 979959\n",
            "Episode: 15/50 RapTime: 0:03:35.079481 FixedProfit: 996216\n",
            "Episode: 15/50 RapTime: 0:03:33.849840 FixedProfit: 1348817\n",
            "Episode: 15/50 RapTime: 0:03:34.010252 FixedProfit: 1221464\n",
            "Episode: 15/50 RapTime: 0:03:35.824910 FixedProfit: 1168191\n",
            "Episode: 16/50 RapTime: 0:03:41.905804 FixedProfit: 1208414\n",
            "Episode: 16/50 RapTime: 0:03:36.622346 FixedProfit: 983263\n",
            "Episode: 16/50 RapTime: 0:03:44.627954 FixedProfit: 1133187\n",
            "Episode: 16/50 RapTime: 0:03:37.402321 FixedProfit: 1187818\n",
            "Episode: 17/50 RapTime: 0:03:40.859828 FixedProfit: 1120599\n",
            "Episode: 17/50 RapTime: 0:03:41.921390 FixedProfit: 999687\n",
            "Episode: 17/50 RapTime: 0:03:37.051625 FixedProfit: 1190030\n",
            "Episode: 17/50 RapTime: 0:03:41.778626 FixedProfit: 1221297\n",
            "Episode: 18/50 RapTime: 0:03:41.282375 FixedProfit: 1216415\n",
            "Episode: 18/50 RapTime: 0:03:41.005953 FixedProfit: 993513\n",
            "Episode: 18/50 RapTime: 0:03:39.471075 FixedProfit: 1104736\n",
            "Episode: 18/50 RapTime: 0:03:39.259692 FixedProfit: 1048866\n",
            "Episode: 19/50 RapTime: 0:03:41.366891 FixedProfit: 1266770\n",
            "Episode: 19/50 RapTime: 0:03:38.436891 FixedProfit: 1298624\n",
            "Episode: 19/50 RapTime: 0:03:41.960231 FixedProfit: 1095884\n",
            "Episode: 19/50 RapTime: 0:03:38.082467 FixedProfit: 1088823\n",
            "Episode: 20/50 RapTime: 0:03:42.816682 FixedProfit: 1113080\n",
            "Episode: 20/50 RapTime: 0:03:44.508544 FixedProfit: 1067717\n",
            "Episode: 20/50 RapTime: 0:03:44.955260 FixedProfit: 1165438\n",
            "Episode: 20/50 RapTime: 0:03:43.893950 FixedProfit: 1037675\n",
            "Episode: 21/50 RapTime: 0:03:45.002478 FixedProfit: 907993\n",
            "Episode: 21/50 RapTime: 0:03:45.155922 FixedProfit: 948143\n",
            "Episode: 21/50 RapTime: 0:03:43.019156 FixedProfit: 986435\n",
            "Episode: 21/50 RapTime: 0:03:41.885827 FixedProfit: 1212256\n",
            "Episode: 22/50 RapTime: 0:03:45.904051 FixedProfit: 1144714\n",
            "Episode: 22/50 RapTime: 0:03:44.329121 FixedProfit: 1155228\n",
            "Episode: 22/50 RapTime: 0:03:44.475572 FixedProfit: 912559\n",
            "Episode: 22/50 RapTime: 0:03:47.900199 FixedProfit: 1058386\n",
            "Episode: 23/50 RapTime: 0:03:49.160660 FixedProfit: 1000612\n",
            "Episode: 23/50 RapTime: 0:03:46.732073 FixedProfit: 1153046\n",
            "Episode: 23/50 RapTime: 0:03:52.609445 FixedProfit: 1102831\n",
            "Episode: 23/50 RapTime: 0:03:49.220405 FixedProfit: 1092845\n",
            "Episode: 24/50 RapTime: 0:03:46.007412 FixedProfit: 1089476\n",
            "Episode: 24/50 RapTime: 0:03:47.202585 FixedProfit: 1265970\n",
            "Episode: 24/50 RapTime: 0:03:50.132501 FixedProfit: 956891\n",
            "Episode: 24/50 RapTime: 0:03:49.081747 FixedProfit: 958957\n",
            "Episode: 25/50 RapTime: 0:03:47.110316 FixedProfit: 1077904\n",
            "Episode: 25/50 RapTime: 0:03:54.071852 FixedProfit: 1024160\n",
            "Episode: 25/50 RapTime: 0:03:53.286884 FixedProfit: 1162763\n",
            "Episode: 25/50 RapTime: 0:03:50.185481 FixedProfit: 1030601\n",
            "Episode: 26/50 RapTime: 0:03:53.537367 FixedProfit: 1036705\n",
            "Episode: 26/50 RapTime: 0:03:51.259131 FixedProfit: 1071572\n",
            "Episode: 26/50 RapTime: 0:03:55.120718 FixedProfit: 1008911\n",
            "Episode: 26/50 RapTime: 0:03:53.881191 FixedProfit: 971035\n",
            "Episode: 27/50 RapTime: 0:03:56.923351 FixedProfit: 945139\n",
            "Episode: 27/50 RapTime: 0:03:57.364764 FixedProfit: 1201928\n",
            "Episode: 27/50 RapTime: 0:03:56.541550 FixedProfit: 1249396\n",
            "Episode: 27/50 RapTime: 0:03:58.705389 FixedProfit: 1098184\n",
            "Episode: 28/50 RapTime: 0:03:58.697006 FixedProfit: 1123000\n",
            "Episode: 28/50 RapTime: 0:04:00.261733 FixedProfit: 1000470\n",
            "Episode: 28/50 RapTime: 0:04:00.922719 FixedProfit: 1236791\n",
            "Episode: 28/50 RapTime: 0:04:02.172586 FixedProfit: 1173362\n",
            "Episode: 29/50 RapTime: 0:04:01.969644 FixedProfit: 1085701\n",
            "Episode: 29/50 RapTime: 0:04:00.269012 FixedProfit: 1027143\n",
            "Episode: 29/50 RapTime: 0:04:02.271336 FixedProfit: 1017529\n",
            "Episode: 29/50 RapTime: 0:04:02.499787 FixedProfit: 1082284\n",
            "Episode: 30/50 RapTime: 0:04:06.413872 FixedProfit: 1169064\n",
            "Episode: 30/50 RapTime: 0:04:04.786149 FixedProfit: 1169005\n",
            "Episode: 30/50 RapTime: 0:04:08.429877 FixedProfit: 1038489\n",
            "Episode: 30/50 RapTime: 0:04:07.853960 FixedProfit: 1230632\n",
            "Episode: 31/50 RapTime: 0:04:07.555581 FixedProfit: 1022759\n",
            "Episode: 31/50 RapTime: 0:04:07.436134 FixedProfit: 1180716\n",
            "Episode: 31/50 RapTime: 0:04:07.265382 FixedProfit: 1058104\n",
            "Episode: 31/50 RapTime: 0:04:07.046496 FixedProfit: 1162406\n",
            "Episode: 32/50 RapTime: 0:04:04.639827 FixedProfit: 1276577\n",
            "Episode: 32/50 RapTime: 0:04:10.548865 FixedProfit: 958519\n",
            "Episode: 32/50 RapTime: 0:04:12.470468 FixedProfit: 1042906\n",
            "Episode: 32/50 RapTime: 0:04:10.774216 FixedProfit: 984750\n",
            "Episode: 33/50 RapTime: 0:04:13.638903 FixedProfit: 1044525\n",
            "Episode: 33/50 RapTime: 0:04:13.806184 FixedProfit: 1158982\n",
            "Episode: 33/50 RapTime: 0:04:16.495729 FixedProfit: 1250085\n",
            "Episode: 33/50 RapTime: 0:04:13.795275 FixedProfit: 1226988\n",
            "Episode: 34/50 RapTime: 0:04:14.422256 FixedProfit: 1051010\n",
            "Episode: 34/50 RapTime: 0:04:11.597322 FixedProfit: 1169495\n",
            "Episode: 34/50 RapTime: 0:04:14.837288 FixedProfit: 1014767\n",
            "Episode: 34/50 RapTime: 0:04:11.270156 FixedProfit: 1011271\n",
            "Episode: 35/50 RapTime: 0:04:21.150585 FixedProfit: 901330\n",
            "Episode: 35/50 RapTime: 0:04:14.872070 FixedProfit: 1176262\n",
            "Episode: 35/50 RapTime: 0:04:18.985764 FixedProfit: 929792\n",
            "Episode: 35/50 RapTime: 0:04:17.721194 FixedProfit: 944461\n",
            "Episode: 36/50 RapTime: 0:04:24.009732 FixedProfit: 1081793\n",
            "Episode: 36/50 RapTime: 0:04:24.073974 FixedProfit: 963066\n",
            "Episode: 36/50 RapTime: 0:04:23.870456 FixedProfit: 1236455\n",
            "Episode: 36/50 RapTime: 0:04:24.702413 FixedProfit: 1134704\n",
            "Episode: 37/50 RapTime: 0:04:21.103839 FixedProfit: 1041813\n",
            "Episode: 37/50 RapTime: 0:04:17.785118 FixedProfit: 914015\n",
            "Episode: 37/50 RapTime: 0:04:25.890961 FixedProfit: 997016\n",
            "Episode: 37/50 RapTime: 0:04:32.230730 FixedProfit: 1346790\n",
            "Episode: 38/50 RapTime: 0:04:27.254178 FixedProfit: 1113518\n",
            "Episode: 38/50 RapTime: 0:04:26.340401 FixedProfit: 975954\n",
            "Episode: 38/50 RapTime: 0:04:26.755385 FixedProfit: 1102315\n",
            "Episode: 38/50 RapTime: 0:04:26.278092 FixedProfit: 1240809\n",
            "Episode: 39/50 RapTime: 0:04:32.800435 FixedProfit: 1206741\n",
            "Episode: 39/50 RapTime: 0:04:31.628699 FixedProfit: 1159394\n",
            "Episode: 39/50 RapTime: 0:04:33.829886 FixedProfit: 1006465\n",
            "Episode: 39/50 RapTime: 0:04:27.460309 FixedProfit: 1034700\n",
            "Episode: 40/50 RapTime: 0:04:32.836381 FixedProfit: 800912\n",
            "Episode: 40/50 RapTime: 0:04:35.494600 FixedProfit: 1054855\n",
            "Episode: 40/50 RapTime: 0:04:30.598476 FixedProfit: 1168108\n",
            "Episode: 40/50 RapTime: 0:04:35.627538 FixedProfit: 1180721\n",
            "Episode: 41/50 RapTime: 0:04:26.548643 FixedProfit: 1085683\n",
            "Episode: 41/50 RapTime: 0:04:28.538474 FixedProfit: 944925\n",
            "Episode: 41/50 RapTime: 0:04:25.040735 FixedProfit: 1255038\n",
            "Episode: 41/50 RapTime: 0:04:23.437010 FixedProfit: 1197744\n",
            "Episode: 42/50 RapTime: 0:04:14.954891 FixedProfit: 1011593\n",
            "Episode: 42/50 RapTime: 0:04:17.475442 FixedProfit: 1044681\n",
            "Episode: 42/50 RapTime: 0:04:14.554326 FixedProfit: 1098810\n",
            "Episode: 42/50 RapTime: 0:04:17.797484 FixedProfit: 1129245\n",
            "Episode: 43/50 RapTime: 0:04:17.033151 FixedProfit: 965216\n",
            "Episode: 43/50 RapTime: 0:04:12.142472 FixedProfit: 926023\n",
            "Episode: 43/50 RapTime: 0:04:15.198638 FixedProfit: 968796\n",
            "Episode: 43/50 RapTime: 0:04:17.550768 FixedProfit: 876126\n",
            "Episode: 44/50 RapTime: 0:04:18.628177 FixedProfit: 1253971\n",
            "Episode: 44/50 RapTime: 0:04:22.127417 FixedProfit: 1076472\n",
            "Episode: 44/50 RapTime: 0:04:12.433128 FixedProfit: 1095413\n",
            "Episode: 44/50 RapTime: 0:04:13.005103 FixedProfit: 1133475\n",
            "Episode: 45/50 RapTime: 0:04:15.338338 FixedProfit: 1057623\n",
            "Episode: 45/50 RapTime: 0:04:17.645857 FixedProfit: 1046278\n",
            "Episode: 45/50 RapTime: 0:04:16.765492 FixedProfit: 939884\n",
            "Episode: 45/50 RapTime: 0:04:16.518213 FixedProfit: 1227313\n",
            "Episode: 46/50 RapTime: 0:04:11.285265 FixedProfit: 1138461\n",
            "Episode: 46/50 RapTime: 0:04:21.245348 FixedProfit: 1158817\n",
            "Episode: 46/50 RapTime: 0:04:14.214673 FixedProfit: 1247121\n",
            "Episode: 46/50 RapTime: 0:04:29.116508 FixedProfit: 1069359\n",
            "Episode: 47/50 RapTime: 0:04:17.523927 FixedProfit: 1161014\n",
            "Episode: 47/50 RapTime: 0:04:21.380598 FixedProfit: 1271225\n",
            "Episode: 47/50 RapTime: 0:04:27.366869 FixedProfit: 991588\n",
            "Episode: 47/50 RapTime: 0:04:21.188664 FixedProfit: 1069573\n",
            "Episode: 48/50 RapTime: 0:04:24.331119 FixedProfit: 1338478\n",
            "Episode: 48/50 RapTime: 0:04:19.149648 FixedProfit: 1166776\n",
            "Episode: 48/50 RapTime: 0:04:20.982379 FixedProfit: 1194771\n",
            "Episode: 48/50 RapTime: 0:04:20.749712 FixedProfit: 1215754\n",
            "Episode: 49/50 RapTime: 0:04:25.263582 FixedProfit: 1082831\n",
            "Episode: 49/50 RapTime: 0:04:25.347231 FixedProfit: 1317465\n",
            "Episode: 49/50 RapTime: 0:04:38.079423 FixedProfit: 1083536\n",
            "Episode: 49/50 RapTime: 0:04:25.041657 FixedProfit: 867979\n",
            "Episode: 50/50 RapTime: 0:04:30.480109 FixedProfit: 1075339\n",
            "Episode: 50/50 RapTime: 0:04:26.588424 FixedProfit: 1110597\n",
            "Episode: 50/50 RapTime: 0:04:23.899037 FixedProfit: 953602\n",
            "Episode: 50/50 RapTime: 0:04:14.812504 FixedProfit: 1230241\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}